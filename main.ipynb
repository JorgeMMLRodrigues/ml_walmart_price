{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6100c02c",
   "metadata": {},
   "source": [
    "<a href=\"https://www.kaggle.com/code/jorgemmlrodrigues/walmart-price-pred?scriptVersionId=247661249\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6701bea9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T02:01:35.466416Z",
     "iopub.status.busy": "2025-06-27T02:01:35.466122Z",
     "iopub.status.idle": "2025-06-27T02:01:44.183096Z",
     "shell.execute_reply": "2025-06-27T02:01:44.182411Z",
     "shell.execute_reply.started": "2025-06-27T02:01:35.466392Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Kaggle\n",
    "!git -C /kaggle/working clone --depth 1 https://github.com/JorgeMMLRodrigues/ml_walmart_price.git || \\\n",
    " git -C /kaggle/working/ml_walmart_price pull    \n",
    "!pip install -q -r /kaggle/working/ml_walmart_price/requirements.txt\n",
    "\n",
    "import sys, os\n",
    "os.chdir(\"/kaggle/working/ml_walmart_price\")\n",
    "sys.path.insert(0, os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "295d466e-5ee6-4c6d-ba0e-e5007bdbc98d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T02:01:45.752693Z",
     "iopub.status.busy": "2025-06-27T02:01:45.751766Z",
     "iopub.status.idle": "2025-06-27T02:01:52.517537Z",
     "shell.execute_reply": "2025-06-27T02:01:52.516853Z",
     "shell.execute_reply.started": "2025-06-27T02:01:45.752644Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\estif\\Desktop\\DataAnalyst\\_DataCourse_IronHack\\Quests\\ml_walmart_price\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from utils.trainer import ModelTrainer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import random, time, inspect,time,json,os,requests,sys, math\n",
    "from pathlib import Path\n",
    "\n",
    "from datetime import date, datetime, timedelta\n",
    "from dateutil.easter import easter\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "import akshare as ak\n",
    "\n",
    "from pandas_datareader.data import DataReader\n",
    "from pandas_datareader import wb\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, f1_score, roc_auc_score,make_scorer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,RobustScaler\n",
    "from sklearn.linear_model import RidgeCV, Lasso,ElasticNetCV\n",
    "from sklearn.experimental import enable_halving_search_cv \n",
    "from sklearn.model_selection import TimeSeriesSplit,ParameterGrid,GridSearchCV, HalvingRandomSearchCV\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.inspection import PartialDependenceDisplay,permutation_importance\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor,ExtraTreesRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e83caba5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.064462Z",
     "iopub.status.idle": "2025-06-26T22:10:14.06474Z",
     "shell.execute_reply": "2025-06-26T22:10:14.06463Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.064618Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# skip cells:\n",
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "@register_cell_magic\n",
    "def skip(line, cell):\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ecb136",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73590342",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aca79ac9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.066252Z",
     "iopub.status.idle": "2025-06-26T22:10:14.0666Z",
     "shell.execute_reply": "2025-06-26T22:10:14.066478Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.066461Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_walmart_train = pd.read_csv('csv_files/walmart_data/train.csv')\n",
    "df_walmart_test = pd.read_csv('csv_files/walmart_data/test.csv')\n",
    "df_walmart_features = pd.read_csv('csv_files/walmart_data/features.csv')\n",
    "df_walmart_stores = pd.read_csv('csv_files/walmart_data/stores.csv')\n",
    "\n",
    "df_walmart_train[\"Date\"] = pd.to_datetime(df_walmart_train[\"Date\"], errors=\"raise\")\n",
    "df_walmart_test[\"Date\"] = pd.to_datetime(df_walmart_test[\"Date\"], errors=\"raise\")\n",
    "df_walmart_features[\"Date\"] = pd.to_datetime(df_walmart_features[\"Date\"], errors=\"raise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5231e068",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.068037Z",
     "iopub.status.idle": "2025-06-26T22:10:14.068349Z",
     "shell.execute_reply": "2025-06-26T22:10:14.068213Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.068195Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_walmart_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a576dec3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.069739Z",
     "iopub.status.idle": "2025-06-26T22:10:14.070061Z",
     "shell.execute_reply": "2025-06-26T22:10:14.069932Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.069918Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_walmart_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fd3115b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.071027Z",
     "iopub.status.idle": "2025-06-26T22:10:14.071324Z",
     "shell.execute_reply": "2025-06-26T22:10:14.07119Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.071174Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_walmart_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6bce62",
   "metadata": {},
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4045cd2",
   "metadata": {},
   "source": [
    "#### Sp500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a568aad2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.072069Z",
     "iopub.status.idle": "2025-06-26T22:10:14.072323Z",
     "shell.execute_reply": "2025-06-26T22:10:14.072214Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.072202Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "# SP500 Index\n",
    "START_DATE = \"2000-01-01\"\n",
    "END_DATE   = date.today().isoformat()\n",
    "\n",
    "\n",
    "daily = yf.download(\n",
    "    \"^GSPC\",           # S&P 500 index ticker\n",
    "    start=START_DATE,\n",
    "    end=END_DATE,\n",
    "    interval=\"1d\",\n",
    "    auto_adjust=True,\n",
    "    progress=False,\n",
    ")\n",
    "\n",
    "if isinstance(daily.columns, pd.MultiIndex):\n",
    "    lvl0 = daily.columns.get_level_values(0)\n",
    "    if \"Close\" in lvl0:\n",
    "        close_prices = daily.xs(\"Close\", axis=1, level=0)\n",
    "    elif \"Adj Close\" in lvl0:\n",
    "        close_prices = daily.xs(\"Adj Close\", axis=1, level=0)\n",
    "    else:\n",
    "        raise KeyError(\"Neither 'Close' nor 'Adj Close' found in data\")\n",
    "else:\n",
    "    if \"Close\" in daily.columns:\n",
    "        close_prices = daily[\"Close\"]\n",
    "    else:\n",
    "        close_prices = daily[\"Adj Close\"]\n",
    "\n",
    "\n",
    "weekly_mean_close = close_prices.resample(\"W-FRI\").mean()\n",
    "\n",
    "if isinstance(weekly_mean_close, pd.Series):\n",
    "    df_sp500 = weekly_mean_close.to_frame(name=\"SPX_Weekly_Mean_Close\")\n",
    "else:\n",
    "    df_sp500 = weekly_mean_close.copy()\n",
    "    df_sp500.columns = [\"SPX_Weekly_Mean_Close\"]\n",
    "\n",
    "\n",
    "OUTFILE = \"csv_files/idea_csv/sp500_weekly_mean_close.csv\"\n",
    "df_sp500.to_csv(OUTFILE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cf15d9d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.073094Z",
     "iopub.status.idle": "2025-06-26T22:10:14.073328Z",
     "shell.execute_reply": "2025-06-26T22:10:14.073231Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.073214Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_sp500 = pd.read_csv(\"csv_files/idea_csv/sp500_weekly_mean_close.csv\")\n",
    "df_sp500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb5f51d",
   "metadata": {},
   "source": [
    "#### Walmart Stock Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2f4ab5a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.074871Z",
     "iopub.status.idle": "2025-06-26T22:10:14.075144Z",
     "shell.execute_reply": "2025-06-26T22:10:14.075037Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.075024Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "START_DATE = \"2000-01-01\"\n",
    "END_DATE   = date.today().isoformat()\n",
    "\n",
    "\n",
    "daily = yf.download(\n",
    "    \"WMT\",           \n",
    "    start=START_DATE,\n",
    "    end=END_DATE,\n",
    "    interval=\"1d\",\n",
    "    auto_adjust=True, \n",
    "    progress=False,\n",
    ")\n",
    "\n",
    "\n",
    "if isinstance(daily.columns, pd.MultiIndex):\n",
    "    lvl0 = daily.columns.get_level_values(0)\n",
    "    if \"Close\" in lvl0:\n",
    "        close_prices = daily.xs(\"Close\", axis=1, level=0)\n",
    "    elif \"Adj Close\" in lvl0:\n",
    "        close_prices = daily.xs(\"Adj Close\", axis=1, level=0)\n",
    "    else:\n",
    "        raise KeyError(\"Neither 'Close' nor 'Adj Close' found in data\")\n",
    "else:\n",
    "    if \"Close\" in daily.columns:\n",
    "        close_prices = daily[\"Close\"]\n",
    "    else:\n",
    "        close_prices = daily[\"Adj Close\"]\n",
    "\n",
    "\n",
    "weekly_mean_close = close_prices.resample(\"W-FRI\").mean()\n",
    "\n",
    "\n",
    "if isinstance(weekly_mean_close, pd.Series):\n",
    "    df_walmart_stock = weekly_mean_close.to_frame(name=\"WMT_Weekly_Mean_Close\")\n",
    "else:\n",
    "    df_walmart_stock = weekly_mean_close.copy()\n",
    "    df_walmart_stock.columns = [\"WMT_Weekly_Mean_Close\"]\n",
    "\n",
    "\n",
    "OUTFILE = \"csv_files/idea_csv/wmt_weekly_mean_close.csv\"\n",
    "df_walmart_stock.to_csv(OUTFILE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00c9a073",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.076035Z",
     "iopub.status.idle": "2025-06-26T22:10:14.07631Z",
     "shell.execute_reply": "2025-06-26T22:10:14.076201Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.076189Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_walmart_stock = pd.read_csv(\"csv_files/idea_csv/wmt_weekly_mean_close.csv\")\n",
    "df_walmart_stock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26393546",
   "metadata": {},
   "source": [
    "#### External Logistic companies Walmart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "813a9bff",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.077189Z",
     "iopub.status.idle": "2025-06-26T22:10:14.077467Z",
     "shell.execute_reply": "2025-06-26T22:10:14.07733Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.077319Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "#   - ARCB: ArcBest Corporation (ABF Logistics / ArcBest Freight)\n",
    "#   - AIT: AIT Worldwide Logistics\n",
    "#   - CEVA: CEVA Logistics\n",
    "#   - DPW.DE: Deutsche Post (DHL Freight / DHL Supply Chain) on XETRA\n",
    "#   - FDX: FedEx Corporation (FedEx Freight)\n",
    "#   - SAIA: Saia, Inc. (Saia Motor Freight Line)\n",
    "#   - TFII.TO: TFI International (TForce Freight) on TSX\n",
    "#   - XPO: XPO Logistics, Inc.\n",
    "#   - ODFL: Old Dominion Freight Line, Inc.\n",
    "#   - UPS: United Parcel Service, Inc.\n",
    "#   - JBHT: J.B. Hunt Transport Services, Inc.\n",
    "# Note: Some private carriers (Estes Express, R+L Carriers) are not publicly traded.\n",
    "\n",
    "TICKERS = [\n",
    "    \"ARCB\", \"AIT\", \"CEVA\", \"DPW.DE\", \"FDX\",\n",
    "    \"SAIA\", \"TFII.TO\", \"XPO\", \"ODFL\", \"UPS\", \"JBHT\"\n",
    "]\n",
    "\n",
    "START_DATE = \"2000-01-01\"\n",
    "END_DATE   = date.today().isoformat()\n",
    "\n",
    "daily = yf.download(\n",
    "    TICKERS,\n",
    "    start=START_DATE,\n",
    "    end=END_DATE,\n",
    "    interval=\"1d\",\n",
    "    auto_adjust=True,\n",
    "    group_by=\"ticker\",\n",
    "    threads=True,\n",
    "    progress=True,\n",
    ")\n",
    "\n",
    "close = pd.DataFrame()\n",
    "for sym in TICKERS:\n",
    "    try:\n",
    "        series = daily[sym][\"Close\"]\n",
    "        close[sym] = series\n",
    "    except Exception:\n",
    "        print(f\"Skipping {sym!r}: no data available or ticker invalid\")\n",
    "\n",
    "\n",
    "before = close.shape[1]\n",
    "close = close.dropna(axis=1, how=\"all\")\n",
    "after = close.shape[1]\n",
    "print(f\"Dropped {before-after} tickers; {after} tickers remain for analysis\")\n",
    "\n",
    "df_logistics = close.resample(\"W-FRI\").mean().round(4)\n",
    "\n",
    "df_logistics.columns = [f\"{sym}_df_logistics_Close\" for sym in df_logistics.columns]\n",
    "\n",
    "OUTFILE = \"csv_files/idea_csv/logistics_df_logistics_close.csv\"\n",
    "df_logistics.to_csv(OUTFILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1238b66",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.079013Z",
     "iopub.status.idle": "2025-06-26T22:10:14.079359Z",
     "shell.execute_reply": "2025-06-26T22:10:14.079202Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.079187Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_logistics = pd.read_csv(\"csv_files/idea_csv/logistics_df_logistics_close.csv\")\n",
    "df_logistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876333ca",
   "metadata": {},
   "source": [
    "#### Official China PMI (Caixin PMI only starts in 2014)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c9f73f2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.080372Z",
     "iopub.status.idle": "2025-06-26T22:10:14.080708Z",
     "shell.execute_reply": "2025-06-26T22:10:14.080562Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.080545Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "# All AkShare functions containing \"pmi\"\n",
    "\n",
    "df_official = ak.macro_china_pmi()\n",
    "\n",
    "print(\"Columns in df_official:\", df_official.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d78a461",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.081768Z",
     "iopub.status.idle": "2025-06-26T22:10:14.082081Z",
     "shell.execute_reply": "2025-06-26T22:10:14.081922Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.081908Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "# 1) Fetch the official China PMI data\n",
    "df_official = ak.macro_china_pmi()\n",
    "\n",
    "# 2) Rename Chinese column names to English\n",
    "df_official = df_official.rename(columns={\n",
    "    \"月份\": \"Date\",\n",
    "    \"制造业-指数\": \"Official_Manufacturing_PMI\",\n",
    "    \"制造业-同比增长\": \"Official_Manufacturing_PMI_YoY\",\n",
    "    \"非制造业-指数\": \"Official_Services_PMI\",\n",
    "    \"非制造业-同比增长\": \"Official_Services_PMI_YoY\",\n",
    "})\n",
    "\n",
    "# 3) Clean and parse the 'Date' column (\"YYYY年MM月份\" → \"YYYY-MM\")\n",
    "df_official[\"Date\"] = (\n",
    "    df_official[\"Date\"]\n",
    "      .str.replace(\"年\", \"-\", regex=False)\n",
    "      .str.replace(\"月份\", \"\", regex=False)\n",
    ")\n",
    "df_official[\"Date\"] = pd.to_datetime(df_official[\"Date\"], format=\"%Y-%m\")\n",
    "\n",
    "# 4) Set Date as the index and sort\n",
    "df_official = df_official.set_index(\"Date\").sort_index()\n",
    "\n",
    "# 5) Subset to the period 2009-01-01 through 2014-12-31\n",
    "df_pmi_china = df_official.loc[\"2009-01-01\":\"2014-12-31\"]\n",
    "df_pmi_china.to_csv(\"csv_files/idea_csv/df_pmi_china.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "352ea0e7",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.083746Z",
     "iopub.status.idle": "2025-06-26T22:10:14.084123Z",
     "shell.execute_reply": "2025-06-26T22:10:14.083963Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.083946Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_pmi_china = pd.read_csv(\"csv_files/idea_csv/df_pmi_china.csv\")\n",
    "df_pmi_china"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1824d1ce",
   "metadata": {},
   "source": [
    "#### PCE USA (Personal Consumption Expenditures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5091fcc",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.085593Z",
     "iopub.status.idle": "2025-06-26T22:10:14.08584Z",
     "shell.execute_reply": "2025-06-26T22:10:14.085738Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.085728Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "START_DATE = \"2000-01-01\"\n",
    "END_DATE   = date.today().isoformat()\n",
    "\n",
    "df_pce = DataReader(\"PCE\", \"fred\", start=START_DATE, end=END_DATE)\n",
    "\n",
    "df_pce.columns = [\"Personal_Consumption_Expenditures\"]\n",
    "\n",
    "# 4) Save and quick sanity-check\n",
    "OUTFILE = \"csv_files/idea_csv/personal_consumption_expenditures.csv\"\n",
    "df_pce.to_csv(OUTFILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5374042",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.08678Z",
     "iopub.status.idle": "2025-06-26T22:10:14.087024Z",
     "shell.execute_reply": "2025-06-26T22:10:14.086922Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.086911Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_pce = pd.read_csv(\"csv_files/idea_csv/personal_consumption_expenditures.csv\")\n",
    "df_pce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c091ad03",
   "metadata": {},
   "source": [
    "#### Interest Rates USA (Fed Funds Rate & Tbill 3 Months Yield)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06d04fe0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.087815Z",
     "iopub.status.idle": "2025-06-26T22:10:14.088041Z",
     "shell.execute_reply": "2025-06-26T22:10:14.087944Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.087933Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "START = \"2001-06-01\"               \n",
    "END   = date.today().isoformat()\n",
    "\n",
    "\n",
    "fed  = DataReader(\"FEDFUNDS\", \"fred\", START, END)\n",
    "tbill = DataReader(\"DGS3MO\",  \"fred\", START, END)\n",
    "\n",
    "df_interest_rates = pd.concat([fed, tbill], axis=1).rename(columns={\n",
    "    \"FEDFUNDS\": \"Fed_Funds_Rate\",\n",
    "    \"DGS3MO\":   \"TBill_3mo_Yield\",\n",
    "})\n",
    "df_interest_rates = df_interest_rates.resample(\"W-FRI\").mean()\n",
    "\n",
    "OUTFILE = \"csv_files/idea_csv/df_interest_rates.csv\"\n",
    "df_interest_rates.to_csv(OUTFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41da9b40",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.088934Z",
     "iopub.status.idle": "2025-06-26T22:10:14.089281Z",
     "shell.execute_reply": "2025-06-26T22:10:14.08913Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.089114Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_interest_rates = pd.read_csv(\"csv_files/idea_csv/df_interest_rates.csv\")\n",
    "df_interest_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8907aa88",
   "metadata": {},
   "source": [
    "#### CCI USA (Consumer Confidence Index) from University of Michigan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8eff796",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.091569Z",
     "iopub.status.idle": "2025-06-26T22:10:14.091921Z",
     "shell.execute_reply": "2025-06-26T22:10:14.091761Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.091745Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "START_DATE = \"2001-06-17\"\n",
    "END_DATE   = date.today().isoformat()\n",
    "\n",
    "df_us_cci = DataReader(\"UMCSENT\", \"fred\", START_DATE, END_DATE)\n",
    "df_us_cci.columns = [\"Consumer_Sentiment_UMich\"]\n",
    "\n",
    "OUTFILE = \"csv_files/idea_csv/consumer_confidence_index.csv\"\n",
    "df_us_cci.to_csv(OUTFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51523471",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.093128Z",
     "iopub.status.idle": "2025-06-26T22:10:14.093452Z",
     "shell.execute_reply": "2025-06-26T22:10:14.093282Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.093266Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_us_cci = pd.read_csv(\"csv_files/idea_csv/consumer_confidence_index.csv\")\n",
    "df_us_cci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9939e092",
   "metadata": {},
   "source": [
    "#### U.S.A Advance Retail Sales: Retail Trade and Food Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f03ba7e2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.094932Z",
     "iopub.status.idle": "2025-06-26T22:10:14.095163Z",
     "shell.execute_reply": "2025-06-26T22:10:14.095067Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.095057Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "START_DATE = \"2000-01-01\"\n",
    "END_DATE   = date.today().isoformat()\n",
    "\n",
    "# RSAFS = Advance Retail Sales: Retail Trade and Food Services (Millions of Dollars, SA)\n",
    "df_us_retail = DataReader(\"RSAFS\", \"fred\", START_DATE, END_DATE)\n",
    "\n",
    "df_us_retail.columns = [\"Retail_Sales_Retail_and_Food_Services_USA\"]\n",
    "\n",
    "OUTFILE = \"csv_files/idea_csv/usa_retail_sales.csv\"\n",
    "df_us_retail.to_csv(OUTFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a51ef437",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.095771Z",
     "iopub.status.idle": "2025-06-26T22:10:14.096022Z",
     "shell.execute_reply": "2025-06-26T22:10:14.095907Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.095897Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_us_retail = pd.read_csv(\"csv_files/idea_csv/usa_retail_sales.csv\")\n",
    "df_us_retail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556249e1",
   "metadata": {},
   "source": [
    "#### Exchange Rates (China, Mexico, Canada, India, Vietnam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eac1803e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.097201Z",
     "iopub.status.idle": "2025-06-26T22:10:14.097582Z",
     "shell.execute_reply": "2025-06-26T22:10:14.097429Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.097412Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "START = \"2001-06-17\"                 \n",
    "END   = date.today().isoformat()\n",
    "\n",
    "#    China (CNY per USD): DEXCHUS  \n",
    "#    Mexico (MXN per USD): DEXMXUS  \n",
    "#    Canada (CAD per USD): DEXCAUS  \n",
    "#    India (INR per USD): DEXINUS  \n",
    "cny = DataReader(\"DEXCHUS\", \"fred\", START, END)\n",
    "mxn = DataReader(\"DEXMXUS\", \"fred\", START, END)\n",
    "cad = DataReader(\"DEXCAUS\", \"fred\", START, END)\n",
    "inr = DataReader(\"DEXINUS\", \"fred\", START, END)\n",
    "\n",
    "# Vietnam via yfinance\n",
    "vn_df = yf.download(\n",
    "    \"USDVND=X\",\n",
    "    start=START,\n",
    "    end=END,\n",
    "    progress=False\n",
    ")\n",
    "vn = vn_df[[\"Close\"]].rename(columns={\"Close\": \"VND_per_USD\"})\n",
    "\n",
    "\n",
    "fx = pd.concat([cny, mxn, cad, inr, vn], axis=1).rename(columns={\n",
    "    \"DEXCHUS\": \"CNY_per_USD\",\n",
    "    \"DEXMXUS\": \"MXN_per_USD\",\n",
    "    \"DEXCAUS\": \"CAD_per_USD\",\n",
    "    \"DEXINUS\": \"INR_per_USD\"\n",
    "})\n",
    "\n",
    "df_fx = fx.resample(\"W-FRI\").mean().dropna(how=\"all\").round(4)\n",
    "\n",
    "\n",
    "OUTFILE = \"csv_files/idea_csv/foreign_exchange.csv\"\n",
    "df_fx.to_csv(OUTFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08e87636",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.098822Z",
     "iopub.status.idle": "2025-06-26T22:10:14.099158Z",
     "shell.execute_reply": "2025-06-26T22:10:14.099004Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.098989Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_fx = pd.read_csv(\"csv_files/idea_csv/foreign_exchange.csv\")\n",
    "df_fx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96b6f4e",
   "metadata": {},
   "source": [
    "#### US External Tax Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c1f4120",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.100168Z",
     "iopub.status.idle": "2025-06-26T22:10:14.100513Z",
     "shell.execute_reply": "2025-06-26T22:10:14.100336Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.100321Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "INDICATOR   = \"TM.TAX.MRCH.WM.AR.ZS\"  # Tariff rate %\n",
    "COUNTRIES   = [\"CN\", \"IN\", \"MX\", \"CA\", \"VN\"]\n",
    "START_YEAR  = 2000\n",
    "END_YEAR    = date.today().year\n",
    "\n",
    "# from World Bank\n",
    "df_us_tariff = wb.download(\n",
    "    indicator=INDICATOR,\n",
    "    country=COUNTRIES,\n",
    "    start=START_YEAR,\n",
    "    end=END_YEAR\n",
    ")\n",
    "\n",
    "df_us_tariff = df_us_tariff.reset_index().pivot(index=\"year\", columns=\"country\", values=INDICATOR)\n",
    "\n",
    "df_us_tariff = df_us_tariff.rename(columns={\n",
    "    \"CN\": \"China_Applied_Tariff_%\", \n",
    "    \"IN\": \"India_Applied_Tariff_%\", \n",
    "    \"MX\": \"Mexico_Applied_Tariff_%\", \n",
    "    \"CA\": \"Canada_Applied_Tariff_%\", \n",
    "    \"VN\": \"Vietnam_Applied_Tariff_%\"\n",
    "})\n",
    "\n",
    "\n",
    "OUTFILE = \"csv_files/idea_csv/external_tax_rates.csv\"\n",
    "df_us_tariff.to_csv(OUTFILE, index_label=\"Year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ffeee62",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.101818Z",
     "iopub.status.idle": "2025-06-26T22:10:14.102144Z",
     "shell.execute_reply": "2025-06-26T22:10:14.101994Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.101979Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_us_tariff = pd.read_csv(\"csv_files/idea_csv/external_tax_rates.csv\")\n",
    "df_us_tariff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f8530b",
   "metadata": {},
   "source": [
    "#### Holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b56fb08e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.103124Z",
     "iopub.status.idle": "2025-06-26T22:10:14.103504Z",
     "shell.execute_reply": "2025-06-26T22:10:14.103318Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.103303Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "def nth_weekday(year, month, weekday, n):\n",
    "    \"\"\"\n",
    "    Return the date of the nth occurrence of the given weekday\n",
    "    in the specified month and year.\n",
    "    weekday: Monday=0, Sunday=6\n",
    "    \"\"\"\n",
    "    d = date(year, month, 1)\n",
    "    count = 0\n",
    "    while True:\n",
    "        if d.weekday() == weekday:\n",
    "            count += 1\n",
    "            if count == n:\n",
    "                return d\n",
    "        d += timedelta(days=1)\n",
    "\n",
    "# Super Bowl dates per your list\n",
    "super_bowl_day = {2010: 12, 2011: 11, 2012: 10, 2013: 8}\n",
    "\n",
    "years = range(2010, 2014)\n",
    "records = []\n",
    "\n",
    "for year in years:\n",
    "    # Fixed‐date holidays\n",
    "    records += [\n",
    "        {\"Date\": pd.Timestamp(date(year, 2, 14)),  \"Holiday\": \"Valentine's Day\"},\n",
    "        {\"Date\": pd.Timestamp(date(year, 3, 17)),  \"Holiday\": \"St. Patrick's Day\"},\n",
    "        {\"Date\": pd.Timestamp(date(year, 7, 4)),   \"Holiday\": \"Independence Day\"},\n",
    "        {\"Date\": pd.Timestamp(date(year,10,31)),   \"Holiday\": \"Halloween\"},\n",
    "        {\"Date\": pd.Timestamp(date(year,12,24)),   \"Holiday\": \"Christmas Eve\"},\n",
    "        {\"Date\": pd.Timestamp(date(year,12,25)),   \"Holiday\": \"Christmas Day\"},\n",
    "        {\"Date\": pd.Timestamp(date(year,12,31)),   \"Holiday\": \"New Year's Eve\"},\n",
    "        # Super Bowl\n",
    "        {\"Date\": pd.Timestamp(date(year, 2, super_bowl_day[year])), \"Holiday\": \"Super Bowl\"},\n",
    "    ]\n",
    "    \n",
    "    # Presidents' Day: 3rd Monday in February\n",
    "    pd_day = nth_weekday(year, 2, 0, 3)\n",
    "    records.append({\"Date\": pd.Timestamp(pd_day), \"Holiday\": \"Presidents' Day\"})\n",
    "    \n",
    "    # Mother's Day: 2nd Sunday in May\n",
    "    md = nth_weekday(year, 5, 6, 2)\n",
    "    records.append({\"Date\": pd.Timestamp(md), \"Holiday\": \"Mother's Day\"})\n",
    "    \n",
    "    # Father's Day: 3rd Sunday in June\n",
    "    fd = nth_weekday(year, 6, 6, 3)\n",
    "    records.append({\"Date\": pd.Timestamp(fd), \"Holiday\": \"Father's Day\"})\n",
    "    \n",
    "    # Memorial Day: last Monday in May\n",
    "    d_mem = date(year, 5, 31)\n",
    "    while d_mem.weekday() != 0:  # 0 = Monday\n",
    "        d_mem -= timedelta(days=1)\n",
    "    records.append({\"Date\": pd.Timestamp(d_mem), \"Holiday\": \"Memorial Day\"})\n",
    "    \n",
    "    # Labor Day: 1st Monday in September\n",
    "    ld = nth_weekday(year, 9, 0, 1)\n",
    "    records.append({\"Date\": pd.Timestamp(ld), \"Holiday\": \"Labor Day\"})\n",
    "    \n",
    "    # Good Friday & Easter\n",
    "    eas = easter(year)\n",
    "    gf = eas - timedelta(days=2)\n",
    "    records.append({\"Date\": pd.Timestamp(gf), \"Holiday\": \"Good Friday\"})\n",
    "    records.append({\"Date\": pd.Timestamp(eas), \"Holiday\": \"Easter Sunday\"})\n",
    "    \n",
    "    # Daylight Saving Time\n",
    "    dst_start = nth_weekday(year, 3, 6, 2)   # 2nd Sunday in March\n",
    "    dst_end   = nth_weekday(year,11, 6, 1)   # 1st Sunday in November\n",
    "    records.append({\"Date\": pd.Timestamp(dst_start), \"Holiday\": \"DST Start\"})\n",
    "    records.append({\"Date\": pd.Timestamp(dst_end),   \"Holiday\": \"DST End\"})\n",
    "    \n",
    "    # Thanksgiving & related\n",
    "    th = nth_weekday(year, 11, 3, 4)  # 4th Thu in Nov\n",
    "    records.append({\"Date\": pd.Timestamp(th), \"Holiday\": \"Thanksgiving\"})\n",
    "    records.append({\"Date\": pd.Timestamp(th + timedelta(days=1)), \"Holiday\": \"Black Friday\"})\n",
    "    records.append({\"Date\": pd.Timestamp(th + timedelta(days=2)), \"Holiday\": \"Small Business Saturday\"})\n",
    "    records.append({\"Date\": pd.Timestamp(th + timedelta(days=4)), \"Holiday\": \"Cyber Monday\"})\n",
    "    # Super Saturday: last Saturday before Christmas Eve\n",
    "    d2 = date(year, 12, 24) - timedelta(days=1)\n",
    "    while d2.weekday() != 5: d2 -= timedelta(days=1)\n",
    "    records.append({\"Date\": pd.Timestamp(d2), \"Holiday\": \"Super Saturday\"})\n",
    "    \n",
    "    # Green Monday: 2nd Monday in December\n",
    "    gm = nth_weekday(year, 12, 0, 2)\n",
    "    records.append({\"Date\": pd.Timestamp(gm), \"Holiday\": \"Green Monday\"})\n",
    "    \n",
    "    # 2012‐only events\n",
    "    if year == 2012:\n",
    "        records.append({\"Date\": pd.Timestamp(date(2012, 7, 27)), \"Holiday\": \"Olympics Opening\"})\n",
    "        records.append({\"Date\": pd.Timestamp(date(2012,11, 6)), \"Holiday\": \"Presidential Election\"})\n",
    "\n",
    "# Build the DataFrame\n",
    "df_us_holidays = (\n",
    "    pd.DataFrame(records)\n",
    "      .drop_duplicates(subset=\"Date\")      # in case any collide\n",
    "      .sort_values(\"Date\")\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Save or merge as needed\n",
    "df_us_holidays.to_csv(\"csv_files/idea_csv/df_us_holidays.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3611fc71",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.104262Z",
     "iopub.status.idle": "2025-06-26T22:10:14.104611Z",
     "shell.execute_reply": "2025-06-26T22:10:14.104463Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.104438Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_us_holidays = pd.read_csv(\"csv_files/idea_csv/df_us_holidays.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d10bbba2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.108715Z",
     "iopub.status.idle": "2025-06-26T22:10:14.108989Z",
     "shell.execute_reply": "2025-06-26T22:10:14.108884Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.108873Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "#  parâmetros\n",
    "ramp_up_days   = 42\n",
    "ramp_down_days = 14\n",
    "window_days    = ramp_up_days + ramp_down_days    \n",
    "\n",
    "# dados de entrada \n",
    "df_us_holidays['Date'] = pd.to_datetime(df_us_holidays['Date']).dt.normalize()\n",
    "holidays = df_us_holidays['Date'].tolist()\n",
    "\n",
    "df_holiday_impact = df_walmart_train[['Date']].copy()\n",
    "df_holiday_impact['Date'] = pd.to_datetime(df_holiday_impact['Date']).dt.normalize()\n",
    "df_holiday_impact['HolidayImpact'] = 0.0\n",
    "\n",
    "#  função vectorizada para um único feriado\n",
    "def add_one_holiday(peak_date):\n",
    "    start = peak_date - timedelta(days=ramp_up_days)\n",
    "    end   = peak_date + timedelta(days=ramp_down_days)\n",
    "\n",
    "    mask = (df_holiday_impact['Date'] >= start) & (df_holiday_impact['Date'] <= end)\n",
    "    if not mask.any():   \n",
    "        return\n",
    "\n",
    "    diff = (df_holiday_impact.loc[mask, 'Date'] - peak_date).dt.days.to_numpy()\n",
    "\n",
    "    # parte esquerda (ramp-up: diff ∈ [-14, 0])\n",
    "    up_mask   = diff <= 0\n",
    "    x_up      = (ramp_up_days + diff[up_mask]) / ramp_up_days          # 0→1\n",
    "    weights   = np.zeros_like(diff, dtype=float)\n",
    "    weights[up_mask] = 0.5 * (1 - np.cos(np.pi * x_up))\n",
    "\n",
    "    # parte direita (ramp-down: diff ∈ (0, 42])\n",
    "    down_mask = diff > 0\n",
    "    x_down    = diff[down_mask] / ramp_down_days                       # 0→1\n",
    "    weights[down_mask] = 0.5 * (1 + np.cos(np.pi * x_down))\n",
    "\n",
    "    # soma ao total\n",
    "    df_holiday_impact.loc[mask, 'HolidayImpact'] += weights\n",
    "\n",
    "#  corre todos os feriados \n",
    "for hday in holidays:\n",
    "    add_one_holiday(hday)\n",
    "\n",
    "df_holiday_impact['HolidayImpact'] = df_holiday_impact['HolidayImpact']\n",
    "\n",
    "df_holiday_impact.to_csv('csv_files/idea_csv/df_holiday_impact.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85a722ea",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.109953Z",
     "iopub.status.idle": "2025-06-26T22:10:14.110571Z",
     "shell.execute_reply": "2025-06-26T22:10:14.11038Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.110357Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_holiday_impact = pd.read_csv('csv_files/idea_csv/df_holiday_impact.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a0ce63",
   "metadata": {},
   "source": [
    "#### Tax Return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec547b96",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1bf355ee",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.113541Z",
     "iopub.status.idle": "2025-06-26T22:10:14.113878Z",
     "shell.execute_reply": "2025-06-26T22:10:14.113746Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.113729Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_tax_return_train = df_walmart_train[[\"Date\"]].copy()\n",
    "df_tax_return_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a428b117",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.115529Z",
     "iopub.status.idle": "2025-06-26T22:10:14.115854Z",
     "shell.execute_reply": "2025-06-26T22:10:14.115743Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.115727Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "ramp_up_days   = 14 \n",
    "ramp_down_days = 42  \n",
    "\n",
    "def filing_deadline(year):\n",
    "    \"\"\"\n",
    "    IRS filing deadline April 15, bumped to Monday if on a weekend.\n",
    "    \"\"\"\n",
    "    d = date(year, 4, 15)\n",
    "    while d.weekday() >= 5:  # \n",
    "        d += timedelta(days=1)\n",
    "    return pd.Timestamp(d)\n",
    "\n",
    "\n",
    "def tax_return_weight(ts, ramp_up=ramp_up_days, ramp_down=ramp_down_days):\n",
    "    \"\"\"\n",
    "    Smooth raised-cosine weight:\n",
    "      • 0 before (deadline - ramp_up)\n",
    "      • ramps up from 0→1 over `ramp_up` days\n",
    "      • ramps down from 1→0 over `ramp_down` days\n",
    "      • 0 after (deadline + ramp_down)\n",
    "    \"\"\"\n",
    "    ts   = pd.Timestamp(ts).normalize()\n",
    "    peak = filing_deadline(ts.year)\n",
    "    start = peak - timedelta(days=ramp_up)\n",
    "    end   = peak + timedelta(days=ramp_down)\n",
    "\n",
    "    if ts < start or ts > end:\n",
    "        return 0.0\n",
    "\n",
    "    if ts <= peak:\n",
    "        # fraction of ramp-up completed [0…1]\n",
    "        x = (ts - start).days / ramp_up\n",
    "        # raised‐cosine from 0→1\n",
    "        return 0.5 * (1 - np.cos(np.pi * x))\n",
    "    else:\n",
    "        # fraction of ramp-down completed [0…1]\n",
    "        x = (ts - peak).days / ramp_down\n",
    "        # raised‐cosine from 1→0\n",
    "        return 0.5 * (1 + np.cos(np.pi * x))\n",
    "\n",
    "\n",
    "df_tax_return_train = df_walmart_train[['Date']].copy()\n",
    "df_tax_return_train['TaxReturnImpact'] = (\n",
    "    df_tax_return_train['Date']\n",
    "      .dt.normalize()\n",
    "      .map(tax_return_weight)\n",
    ")\n",
    "\n",
    "df_tax_return_train.to_csv('csv_files/idea_csv/df_tax_return_train.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3fafe35",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.116798Z",
     "iopub.status.idle": "2025-06-26T22:10:14.117193Z",
     "shell.execute_reply": "2025-06-26T22:10:14.117054Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.117036Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_unique = df_tax_return_train.drop_duplicates(subset='Date', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1dfd1022",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.120597Z",
     "iopub.status.idle": "2025-06-26T22:10:14.120893Z",
     "shell.execute_reply": "2025-06-26T22:10:14.120782Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.120769Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_tax_return_train = pd.read_csv('csv_files/idea_csv/df_tax_return_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f4f2ca",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31cd2010",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.122091Z",
     "iopub.status.idle": "2025-06-26T22:10:14.122349Z",
     "shell.execute_reply": "2025-06-26T22:10:14.12223Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.122218Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "ramp_up_days   = 14 \n",
    "ramp_down_days = 42  \n",
    "\n",
    "def filing_deadline(year):\n",
    "    \"\"\"\n",
    "    IRS filing deadline April 15, bumped to Monday if on a weekend.\n",
    "    \"\"\"\n",
    "    d = date(year, 4, 15)\n",
    "    while d.weekday() >= 5:\n",
    "        d += timedelta(days=1)\n",
    "    return pd.Timestamp(d)\n",
    "\n",
    "# ─── SMOOTH WEIGHT FUNCTION ───────────────────────────────\n",
    "def tax_return_weight(ts, ramp_up=ramp_up_days, ramp_down=ramp_down_days):\n",
    "    \"\"\"\n",
    "    Smooth raised-cosine weight:\n",
    "      • 0 before (deadline - ramp_up)\n",
    "      • ramps up from 0→1 over `ramp_up` days\n",
    "      • ramps down from 1→0 over `ramp_down` days\n",
    "      • 0 after (deadline + ramp_down)\n",
    "    \"\"\"\n",
    "    ts   = pd.Timestamp(ts).normalize()\n",
    "    peak = filing_deadline(ts.year)\n",
    "    start = peak - timedelta(days=ramp_up)\n",
    "    end   = peak + timedelta(days=ramp_down)\n",
    "\n",
    "    if ts < start or ts > end:\n",
    "        return 0.0\n",
    "\n",
    "    if ts <= peak:\n",
    "        # fraction of ramp-up completed [0…1]\n",
    "        x = (ts - start).days / ramp_up\n",
    "        # raised‐cosine from 0→1\n",
    "        return 0.5 * (1 - np.cos(np.pi * x))\n",
    "    else:\n",
    "        # fraction of ramp-down completed [0…1]\n",
    "        x = (ts - peak).days / ramp_down\n",
    "        # raised‐cosine from 1→0\n",
    "        return 0.5 * (1 + np.cos(np.pi * x))\n",
    "\n",
    "df_tax_return_test = df_walmart_test[['Date']].copy()\n",
    "df_tax_return_test['TaxReturnImpact'] = (\n",
    "    df_tax_return_test['Date']\n",
    "      .dt.normalize()\n",
    "      .map(tax_return_weight)\n",
    ")\n",
    "\n",
    "df_tax_return_test.to_csv('csv_files/idea_csv/df_tax_return_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de2931b9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.123652Z",
     "iopub.status.idle": "2025-06-26T22:10:14.123994Z",
     "shell.execute_reply": "2025-06-26T22:10:14.123846Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.123831Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_tax_return_test = pd.read_csv('csv_files/idea_csv/df_tax_return_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51bedab",
   "metadata": {},
   "source": [
    "#### Stores Types & Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06cccb9d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.127707Z",
     "iopub.status.idle": "2025-06-26T22:10:14.129062Z",
     "shell.execute_reply": "2025-06-26T22:10:14.128871Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.128848Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_walmart_train['Store']  = df_walmart_train['Store'].astype(str)\n",
    "df_walmart_stores['Store'] = df_walmart_stores['Store'].astype(str)\n",
    "\n",
    "# Merge the store metadata into your training DataFrame\n",
    "df_store_types_sizes = df_walmart_train.merge(\n",
    "    df_walmart_stores,     \n",
    "    on='Store',             \n",
    "    how='left',       \n",
    "    validate='many_to_one'  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "797265fe",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.130112Z",
     "iopub.status.idle": "2025-06-26T22:10:14.130417Z",
     "shell.execute_reply": "2025-06-26T22:10:14.130288Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.130265Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_store_types_sizes = df_store_types_sizes.loc[:, [\"Store\",\"Type\",\"Size\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ef73b4",
   "metadata": {},
   "source": [
    "#### Oil Price The U.S. domestic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e79e31d2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.133836Z",
     "iopub.status.idle": "2025-06-26T22:10:14.134165Z",
     "shell.execute_reply": "2025-06-26T22:10:14.134038Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.134022Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "start = \"2010-02-05\"\n",
    "end   = date.today().isoformat()\n",
    " \n",
    "df_us_oil_price = DataReader(\"DCOILWTICO\", \"fred\", start, end)\n",
    "\n",
    "wti_weekly = df_us_oil_price.resample(\"W-FRI\").mean().rename(\n",
    "    columns={\"DCOILWTICO\":\"WTI_Weekly_Mean_Price\"}\n",
    ")\n",
    "df_us_oil_price.to_csv('csv_files/idea_csv/df_us_oil_price.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6c47a64b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.135358Z",
     "iopub.status.idle": "2025-06-26T22:10:14.135715Z",
     "shell.execute_reply": "2025-06-26T22:10:14.135567Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.135551Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_us_oil_price = pd.read_csv('csv_files/idea_csv/df_us_oil_price.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78f1794",
   "metadata": {},
   "source": [
    "#### U.S. ISM Manufacturing PMI & ISM Services PMI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b0ba176",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.139348Z",
     "iopub.status.idle": "2025-06-26T22:10:14.139698Z",
     "shell.execute_reply": "2025-06-26T22:10:14.139582Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.139569Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "# Get columns names\n",
    "df_man = ak.macro_usa_ism_pmi()\n",
    "\n",
    "print(\"Columns in df_man:\", df_man.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dcad5ebe",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.140809Z",
     "iopub.status.idle": "2025-06-26T22:10:14.141103Z",
     "shell.execute_reply": "2025-06-26T22:10:14.140995Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.14098Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "START, END = \"2009-01-01\", \"2014-12-31\"\n",
    "\n",
    "df_man = ak.macro_usa_ism_pmi()\n",
    "\n",
    "df_man = df_man.rename(columns={\n",
    "    \"日期\": \"Date\",\n",
    "    \"今值\": \"ISM_Manufacturing_PMI\"\n",
    "})\n",
    "df_man[\"Date\"] = pd.to_datetime(df_man[\"Date\"], format=\"%Y-%m\")\n",
    "df_man = (\n",
    "    df_man.set_index(\"Date\")[[\"ISM_Manufacturing_PMI\"]]\n",
    "    .sort_index()\n",
    "    .loc[START:END]\n",
    ")\n",
    "\n",
    "df_svc = ak.macro_usa_ism_non_pmi()\n",
    "\n",
    "df_svc = df_svc.rename(columns={\n",
    "    \"日期\": \"Date\",\n",
    "    \"今值\": \"ISM_Services_PMI\"\n",
    "})\n",
    "df_svc[\"Date\"] = pd.to_datetime(df_svc[\"Date\"], format=\"%Y-%m\")\n",
    "df_svc = (\n",
    "    df_svc.set_index(\"Date\")[[\"ISM_Services_PMI\"]]\n",
    "    .sort_index()\n",
    "    .loc[START:END]\n",
    ")\n",
    "\n",
    "df_us_ism = df_man.join(df_svc, how=\"outer\")\n",
    "\n",
    "df_us_ism.to_csv('csv_files/idea_csv/df_us_ism.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bdcf123d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.142108Z",
     "iopub.status.idle": "2025-06-26T22:10:14.142513Z",
     "shell.execute_reply": "2025-06-26T22:10:14.142334Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.142316Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_us_ism = pd.read_csv('csv_files/idea_csv/df_us_ism.csv')\n",
    "df_us_ism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e29c85",
   "metadata": {},
   "source": [
    "#### US CPI Food & Beverages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d43223c8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.143891Z",
     "iopub.status.idle": "2025-06-26T22:10:14.144194Z",
     "shell.execute_reply": "2025-06-26T22:10:14.144084Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.144073Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "START, END = \"2009-01-01\", \"2014-12-31\"\n",
    "\n",
    "df_us_cpi_food = DataReader(\"CPIFABSL\", \"fred\", START, END)\n",
    "\n",
    "df_us_cpi_food.rename(columns={\"CPIFABSL\": \"CPI_Food_Beverages\"}, inplace=True)\n",
    "\n",
    "df_us_cpi_food = (\n",
    "    df_us_cpi_food[\"CPI_Food_Beverages\"]\n",
    "    .resample(\"W-FRI\")\n",
    "    .ffill()\n",
    "    .to_frame()\n",
    ")\n",
    "df_us_cpi_food.to_csv('csv_files/idea_csv/df_us_cpi_food.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "574fba58",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.145273Z",
     "iopub.status.idle": "2025-06-26T22:10:14.145752Z",
     "shell.execute_reply": "2025-06-26T22:10:14.14544Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.145424Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_us_cpi_food = pd.read_csv('csv_files/idea_csv/df_us_cpi_food.csv')\n",
    "df_us_cpi_food"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a76d45a",
   "metadata": {},
   "source": [
    "#### US CPI Shelter (Housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b7d7eb2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.147377Z",
     "iopub.status.idle": "2025-06-26T22:10:14.147693Z",
     "shell.execute_reply": "2025-06-26T22:10:14.147576Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.14756Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "START, END = \"2009-01-01\", \"2014-12-31\"\n",
    "\n",
    "df_us_cpi_shelter = DataReader(\"CUSR0000SAH1\", \"fred\", START, END)\n",
    "\n",
    "df_us_cpi_shelter.rename(columns={\"CUSR0000SAH1\": \"CPI_Shelter\"}, inplace=True)\n",
    "\n",
    "df_us_cpi_shelter = (\n",
    "    df_us_cpi_shelter[\"CPI_Shelter\"]\n",
    "      .resample(\"W-FRI\")\n",
    "      .ffill()            \n",
    "      .to_frame()       \n",
    ")\n",
    "\n",
    "df_us_cpi_shelter.to_csv('csv_files/idea_csv/df_us_cpi_shelter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ae792c64",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.148695Z",
     "iopub.status.idle": "2025-06-26T22:10:14.148994Z",
     "shell.execute_reply": "2025-06-26T22:10:14.14884Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.148826Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_us_cpi_shelter = pd.read_csv('csv_files/idea_csv/df_us_cpi_shelter.csv')\n",
    "df_us_cpi_shelter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84e0424",
   "metadata": {},
   "source": [
    "#### US CPI Medical Care\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "83ddcd95",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.150507Z",
     "iopub.status.idle": "2025-06-26T22:10:14.150816Z",
     "shell.execute_reply": "2025-06-26T22:10:14.150678Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.150662Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "START, END = \"2009-01-01\", \"2014-12-31\"\n",
    "\n",
    "df_us_cpi_med = DataReader(\"CPIMEDSL\", \"fred\", START, END)\n",
    "\n",
    "df_us_cpi_med.rename(columns={\"CPIMEDSL\": \"CPI_Medical_Care\"}, inplace=True)\n",
    "\n",
    "df_us_cpi_med = (\n",
    "    df_us_cpi_med[\"CPI_Medical_Care\"]\n",
    "      .resample(\"W-FRI\")   # calendar‐weeks ending Fridays\n",
    "      .ffill()             # carry each month’s CPI forward until the next release\n",
    "      .to_frame()\n",
    ")\n",
    "\n",
    "df_us_cpi_med.to_csv('csv_files/idea_csv/df_us_cpi_med.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a8a5cbec",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.152002Z",
     "iopub.status.idle": "2025-06-26T22:10:14.152294Z",
     "shell.execute_reply": "2025-06-26T22:10:14.152168Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.152154Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_us_cpi_med = pd.read_csv('csv_files/idea_csv/df_us_cpi_med.csv')\n",
    "df_us_cpi_med"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd3d247",
   "metadata": {},
   "source": [
    "#### US CPI Transportation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e1d82656",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.153339Z",
     "iopub.status.idle": "2025-06-26T22:10:14.153906Z",
     "shell.execute_reply": "2025-06-26T22:10:14.153755Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.153737Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "START, END = \"2009-01-01\", \"2014-12-31\"\n",
    "\n",
    "df_us_cpi_trans = DataReader(\"CPITRNSL\", \"fred\", START, END)\n",
    "\n",
    "df_us_cpi_trans.rename(columns={\"CPITRNSL\": \"CPI_Transportation\"}, inplace=True)\n",
    "\n",
    "df_us_cpi_trans = (\n",
    "    df_us_cpi_trans[\"CPI_Transportation\"]\n",
    "      .resample(\"W-FRI\")\n",
    "      .ffill()\n",
    "      .to_frame()\n",
    ")\n",
    "\n",
    "df_us_cpi_trans.to_csv('csv_files/idea_csv/df_us_cpi_trans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5095ed62",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.155182Z",
     "iopub.status.idle": "2025-06-26T22:10:14.155519Z",
     "shell.execute_reply": "2025-06-26T22:10:14.155357Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.155341Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_us_cpi_trans = pd.read_csv('csv_files/idea_csv/df_us_cpi_trans.csv')\n",
    "df_us_cpi_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66507566",
   "metadata": {},
   "source": [
    "#### PCE: US Healthcare Services\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4b7d3784",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.156493Z",
     "iopub.status.idle": "2025-06-26T22:10:14.156764Z",
     "shell.execute_reply": "2025-06-26T22:10:14.156652Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.156641Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "START, END = \"2009-01-01\", \"2014-12-31\"\n",
    "\n",
    "df_us_pce_health = DataReader(\"DHLCRC1Q027SBEA\", \"fred\", START, END)\n",
    "\n",
    "df_us_pce_health.rename(columns={\"DHLCRC1Q027SBEA\": \"PCE_Healthcare_Services\"}, inplace=True)\n",
    "\n",
    "df_us_pce_health = (\n",
    "    df_us_pce_health[\"PCE_Healthcare_Services\"]\n",
    "      .resample(\"W-FRI\")   \n",
    "      .ffill()      \n",
    "      .to_frame()\n",
    ")\n",
    "\n",
    "\n",
    "df_us_pce_health.to_csv('csv_files/idea_csv/df_us_pce_health.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7751d199",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.157901Z",
     "iopub.status.idle": "2025-06-26T22:10:14.158176Z",
     "shell.execute_reply": "2025-06-26T22:10:14.158042Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.158032Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_us_pce_health = pd.read_csv('csv_files/idea_csv/df_us_pce_health.csv')\n",
    "df_us_pce_health"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d4fd13",
   "metadata": {},
   "source": [
    "#### US ICSA (Jobless Claims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "601cfc27",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.159149Z",
     "iopub.status.idle": "2025-06-26T22:10:14.15949Z",
     "shell.execute_reply": "2025-06-26T22:10:14.159335Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.15932Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "START, END = \"2009-01-01\", \"2014-12-31\"\n",
    "\n",
    "\n",
    "df_us_icsa_jobless = DataReader(\"ICSA\", \"fred\", START, END)\n",
    "\n",
    "df_us_icsa_jobless.rename(columns={\"ICSA\": \"Weekly_Initial_Jobless_Claims\"}, inplace=True)\n",
    "\n",
    "df_us_icsa_jobless = (\n",
    "    df_us_icsa_jobless[\"Weekly_Initial_Jobless_Claims\"]\n",
    "      .resample(\"W-FRI\")  \n",
    "      .ffill()           \n",
    "      .to_frame()\n",
    ")\n",
    "\n",
    "df_us_icsa_jobless.to_csv('csv_files/idea_csv/df_us_icsa_jobless.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bb3cc0dc",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.160335Z",
     "iopub.status.idle": "2025-06-26T22:10:14.160639Z",
     "shell.execute_reply": "2025-06-26T22:10:14.160531Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.160516Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_us_icsa_jobless = pd.read_csv('csv_files/idea_csv/df_us_icsa_jobless.csv')\n",
    "df_us_icsa_jobless"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaab7ab",
   "metadata": {},
   "source": [
    "#### US Rail , Freight & Carloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1e18106c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.161207Z",
     "iopub.status.idle": "2025-06-26T22:10:14.161469Z",
     "shell.execute_reply": "2025-06-26T22:10:14.161336Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.161326Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "START, END = \"2009-01-01\", \"2014-12-31\"\n",
    "\n",
    "rail = DataReader(\"RAILFRTCARLOADS\", \"fred\", START, END)\n",
    "rail.rename(columns={\"RAILFRTCARLOADS\": \"Rail_Freight_Carloads\"}, inplace=True)\n",
    "\n",
    "rail_weekly = (\n",
    "    rail[\"Rail_Freight_Carloads\"]\n",
    "        .resample(\"W-FRI\")\n",
    "        .ffill()\n",
    "        .to_frame()\n",
    ")\n",
    "\n",
    "truck = DataReader(\"TRUCKD11\", \"fred\", START, END)\n",
    "truck.rename(columns={\"TRUCKD11\": \"Truck_Tonnage_Index\"}, inplace=True)\n",
    "\n",
    "truck_weekly = (\n",
    "    truck[\"Truck_Tonnage_Index\"]\n",
    "         .resample(\"W-FRI\")\n",
    "         .ffill()\n",
    "         .to_frame()\n",
    ")\n",
    "\n",
    "df_us_rail_freight_carloads = rail_weekly.join(truck_weekly, how=\"outer\")\n",
    "\n",
    "df_us_rail_freight_carloads.to_csv('csv_files/idea_csv/df_us_rail_freight_carloads.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "db603ad4",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.162373Z",
     "iopub.status.idle": "2025-06-26T22:10:14.162932Z",
     "shell.execute_reply": "2025-06-26T22:10:14.162747Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.162724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_us_rail_freight_carloads = pd.read_csv('csv_files/idea_csv/df_us_rail_freight_carloads.csv')\n",
    "df_us_rail_freight_carloads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0987caa",
   "metadata": {},
   "source": [
    "#### EU PMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6433ffd1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.164878Z",
     "iopub.status.idle": "2025-06-26T22:10:14.165142Z",
     "shell.execute_reply": "2025-06-26T22:10:14.165034Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.16502Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_eu = ak.macro_euro_manufacturing_pmi()\n",
    "\n",
    "print(df_eu.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "92723d01",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.166306Z",
     "iopub.status.idle": "2025-06-26T22:10:14.166606Z",
     "shell.execute_reply": "2025-06-26T22:10:14.166495Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.166485Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "START, END = \"2009-01-01\", \"2014-12-31\"\n",
    "\n",
    "df_eu_pmi = ak.macro_euro_manufacturing_pmi()\n",
    "\n",
    "df_eu_pmi = df_eu_pmi.rename(columns={\n",
    "    \"日期\": \"Date\",\n",
    "    \"今值\":  \"Euro_Manufacturing_PMI\"\n",
    "})\n",
    "df_eu_pmi[\"Date\"] = pd.to_datetime(df_eu_pmi[\"Date\"], format=\"%Y-%m\")\n",
    "\n",
    "df_eu_pmi = (\n",
    "    df_eu_pmi.set_index(\"Date\")[[\"Euro_Manufacturing_PMI\"]]\n",
    "              .sort_index()\n",
    "              .loc[START:END]\n",
    ")\n",
    "\n",
    "df_eu_pmi = (\n",
    "    df_eu_pmi[\"Euro_Manufacturing_PMI\"]\n",
    "      .resample(\"W-FRI\")\n",
    "      .ffill()\n",
    "      .to_frame()\n",
    ")\n",
    "df_eu_pmi.to_csv('csv_files/idea_csv/df_eu_pmi.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0842da7a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.167323Z",
     "iopub.status.idle": "2025-06-26T22:10:14.167601Z",
     "shell.execute_reply": "2025-06-26T22:10:14.167473Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.167463Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_eu_pmi = pd.read_csv('csv_files/idea_csv/df_eu_pmi.csv')\n",
    "df_eu_pmi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48f0bab",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d19ee0d3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.169066Z",
     "iopub.status.idle": "2025-06-26T22:10:14.169519Z",
     "shell.execute_reply": "2025-06-26T22:10:14.169323Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.169232Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train = df_walmart_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750503ef",
   "metadata": {},
   "source": [
    "### Data Cleaning - Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654597fd",
   "metadata": {},
   "source": [
    "#### SP 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0a154839",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.171312Z",
     "iopub.status.idle": "2025-06-26T22:10:14.171636Z",
     "shell.execute_reply": "2025-06-26T22:10:14.171513Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.171499Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_sp500['Date'] = pd.to_datetime(df_sp500[\"Date\"], errors=\"raise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4adf2de3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.173728Z",
     "iopub.status.idle": "2025-06-26T22:10:14.174046Z",
     "shell.execute_reply": "2025-06-26T22:10:14.173898Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.173884Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_sp500.rename(columns={\n",
    "    'SPX_Weekly_Mean_Close': 'SP500_Weekly_Mean_Close'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "048a5345",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.175969Z",
     "iopub.status.idle": "2025-06-26T22:10:14.176314Z",
     "shell.execute_reply": "2025-06-26T22:10:14.176145Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.176129Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_merged = df_wm_train.merge(\n",
    "    df_sp500,\n",
    "    on=\"Date\",\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2f21dc64",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.18016Z",
     "iopub.status.idle": "2025-06-26T22:10:14.180546Z",
     "shell.execute_reply": "2025-06-26T22:10:14.180407Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.180368Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train = df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd6d60b",
   "metadata": {},
   "source": [
    "#### Walmart Stock Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f6f51118",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.183541Z",
     "iopub.status.idle": "2025-06-26T22:10:14.183964Z",
     "shell.execute_reply": "2025-06-26T22:10:14.183801Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.183783Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_walmart_stock['Date'] = pd.to_datetime(df_walmart_stock[\"Date\"], errors=\"raise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e79b05d6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.184664Z",
     "iopub.status.idle": "2025-06-26T22:10:14.185105Z",
     "shell.execute_reply": "2025-06-26T22:10:14.184841Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.184826Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_merged = df_wm_train.merge(\n",
    "    df_walmart_stock,\n",
    "    on=\"Date\",\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a8b85d47",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.186207Z",
     "iopub.status.idle": "2025-06-26T22:10:14.186538Z",
     "shell.execute_reply": "2025-06-26T22:10:14.186409Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.186374Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train = df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8ce570",
   "metadata": {},
   "source": [
    "#### External Logistic companies Walmart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "09f2840c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.191532Z",
     "iopub.status.idle": "2025-06-26T22:10:14.19187Z",
     "shell.execute_reply": "2025-06-26T22:10:14.191716Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.1917Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_logistics['Date'] = pd.to_datetime(df_logistics[\"Date\"], errors=\"raise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8e79c62f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.193019Z",
     "iopub.status.idle": "2025-06-26T22:10:14.193244Z",
     "shell.execute_reply": "2025-06-26T22:10:14.193146Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.193136Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_merged = df_wm_train.merge(\n",
    "    df_logistics,\n",
    "    on=\"Date\",\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "43a70cb4",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.194008Z",
     "iopub.status.idle": "2025-06-26T22:10:14.194339Z",
     "shell.execute_reply": "2025-06-26T22:10:14.194191Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.194176Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train = df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc856701",
   "metadata": {},
   "source": [
    "#### Official China PMI (Caixin PMI only starts in 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0a0aa189",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.197921Z",
     "iopub.status.idle": "2025-06-26T22:10:14.198203Z",
     "shell.execute_reply": "2025-06-26T22:10:14.198059Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.198046Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_pmi_china.drop(columns=['Official_Manufacturing_PMI_YoY', 'Official_Services_PMI_YoY'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "511d53b8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.198944Z",
     "iopub.status.idle": "2025-06-26T22:10:14.199193Z",
     "shell.execute_reply": "2025-06-26T22:10:14.199087Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.199077Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_pmi_china.rename(columns={\n",
    "    'Official_Manufacturing_PMI': 'China_Official_Manufacturing_PMI',\n",
    "    'Official_Services_PMI': 'China_Official_Services_PMI'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "85bfa335",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.199782Z",
     "iopub.status.idle": "2025-06-26T22:10:14.199997Z",
     "shell.execute_reply": "2025-06-26T22:10:14.199906Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.199897Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_pmi_china['Date'] = pd.to_datetime(df_pmi_china[\"Date\"], errors=\"raise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9d829f1a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.200968Z",
     "iopub.status.idle": "2025-06-26T22:10:14.201238Z",
     "shell.execute_reply": "2025-06-26T22:10:14.201101Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.201087Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train['YM'] = df_wm_train['Date'].dt.to_period('M')\n",
    "df_pmi_china    ['YM'] = df_pmi_china    ['Date'].dt.to_period('M')\n",
    "\n",
    "df_merged = df_wm_train.merge(\n",
    "    df_pmi_china[['YM','China_Official_Manufacturing_PMI','China_Official_Services_PMI']],\n",
    "    on='YM',\n",
    "    how='left'\n",
    ").drop(columns='YM')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5035e219",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.203128Z",
     "iopub.status.idle": "2025-06-26T22:10:14.203541Z",
     "shell.execute_reply": "2025-06-26T22:10:14.203343Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.20332Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train = df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55872d6",
   "metadata": {},
   "source": [
    "#### PCE USA (Personal Consumption Expenditures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9a6b48f4",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.206335Z",
     "iopub.status.idle": "2025-06-26T22:10:14.206681Z",
     "shell.execute_reply": "2025-06-26T22:10:14.206532Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.206517Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_pce.rename(columns={\n",
    "    'Personal_Consumption_Expenditures': 'US_Personal_Consumption_Expenditures'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cfa5fa96",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.2077Z",
     "iopub.status.idle": "2025-06-26T22:10:14.208024Z",
     "shell.execute_reply": "2025-06-26T22:10:14.207877Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.207863Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_pce['DATE'] = pd.to_datetime(df_pce[\"DATE\"], errors=\"raise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e53bf8ed",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.208898Z",
     "iopub.status.idle": "2025-06-26T22:10:14.209217Z",
     "shell.execute_reply": "2025-06-26T22:10:14.209069Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.209055Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train['YM'] = df_wm_train['Date'].dt.to_period('M')\n",
    "df_pce    ['YM'] = df_pce    ['DATE'].dt.to_period('M')\n",
    "\n",
    "df_merged = df_wm_train.merge(\n",
    "    df_pce[['YM','US_Personal_Consumption_Expenditures']],\n",
    "    on='YM',\n",
    "    how='left'\n",
    ").drop(columns='YM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b654ea5b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.210855Z",
     "iopub.status.idle": "2025-06-26T22:10:14.211107Z",
     "shell.execute_reply": "2025-06-26T22:10:14.211006Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.210995Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train = df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e063e49c",
   "metadata": {},
   "source": [
    "#### Interest Rates USA (Fed Funds Rate & Tbill 3 Months Yield)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a49657aa",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.213027Z",
     "iopub.status.idle": "2025-06-26T22:10:14.213292Z",
     "shell.execute_reply": "2025-06-26T22:10:14.21316Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.213151Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_interest_rates['DATE'] = pd.to_datetime(df_interest_rates[\"DATE\"], errors=\"raise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f88706b9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.214354Z",
     "iopub.status.idle": "2025-06-26T22:10:14.214817Z",
     "shell.execute_reply": "2025-06-26T22:10:14.214591Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.214575Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_interest_rates.rename(columns={\n",
    "    'Fed_Funds_Rate': 'US_Fed_Funds_Rate',\n",
    "    'TBill_3mo_Yield': 'US_TBill_3mo_Yield',\n",
    "    'DATE': 'Date'\n",
    "\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d563b328",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.215928Z",
     "iopub.status.idle": "2025-06-26T22:10:14.216374Z",
     "shell.execute_reply": "2025-06-26T22:10:14.216237Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.216226Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train = df_wm_train.sort_values('Date')\n",
    "df_interest_rates = df_interest_rates.sort_values('Date')\n",
    "\n",
    "df_merged = df_wm_train.merge(\n",
    "    df_interest_rates[['Date','US_TBill_3mo_Yield','US_Fed_Funds_Rate']],\n",
    "    on='Date',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_merged['US_Fed_Funds_Rate'] = df_merged['US_Fed_Funds_Rate'].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7f55aee9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.217649Z",
     "iopub.status.idle": "2025-06-26T22:10:14.217917Z",
     "shell.execute_reply": "2025-06-26T22:10:14.21779Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.217778Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train = df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f574bc",
   "metadata": {},
   "source": [
    "#### CCI USA (Consumer Confidence Index) from University of Michigan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2f3db3d5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.219869Z",
     "iopub.status.idle": "2025-06-26T22:10:14.220088Z",
     "shell.execute_reply": "2025-06-26T22:10:14.219993Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.219983Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_us_cci['Date']   = pd.to_datetime(df_us_cci['DATE'])\n",
    "df_us_cci = df_us_cci.sort_values('Date')\n",
    "\n",
    "df_merged = pd.merge_asof(\n",
    "    df_wm_train.sort_values('Date'),\n",
    "    df_us_cci[['Date','Consumer_Sentiment_UMich']],\n",
    "    on='Date',\n",
    "    direction='backward'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5444d26d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.221301Z",
     "iopub.status.idle": "2025-06-26T22:10:14.221767Z",
     "shell.execute_reply": "2025-06-26T22:10:14.221622Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.221607Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train = df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc5cbab",
   "metadata": {},
   "source": [
    "#### U.S.A Advance Retail Sales: Retail Trade and Food Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "98d07682",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.224423Z",
     "iopub.status.idle": "2025-06-26T22:10:14.224701Z",
     "shell.execute_reply": "2025-06-26T22:10:14.224595Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.224581Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_us_retail['Date']   = pd.to_datetime(df_us_retail['DATE'])\n",
    "df_us_retail = df_us_retail.sort_values('Date')\n",
    "\n",
    "df_merged = pd.merge_asof(\n",
    "    df_wm_train.sort_values('Date'),\n",
    "    df_us_retail[['Date','Retail_Sales_Retail_and_Food_Services_USA']],\n",
    "    on='Date',\n",
    "    direction='backward'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6bdfb761",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.225346Z",
     "iopub.status.idle": "2025-06-26T22:10:14.225915Z",
     "shell.execute_reply": "2025-06-26T22:10:14.225709Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.225683Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train = df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8a9ac9",
   "metadata": {},
   "source": [
    "#### Exchange Rates (China, Mexico, Canada, India, Vietnam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7fed900a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.230232Z",
     "iopub.status.idle": "2025-06-26T22:10:14.230696Z",
     "shell.execute_reply": "2025-06-26T22:10:14.230508Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.23049Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_fx.rename(columns={\n",
    "    'Unnamed: 0': 'Date',\n",
    "    \"('VND_per_USD', 'USDVND=X')\": 'VND_per_USD'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7a19a385",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.232127Z",
     "iopub.status.idle": "2025-06-26T22:10:14.232532Z",
     "shell.execute_reply": "2025-06-26T22:10:14.232341Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.232324Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_fx['Date']   = pd.to_datetime(df_fx['Date'])\n",
    "df_fx = df_fx.sort_values('Date')\n",
    "\n",
    "df_merged = pd.merge_asof(\n",
    "    df_wm_train.sort_values('Date'),\n",
    "    df_fx[['Date','CNY_per_USD', 'MXN_per_USD','CAD_per_USD','INR_per_USD','VND_per_USD']],\n",
    "    on='Date',\n",
    "    direction='backward'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3893577f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.233612Z",
     "iopub.status.idle": "2025-06-26T22:10:14.23393Z",
     "shell.execute_reply": "2025-06-26T22:10:14.233776Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.233761Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train = df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5457db",
   "metadata": {},
   "source": [
    "#### US External Tax Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7e02ca28",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.236467Z",
     "iopub.status.idle": "2025-06-26T22:10:14.236755Z",
     "shell.execute_reply": "2025-06-26T22:10:14.236647Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.236632Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_us_tariff.rename(columns={\n",
    "    'Canada': 'US_TAX_Canada',\n",
    "    'China': 'US_TAX_China',\n",
    "    'India': 'US_TAX_India',\n",
    "    'Mexico': 'US_TAX_Mexico',\n",
    "    'Viet Nam': 'US_TAX_Vietnam'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "316c820d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.237561Z",
     "iopub.status.idle": "2025-06-26T22:10:14.237778Z",
     "shell.execute_reply": "2025-06-26T22:10:14.237684Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.237674Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "# list of tariff columns\n",
    "tariff_cols = [\n",
    "    'US_TAX_Canada',\n",
    "    'US_TAX_China',\n",
    "    'US_TAX_India',\n",
    "    'US_TAX_Mexico',\n",
    "    'US_TAX_Vietnam'\n",
    "]\n",
    "\n",
    "# 1) prepare the dates\n",
    "df_wm_train['Date']      = pd.to_datetime(df_wm_train['Date'])\n",
    "df_us_tariff['Date']     = pd.date_range(\n",
    "    '2001-01-01',\n",
    "    periods=len(df_us_tariff),\n",
    "    freq='YS'\n",
    ")\n",
    "\n",
    "# 2) sort & merge_asof, then forward-fill tariffs\n",
    "df_merged = (\n",
    "    pd.merge_asof(\n",
    "        df_wm_train.sort_values('Date'),\n",
    "        df_us_tariff[['Date'] + tariff_cols].sort_values('Date'),\n",
    "        on='Date',\n",
    "        direction='backward'\n",
    "    )\n",
    "    .assign(**{col: lambda d, col=col: d[col].ffill() for col in tariff_cols})\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "67456ecb",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.239221Z",
     "iopub.status.idle": "2025-06-26T22:10:14.239557Z",
     "shell.execute_reply": "2025-06-26T22:10:14.239434Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.239419Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_unique = df_merged.drop_duplicates(subset='Date', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a7d9125c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.240933Z",
     "iopub.status.idle": "2025-06-26T22:10:14.241264Z",
     "shell.execute_reply": "2025-06-26T22:10:14.241114Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.2411Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train = df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23031f73",
   "metadata": {},
   "source": [
    "#### Holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "36f24b19",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.245226Z",
     "iopub.status.idle": "2025-06-26T22:10:14.245594Z",
     "shell.execute_reply": "2025-06-26T22:10:14.245425Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.245409Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_holiday_impact['Date'] = pd.to_datetime(df_holiday_impact['Date'])\n",
    "\n",
    "df_merged = pd.merge_asof(\n",
    "    df_wm_train.sort_values('Date'),\n",
    "    df_holiday_impact[['Date','HolidayImpact']].sort_values('Date'),\n",
    "    on='Date',\n",
    "    direction='backward'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "251f3912",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.246531Z",
     "iopub.status.idle": "2025-06-26T22:10:14.246856Z",
     "shell.execute_reply": "2025-06-26T22:10:14.246705Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.24669Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train = df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "347f09e6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.249017Z",
     "iopub.status.idle": "2025-06-26T22:10:14.24936Z",
     "shell.execute_reply": "2025-06-26T22:10:14.24922Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.249205Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "#  make sure both Date columns are datetime at midnight\n",
    "df_us_holidays['Date'] = pd.to_datetime(df_us_holidays['Date']).dt.normalize()\n",
    "df_merged       ['Date'] = pd.to_datetime(df_merged       ['Date']).dt.normalize()\n",
    "\n",
    "# 2. compute each holiday’s “week_end” Friday (weekday=4)\n",
    "df_us_holidays['week_end'] = (\n",
    "    df_us_holidays['Date']\n",
    "  + pd.to_timedelta((4 - df_us_holidays['Date'].dt.weekday) % 7, unit='D')\n",
    ")\n",
    "\n",
    "#  build lookup: week_end → joined holiday names\n",
    "df_holiday_names = (\n",
    "    df_us_holidays\n",
    "      .groupby('week_end', as_index=False)['Holiday']\n",
    "      .agg(lambda names: ', '.join(names))\n",
    "      .rename(columns={'week_end':'Date', 'Holiday':'Holiday_Name'})\n",
    ")\n",
    "\n",
    "#  merge it in\n",
    "df_merged = df_merged.merge(df_holiday_names, on='Date', how='left')\n",
    "\n",
    "#  for weeks without a holiday, fill in “No Holiday”\n",
    "df_merged['Holiday_Name'] = df_merged['Holiday_Name'].fillna('No Holiday')\n",
    "\n",
    "# recompute your flag if you like:\n",
    "df_merged['IsHoliday'] = df_merged['Holiday_Name'] != 'No Holiday'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "348b04c5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.251967Z",
     "iopub.status.idle": "2025-06-26T22:10:14.252482Z",
     "shell.execute_reply": "2025-06-26T22:10:14.252171Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.252155Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_unique = df_merged.drop_duplicates(subset='Date', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0aaa92fc",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.253495Z",
     "iopub.status.idle": "2025-06-26T22:10:14.253861Z",
     "shell.execute_reply": "2025-06-26T22:10:14.253732Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.253712Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train = df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a784bf",
   "metadata": {},
   "source": [
    "#### Tax Return (Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e31b4d53",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.25735Z",
     "iopub.status.idle": "2025-06-26T22:10:14.257614Z",
     "shell.execute_reply": "2025-06-26T22:10:14.257514Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.257503Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_tax_return_train.rename(columns={\n",
    "    'TaxReturnImpact': 'US_Tax_Return'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "57759c75",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.259209Z",
     "iopub.status.idle": "2025-06-26T22:10:14.259545Z",
     "shell.execute_reply": "2025-06-26T22:10:14.259414Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.259398Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_tax_return_train['Date']   = pd.to_datetime(df_tax_return_train['Date'])\n",
    "df_tax_return_train = df_tax_return_train.sort_values('Date')\n",
    "\n",
    "df_merged = pd.merge_asof(\n",
    "    df_wm_train.sort_values('Date'),\n",
    "    df_tax_return_train[['Date','US_Tax_Return']],\n",
    "    on='Date',\n",
    "    direction='backward'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1ec11622",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.260013Z",
     "iopub.status.idle": "2025-06-26T22:10:14.260252Z",
     "shell.execute_reply": "2025-06-26T22:10:14.260148Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.260134Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_unique = df_merged.drop_duplicates(subset='Date', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d9f6580a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.261942Z",
     "iopub.status.idle": "2025-06-26T22:10:14.26225Z",
     "shell.execute_reply": "2025-06-26T22:10:14.262095Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.262081Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train = df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaca538",
   "metadata": {},
   "source": [
    "#### Stores Types & Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c80754b3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.268294Z",
     "iopub.status.idle": "2025-06-26T22:10:14.268591Z",
     "shell.execute_reply": "2025-06-26T22:10:14.268476Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.268461Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_store_types_sizes['Store'] = df_store_types_sizes['Store'].astype(int)\n",
    "df_wm_train['Store'] = df_wm_train['Store'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d9f75a78",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.270475Z",
     "iopub.status.idle": "2025-06-26T22:10:14.270828Z",
     "shell.execute_reply": "2025-06-26T22:10:14.27067Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.270654Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_store_info = df_store_types_sizes.drop_duplicates(subset='Store')\n",
    "\n",
    "main_df = df_wm_train.merge(df_store_info, on='Store', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1ec39f6f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.272722Z",
     "iopub.status.idle": "2025-06-26T22:10:14.273046Z",
     "shell.execute_reply": "2025-06-26T22:10:14.272903Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.272887Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train = main_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712ff2a7",
   "metadata": {},
   "source": [
    "#### Oil Price The U.S. domestic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b2fb65ec",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.277463Z",
     "iopub.status.idle": "2025-06-26T22:10:14.277812Z",
     "shell.execute_reply": "2025-06-26T22:10:14.277662Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.277647Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_us_oil_price['DATE'] = pd.to_datetime(df_us_oil_price['DATE'])\n",
    "df_us_oil_price = df_us_oil_price.set_index('DATE')\n",
    "\n",
    "# Interpolate missing values\n",
    "df_us_oil_price['DCOILWTICO'] = df_us_oil_price['DCOILWTICO'].interpolate(\n",
    "    method='linear',\n",
    "    limit_direction='both',\n",
    "    limit_area='inside'\n",
    ")\n",
    "\n",
    "df_us_oil_price = df_us_oil_price.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "33c8e9fe",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.279371Z",
     "iopub.status.idle": "2025-06-26T22:10:14.279776Z",
     "shell.execute_reply": "2025-06-26T22:10:14.279609Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.279593Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_us_oil_price = df_us_oil_price.rename(columns={'DATE': 'Date'})\n",
    "\n",
    "df_merged = df_wm_train.merge(df_us_oil_price[['Date', 'DCOILWTICO']], on='Date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "062736d6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.281256Z",
     "iopub.status.idle": "2025-06-26T22:10:14.281646Z",
     "shell.execute_reply": "2025-06-26T22:10:14.281488Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.281471Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_unique = df_merged.drop_duplicates(subset='Date', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b8e1c9c7",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.282951Z",
     "iopub.status.idle": "2025-06-26T22:10:14.283294Z",
     "shell.execute_reply": "2025-06-26T22:10:14.283121Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.283111Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train = df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6361e351",
   "metadata": {},
   "source": [
    "#### U.S. ISM Manufacturing PMI & ISM Services PMI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6f3497e6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.28665Z",
     "iopub.status.idle": "2025-06-26T22:10:14.28692Z",
     "shell.execute_reply": "2025-06-26T22:10:14.286819Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.286808Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_us_ism['Date'] = pd.to_datetime(df_us_ism['Date'])\n",
    "df_us_ism = df_us_ism.set_index('Date')\n",
    "\n",
    "# Interpolate missing values\n",
    "df_us_ism['ISM_Manufacturing_PMI'] = df_us_ism['ISM_Manufacturing_PMI'].interpolate(\n",
    "    method='linear',\n",
    "    limit_direction='both',\n",
    "    limit_area='inside'\n",
    ")\n",
    "df_us_ism['ISM_Services_PMI'] = df_us_ism['ISM_Services_PMI'].interpolate(\n",
    "    method='linear',\n",
    "    limit_direction='both',\n",
    "    limit_area='inside'\n",
    ")\n",
    "\n",
    "\n",
    "df_us_ism = df_us_ism.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "51064e60",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.288884Z",
     "iopub.status.idle": "2025-06-26T22:10:14.289556Z",
     "shell.execute_reply": "2025-06-26T22:10:14.289336Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.289313Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_merged = pd.merge_asof(\n",
    "    df_wm_train.sort_values('Date'),\n",
    "    df_us_ism[['Date','ISM_Manufacturing_PMI','ISM_Services_PMI']],\n",
    "    on='Date',\n",
    "    direction='backward'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f9170d54",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.291347Z",
     "iopub.status.idle": "2025-06-26T22:10:14.291682Z",
     "shell.execute_reply": "2025-06-26T22:10:14.291572Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.291559Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_unique = df_merged.drop_duplicates(subset='Date', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d945176c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.292731Z",
     "iopub.status.idle": "2025-06-26T22:10:14.293056Z",
     "shell.execute_reply": "2025-06-26T22:10:14.29292Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.292905Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train = df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3b695a",
   "metadata": {},
   "source": [
    "#### US CPI Food & Beverages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "75d615af",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.29684Z",
     "iopub.status.idle": "2025-06-26T22:10:14.297116Z",
     "shell.execute_reply": "2025-06-26T22:10:14.296994Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.296983Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_us_cpi_food = df_us_cpi_food.rename(columns={'DATE': 'Date'})\n",
    "df_us_cpi_food['Date'] = pd.to_datetime(df_us_cpi_food['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7d48089b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.298954Z",
     "iopub.status.idle": "2025-06-26T22:10:14.299308Z",
     "shell.execute_reply": "2025-06-26T22:10:14.299142Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.299127Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_merged = pd.merge_asof(\n",
    "    df_wm_train.sort_values('Date'),\n",
    "    df_us_cpi_food[['Date','CPI_Food_Beverages']],\n",
    "    on='Date',\n",
    "    direction='backward'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4b428242",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.300369Z",
     "iopub.status.idle": "2025-06-26T22:10:14.300719Z",
     "shell.execute_reply": "2025-06-26T22:10:14.300569Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.300554Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_unique = df_merged.drop_duplicates(subset='Date', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e5561f4f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.301815Z",
     "iopub.status.idle": "2025-06-26T22:10:14.302148Z",
     "shell.execute_reply": "2025-06-26T22:10:14.302Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.301985Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train = df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ea0b9d",
   "metadata": {},
   "source": [
    "#### US CPI Shelter (Housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c31e80fe",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.307154Z",
     "iopub.status.idle": "2025-06-26T22:10:14.307545Z",
     "shell.execute_reply": "2025-06-26T22:10:14.307369Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.307353Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_us_cpi_shelter = df_us_cpi_shelter.rename(columns={'DATE': 'Date'})\n",
    "df_us_cpi_shelter['Date'] = pd.to_datetime(df_us_cpi_shelter['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "06b03902",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.308901Z",
     "iopub.status.idle": "2025-06-26T22:10:14.309264Z",
     "shell.execute_reply": "2025-06-26T22:10:14.309095Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.30908Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_merged = pd.merge_asof(\n",
    "    df_wm_train.sort_values('Date'),\n",
    "    df_us_cpi_shelter[['Date','CPI_Shelter']],\n",
    "    on='Date',\n",
    "    direction='backward'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "437f9582",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.310346Z",
     "iopub.status.idle": "2025-06-26T22:10:14.310714Z",
     "shell.execute_reply": "2025-06-26T22:10:14.310557Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.310541Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_unique = df_merged.drop_duplicates(subset='Date', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5bcb6f13",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.312299Z",
     "iopub.status.idle": "2025-06-26T22:10:14.312679Z",
     "shell.execute_reply": "2025-06-26T22:10:14.312515Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.312498Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train = df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0e04df",
   "metadata": {},
   "source": [
    "#### US CPI Medical Care"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8250753e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.31702Z",
     "iopub.status.idle": "2025-06-26T22:10:14.317378Z",
     "shell.execute_reply": "2025-06-26T22:10:14.317236Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.31722Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_us_cpi_med = df_us_cpi_med.rename(columns={'DATE': 'Date'})\n",
    "df_us_cpi_med['Date'] = pd.to_datetime(df_us_cpi_med['Date'])\n",
    "\n",
    "df_merged = pd.merge_asof(\n",
    "    df_wm_train.sort_values('Date'),\n",
    "    df_us_cpi_med[['Date','CPI_Medical_Care']],\n",
    "    on='Date',\n",
    "    direction='backward'\n",
    ")\n",
    "\n",
    "df_unique = df_merged.drop_duplicates(subset='Date', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3ea8fa51",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.318351Z",
     "iopub.status.idle": "2025-06-26T22:10:14.31866Z",
     "shell.execute_reply": "2025-06-26T22:10:14.318551Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.318535Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train = df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c42970",
   "metadata": {},
   "source": [
    "#### US CPI Transportation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "051daf3e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.323246Z",
     "iopub.status.idle": "2025-06-26T22:10:14.323697Z",
     "shell.execute_reply": "2025-06-26T22:10:14.323555Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.323534Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_us_cpi_trans = df_us_cpi_trans.rename(columns={'DATE': 'Date'})\n",
    "df_us_cpi_trans['Date'] = pd.to_datetime(df_us_cpi_trans['Date'])\n",
    "\n",
    "df_merged = pd.merge_asof(\n",
    "    df_wm_train.sort_values('Date'),\n",
    "    df_us_cpi_trans[['Date','CPI_Transportation']],\n",
    "    on='Date',\n",
    "    direction='backward'\n",
    ")\n",
    "\n",
    "df_unique = df_merged.drop_duplicates(subset='Date', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "24d144f9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.324991Z",
     "iopub.status.idle": "2025-06-26T22:10:14.325253Z",
     "shell.execute_reply": "2025-06-26T22:10:14.325139Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.325129Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train = df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a0202b",
   "metadata": {},
   "source": [
    "#### PCE: US Healthcare Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a7a9a492",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.330935Z",
     "iopub.status.idle": "2025-06-26T22:10:14.331538Z",
     "shell.execute_reply": "2025-06-26T22:10:14.331277Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.331246Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_us_pce_health = df_us_pce_health.rename(columns={'DATE': 'Date'})\n",
    "df_us_pce_health['Date'] = pd.to_datetime(df_us_pce_health['Date'])\n",
    "\n",
    "df_merged = pd.merge_asof(\n",
    "    df_wm_train.sort_values('Date'),\n",
    "    df_us_pce_health[['Date','PCE_Healthcare_Services']],\n",
    "    on='Date',\n",
    "    direction='backward'\n",
    ")\n",
    "\n",
    "df_unique = df_merged.drop_duplicates(subset='Date', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "13326b19",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.333101Z",
     "iopub.status.idle": "2025-06-26T22:10:14.333374Z",
     "shell.execute_reply": "2025-06-26T22:10:14.333261Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.33325Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train = df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8860384",
   "metadata": {},
   "source": [
    "#### US ICSA (Jobless Claims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "25fd7cf4",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.33762Z",
     "iopub.status.idle": "2025-06-26T22:10:14.338292Z",
     "shell.execute_reply": "2025-06-26T22:10:14.338149Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.338133Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_us_icsa_jobless = df_us_icsa_jobless.rename(columns={'DATE': 'Date'})\n",
    "df_us_icsa_jobless['Date'] = pd.to_datetime(df_us_icsa_jobless['Date'])\n",
    "\n",
    "df_merged = pd.merge_asof(\n",
    "    df_wm_train.sort_values('Date'),\n",
    "    df_us_icsa_jobless[['Date','Weekly_Initial_Jobless_Claims']],\n",
    "    on='Date',\n",
    "    direction='backward'\n",
    ")\n",
    "\n",
    "df_unique = df_merged.drop_duplicates(subset='Date', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9a643ebc",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.339427Z",
     "iopub.status.idle": "2025-06-26T22:10:14.339715Z",
     "shell.execute_reply": "2025-06-26T22:10:14.339603Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.339588Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train = df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55f1d38",
   "metadata": {},
   "source": [
    "#### US Rail , Freight & Carloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fb105590",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.34377Z",
     "iopub.status.idle": "2025-06-26T22:10:14.344058Z",
     "shell.execute_reply": "2025-06-26T22:10:14.343953Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.343939Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_us_rail_freight_carloads = df_us_rail_freight_carloads.rename(columns={'DATE': 'Date'})\n",
    "df_us_rail_freight_carloads['Date'] = pd.to_datetime(df_us_rail_freight_carloads['Date'])\n",
    "\n",
    "df_merged = pd.merge_asof(\n",
    "    df_wm_train.sort_values('Date'),\n",
    "    df_us_rail_freight_carloads[['Date','Rail_Freight_Carloads','Truck_Tonnage_Index']],\n",
    "    on='Date',\n",
    "    direction='backward'\n",
    ")\n",
    "\n",
    "df_unique = df_merged.drop_duplicates(subset='Date', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0aa8f6d5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.345092Z",
     "iopub.status.idle": "2025-06-26T22:10:14.345363Z",
     "shell.execute_reply": "2025-06-26T22:10:14.345256Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.345246Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train = df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8b0772",
   "metadata": {},
   "source": [
    "#### EU PMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "048d1001",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.351085Z",
     "iopub.status.idle": "2025-06-26T22:10:14.351682Z",
     "shell.execute_reply": "2025-06-26T22:10:14.351501Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.351484Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_eu_pmi['Date'] = pd.to_datetime(df_eu_pmi['Date'])\n",
    "\n",
    "df_merged = pd.merge_asof(\n",
    "    df_wm_train.sort_values('Date'),\n",
    "    df_eu_pmi[['Date','Euro_Manufacturing_PMI']],\n",
    "    on='Date',\n",
    "    direction='backward'\n",
    ")\n",
    "\n",
    "df_unique = df_merged.drop_duplicates(subset='Date', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f354341b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.359425Z",
     "iopub.status.idle": "2025-06-26T22:10:14.360017Z",
     "shell.execute_reply": "2025-06-26T22:10:14.359836Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.359815Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train = df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe9775b",
   "metadata": {},
   "source": [
    "#### Walmart Promotion Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b3e21d82",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.363219Z",
     "iopub.status.idle": "2025-06-26T22:10:14.363568Z",
     "shell.execute_reply": "2025-06-26T22:10:14.363403Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.363373Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_merged = df_wm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ec848b46",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.372954Z",
     "iopub.status.idle": "2025-06-26T22:10:14.373277Z",
     "shell.execute_reply": "2025-06-26T22:10:14.373165Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.373152Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "# — make sure both date columns are true datetimes —\n",
    "df_merged['Date']           = pd.to_datetime(df_merged['Date'])\n",
    "df_walmart_features['Date'] = pd.to_datetime(df_walmart_features['Date'])\n",
    "\n",
    "# — pick just the columns you need from df_walmart_features —\n",
    "md_cols = ['Store','Date','MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5']\n",
    "\n",
    "# — left-merge so every (store,dept,date) in df_merged picks up that store's markdowns for that week —\n",
    "df_out = df_merged.merge(\n",
    "    df_walmart_features[md_cols],\n",
    "    on=['Store','Date'],\n",
    "    how='left'\n",
    ")\n",
    "df_merged = df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1c90a926",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.374116Z",
     "iopub.status.idle": "2025-06-26T22:10:14.374449Z",
     "shell.execute_reply": "2025-06-26T22:10:14.374315Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.374303Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_unique = df_merged.drop_duplicates(subset='Date', keep='first')\n",
    "df_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e4e1eb2b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.3758Z",
     "iopub.status.idle": "2025-06-26T22:10:14.376072Z",
     "shell.execute_reply": "2025-06-26T22:10:14.375947Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.375936Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train = df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9998a599",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe0b5cb",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8eff0d",
   "metadata": {},
   "source": [
    "#### Columns Renaming Reorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6c828107",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.378307Z",
     "iopub.status.idle": "2025-06-26T22:10:14.37859Z",
     "shell.execute_reply": "2025-06-26T22:10:14.378484Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.378473Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "# lowercase all columns\n",
    "df_merged.columns = df_merged.columns.str.lower()\n",
    "\n",
    "# define new order in lowercase, with markdowns at the end\n",
    "new_order = [\n",
    "    # identifiers & target\n",
    "    'date', 'store', 'type', 'size', 'dept', 'weekly_sales',\n",
    "\n",
    "    # holiday flags\n",
    "    'isholiday', 'holiday_name', 'holidayimpact',\n",
    "\n",
    "    # tax & return\n",
    "    'us_tax_return',\n",
    "\n",
    "    # market indices\n",
    "    'sp500_weekly_mean_close', 'wmt_weekly_mean_close',\n",
    "\n",
    "    # logistics-stock closes\n",
    "    'arcb_df_logistics_close', 'ait_df_logistics_close', 'ceva_df_logistics_close',\n",
    "    'fdx_df_logistics_close', 'saia_df_logistics_close', 'tfii.to_df_logistics_close',\n",
    "    'xpo_df_logistics_close', 'odfl_df_logistics_close', 'ups_df_logistics_close',\n",
    "    'jbht_df_logistics_close',\n",
    "\n",
    "    # oil price\n",
    "    'dcoilwtico',\n",
    "\n",
    "    # PMI\n",
    "    'china_official_manufacturing_pmi', 'china_official_services_pmi',\n",
    "    'ism_manufacturing_pmi', 'ism_services_pmi', 'euro_manufacturing_pmi',\n",
    "\n",
    "    # sentiment & consumption\n",
    "    'consumer_sentiment_umich', 'us_personal_consumption_expenditures',\n",
    "    'retail_sales_retail_and_food_services_usa',\n",
    "\n",
    "    # interest rates\n",
    "    'us_tbill_3mo_yield', 'us_fed_funds_rate',\n",
    "\n",
    "    # inflation measures\n",
    "    'cpi_food_beverages', 'cpi_shelter', 'cpi_medical_care', 'cpi_transportation',\n",
    "    'pce_healthcare_services',\n",
    "\n",
    "    # labor & freight\n",
    "    'weekly_initial_jobless_claims', 'rail_freight_carloads', 'truck_tonnage_index',\n",
    "\n",
    "    # FX rates\n",
    "    'cny_per_usd', 'mxn_per_usd', 'cad_per_usd', 'inr_per_usd', 'vnd_per_usd',\n",
    "\n",
    "    # trade tariffs\n",
    "    'us_tax_canada', 'us_tax_china', 'us_tax_india', 'us_tax_mexico', 'us_tax_vietnam',\n",
    "\n",
    "    # markdowns\n",
    "    'markdown1', 'markdown2', 'markdown3', 'markdown4', 'markdown5'\n",
    "]\n",
    "\n",
    "# sanity check\n",
    "missing = [col for col in new_order if col not in df_merged.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"These columns are missing from df_merged: {missing}\")\n",
    "\n",
    "# reorder\n",
    "df_merged = df_merged[new_order]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0adf3ed5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.379784Z",
     "iopub.status.idle": "2025-06-26T22:10:14.380111Z",
     "shell.execute_reply": "2025-06-26T22:10:14.379962Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.379946Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "# lowercase every column name\n",
    "df_merged.columns = df_merged.columns.str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7cb25dfb",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.381111Z",
     "iopub.status.idle": "2025-06-26T22:10:14.381466Z",
     "shell.execute_reply": "2025-06-26T22:10:14.381288Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.381273Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train = df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686dd941",
   "metadata": {},
   "source": [
    "#### Date Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d7c6d9ca",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.384732Z",
     "iopub.status.idle": "2025-06-26T22:10:14.38501Z",
     "shell.execute_reply": "2025-06-26T22:10:14.384885Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.384871Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "# Start from your raw df_merged_wm_train\n",
    "df_merged = df_wm_train.copy()\n",
    "\n",
    "# Parse date, extract year & weekofyr, then sort\n",
    "df_merged['date']     = pd.to_datetime(df_merged['date'])\n",
    "df_merged['year']     = df_merged['date'].dt.year\n",
    "df_merged['weekofyr'] = df_merged['date'].dt.isocalendar().week.astype(int)\n",
    "df_merged = df_merged.sort_values(['store','dept','date'])\n",
    "\n",
    "# Build lag features (with NaNs in the first 1/4/52 rows per group)\n",
    "df_merged = df_merged.set_index(['store','dept','date'])\n",
    "for lag in [1,4,52]:\n",
    "    df_merged[f'lag_{lag}'] = df_merged.groupby(level=['store','dept'])['weekly_sales'].shift(lag)\n",
    "df_merged = df_merged.reset_index()\n",
    "\n",
    "# Compute seasonal means by (store,dept,weekofyr,year)\n",
    "seasonal = (\n",
    "    df_merged\n",
    "    .groupby(['store','dept','weekofyr','year'])['weekly_sales']\n",
    "    .mean()\n",
    "    .reset_index(name='seasonal_mean')\n",
    ")\n",
    "\n",
    "# Fit year‐over‐year trend (slope & intercept) for each (store,dept,weekofyr)\n",
    "trend_params = {}\n",
    "for (st, dp, wk), grp in seasonal.groupby(['store','dept','weekofyr']):\n",
    "    yrs   = grp['year'].values\n",
    "    means = grp['seasonal_mean'].values\n",
    "    if len(yrs) >= 2:\n",
    "        m, b = np.polyfit(yrs, means, 1)\n",
    "    else:\n",
    "        # if only one year available, flat trend\n",
    "        m, b = 0.0, means[0]\n",
    "    trend_params[(st,dp,wk)] = (m, b)\n",
    "\n",
    "# Define an imputer that uses seasonal-trend prediction\n",
    "def predict_seasonal(row):\n",
    "    key = (row.store, row.dept, row.weekofyr)\n",
    "    m, b = trend_params.get(key, (0.0, np.nan))\n",
    "    return m * row.year + b\n",
    "\n",
    "# fill any missing lag_* by seasonal-trend\n",
    "for lag in [1,4,52]:\n",
    "    col = f'lag_{lag}'\n",
    "    mask = df_merged[col].isna()\n",
    "    df_merged.loc[mask, col] = df_merged[mask].apply(predict_seasonal, axis=1)\n",
    "\n",
    "# Clip at zero\n",
    "for lag in [1,4,52]:\n",
    "    df_merged[f'lag_{lag}'] = df_merged[f'lag_{lag}'].clip(lower=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b979f7a5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.386129Z",
     "iopub.status.idle": "2025-06-26T22:10:14.386371Z",
     "shell.execute_reply": "2025-06-26T22:10:14.38627Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.38626Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "# long-term drift   \n",
    "df_merged['year'] = df_merged['date'].dt.year\n",
    "\n",
    "# annual seasonality on a weekly grid\n",
    "df_merged['weekofyr'] = df_merged['date'].dt.isocalendar().week.astype(int)\n",
    "df_merged['week_sin'] = np.sin(2 * np.pi * df_merged['weekofyr'] / 52)\n",
    "df_merged['week_cos'] = np.cos(2 * np.pi * df_merged['weekofyr'] / 52)\n",
    "\n",
    "# continuous trend\n",
    "df_merged['date_ordinal'] = df_merged['date'].map(pd.Timestamp.toordinal)\n",
    "\n",
    "# drop the raw date if you like\n",
    "df_merged = df_merged.drop(columns=['date'])\n",
    "\n",
    "df_wm_train = df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9434b23f-d8f0-4355-be2b-a21b052a3d15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T22:38:50.924103Z",
     "iopub.status.busy": "2025-06-26T22:38:50.923796Z",
     "iopub.status.idle": "2025-06-26T22:38:54.404406Z",
     "shell.execute_reply": "2025-06-26T22:38:54.403606Z",
     "shell.execute_reply.started": "2025-06-26T22:38:50.924082Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "#Kaggle\n",
    "df_wm_train = pd.read_csv('/kaggle/input/df-wm-train01-kaggle/df_wm_train01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3f19cd38-892a-4c6e-bec6-238ff01c5a4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T22:39:20.242456Z",
     "iopub.status.busy": "2025-06-26T22:39:20.241688Z",
     "iopub.status.idle": "2025-06-26T22:39:20.345353Z",
     "shell.execute_reply": "2025-06-26T22:39:20.344344Z",
     "shell.execute_reply.started": "2025-06-26T22:39:20.242429Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541cf7dd",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "020f78e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T22:39:14.068023Z",
     "iopub.status.busy": "2025-06-26T22:39:14.06773Z",
     "iopub.status.idle": "2025-06-26T22:39:14.100297Z",
     "shell.execute_reply": "2025-06-26T22:39:14.099135Z",
     "shell.execute_reply.started": "2025-06-26T22:39:14.067995Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "type_map = {'A': 1, 'B': 2, 'C': 3}\n",
    "holiday_map = {False: 0, True: 1}\n",
    "\n",
    "df_wm_train['type']      = df_wm_train['type'].map(type_map)\n",
    "df_wm_train['isholiday'] = df_wm_train['isholiday'].map(holiday_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b2283700-7b2c-40f0-b4ba-7aabcf346712",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T22:39:31.594538Z",
     "iopub.status.busy": "2025-06-26T22:39:31.594236Z",
     "iopub.status.idle": "2025-06-26T22:39:54.983052Z",
     "shell.execute_reply": "2025-06-26T22:39:54.982293Z",
     "shell.execute_reply.started": "2025-06-26T22:39:31.594517Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "#Kaggle\n",
    "df_wm_train.to_csv(\"/kaggle/working/df_wm_train02.csv\", index=False)\n",
    "df_wm_train = pd.read_csv('/kaggle/working/df_wm_train02.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8ece482c-3f10-401c-9aa8-a7a9d64761a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T22:40:33.397502Z",
     "iopub.status.busy": "2025-06-26T22:40:33.397204Z",
     "iopub.status.idle": "2025-06-26T22:40:33.479647Z",
     "shell.execute_reply": "2025-06-26T22:40:33.47874Z",
     "shell.execute_reply.started": "2025-06-26T22:40:33.397479Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a1ee67",
   "metadata": {},
   "source": [
    "## Data Viz EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "053e19b8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.393049Z",
     "iopub.status.idle": "2025-06-26T22:10:14.393369Z",
     "shell.execute_reply": "2025-06-26T22:10:14.393222Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.393207Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d113781b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.394301Z",
     "iopub.status.idle": "2025-06-26T22:10:14.39466Z",
     "shell.execute_reply": "2025-06-26T22:10:14.394501Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.394486Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "plt.figure()\n",
    "df_wm_train.groupby('year')['weekly_sales'].mean().plot()\n",
    "plt.title(\"Avg Weekly Sales Over Time\")\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.xlabel(\"Date\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c37e045f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.395777Z",
     "iopub.status.idle": "2025-06-26T22:10:14.396206Z",
     "shell.execute_reply": "2025-06-26T22:10:14.395949Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.395933Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "plt.figure(figsize=(14,4))\n",
    "for i, lag in enumerate(['lag_1','lag_4','lag_52'], 1):\n",
    "    plt.subplot(1,3,i)\n",
    "    sns.scatterplot(x=lag, y='weekly_sales', data=df_wm_train, alpha=0.3)\n",
    "    plt.title(f\"{lag} vs Weekly Sales\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "323edc89",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.398076Z",
     "iopub.status.idle": "2025-06-26T22:10:14.398445Z",
     "shell.execute_reply": "2025-06-26T22:10:14.398265Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.398249Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "order = df_wm_train.groupby('holiday_name')['weekly_sales'].median().sort_values(ascending=False).index\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "ax = sns.boxplot(\n",
    "    x='holiday_name',\n",
    "    y='weekly_sales',\n",
    "    data=df_wm_train,\n",
    "    order=order,\n",
    "    width=0.6\n",
    ")\n",
    "\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "ax.tick_params(axis='x', pad=12)\n",
    "plt.title(\"Sales by Holiday/Special Event (sorted by median sales)\")\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Weekly Sales\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6d955296",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.399773Z",
     "iopub.status.idle": "2025-06-26T22:10:14.40012Z",
     "shell.execute_reply": "2025-06-26T22:10:14.39997Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.399955Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(\n",
    "    x='weekofyr', y='weekly_sales',\n",
    "    hue='year', estimator='mean',\n",
    "    data=df_wm_train, palette=\"tab10\"\n",
    ")\n",
    "plt.title(\"Average Sales by Week of Year, by Year\")\n",
    "plt.xlabel(\"Week of Year\")\n",
    "plt.ylabel(\"Avg Weekly Sales\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "05037fa6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.401522Z",
     "iopub.status.idle": "2025-06-26T22:10:14.401757Z",
     "shell.execute_reply": "2025-06-26T22:10:14.401657Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.401647Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "plt.figure(figsize=(14,5))\n",
    "subset = df_wm_train[df_wm_train['store'].isin([1,2,3,4,9,25,45])] \n",
    "sns.lineplot(\n",
    "    x='weekofyr', y='weekly_sales',\n",
    "    hue='store', data=subset,\n",
    "    estimator='mean', ci=None\n",
    ")\n",
    "plt.title(\"Sales Over Time for Sample Stores\")\n",
    "plt.xlabel(\"Week of Year\")\n",
    "plt.ylabel(\"Weekly Sales\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e29501c",
   "metadata": {},
   "source": [
    "## Data Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b38d9b",
   "metadata": {},
   "source": [
    "#### Drop columns Correlation >= 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a98aa215",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.403158Z",
     "iopub.status.idle": "2025-06-26T22:10:14.403428Z",
     "shell.execute_reply": "2025-06-26T22:10:14.403302Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.403293Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train_pruned = df_wm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "efcee736",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.404696Z",
     "iopub.status.idle": "2025-06-26T22:10:14.40494Z",
     "shell.execute_reply": "2025-06-26T22:10:14.404839Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.404828Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "# absolute correlation of your numeric features\n",
    "df_num = df_wm_train_pruned.select_dtypes(include=[np.number])\n",
    "corr = df_num.corr().abs()\n",
    "\n",
    "# upper‐triangle mask\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# find all pairs with |r|>0.8\n",
    "thresh = 0.9\n",
    "high_corr = (\n",
    "    corr.where(~mask)               \n",
    "        .stack()                    \n",
    "        .loc[lambda s: s > thresh] \n",
    "        .sort_values(ascending=False)\n",
    ")\n",
    "high_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "478732ad",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.405565Z",
     "iopub.status.idle": "2025-06-26T22:10:14.406013Z",
     "shell.execute_reply": "2025-06-26T22:10:14.405697Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.405683Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "target_corr = corr['weekly_sales'].sort_values(ascending=False)\n",
    "print(target_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "591780c3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.407358Z",
     "iopub.status.idle": "2025-06-26T22:10:14.407638Z",
     "shell.execute_reply": "2025-06-26T22:10:14.407535Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.407516Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "\n",
    "us_tax_mexico → keep us_tax_vietnam\n",
    "(Identical tariff signals.)\n",
    "\n",
    "weekofyr → keep week_sin/week_cos\n",
    "(Raw week number is redundant—cyclical encoding is sufficient.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "606970db",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.408583Z",
     "iopub.status.idle": "2025-06-26T22:10:14.408868Z",
     "shell.execute_reply": "2025-06-26T22:10:14.408726Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.408712Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "to_drop = [\n",
    "    'us_tax_mexico',\n",
    "    'weekofyr',\n",
    "]\n",
    "\n",
    "df_wm_train_pruned = df_wm_train.drop(columns=to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8399b60f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.410292Z",
     "iopub.status.idle": "2025-06-26T22:10:14.410675Z",
     "shell.execute_reply": "2025-06-26T22:10:14.410537Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.410516Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_wm_train_pruned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d867b77",
   "metadata": {},
   "source": [
    "## ML Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6c5ced",
   "metadata": {},
   "source": [
    "### 1st selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda32584",
   "metadata": {},
   "source": [
    "#### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b9d68cdd-6835-443b-bd86-483c7971cec7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T02:02:05.529937Z",
     "iopub.status.busy": "2025-06-27T02:02:05.529201Z",
     "iopub.status.idle": "2025-06-27T02:02:09.846203Z",
     "shell.execute_reply": "2025-06-27T02:02:09.845413Z",
     "shell.execute_reply.started": "2025-06-27T02:02:05.529907Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "#Kaggle\n",
    "df_wm_train_pruned = pd.read_csv('/kaggle/input/df-wm-train02/df_wm_train02.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a7ecf7f1-2bd2-46b5-8c56-691b76b42703",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#VsCode\n",
    "df_wm_train_pruned = pd.read_csv('csv_files/ml_train_data/df_wm_train02.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "cda7d960",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T02:02:10.021342Z",
     "iopub.status.busy": "2025-06-27T02:02:10.020836Z",
     "iopub.status.idle": "2025-06-27T02:02:10.137988Z",
     "shell.execute_reply": "2025-06-27T02:02:10.137395Z",
     "shell.execute_reply.started": "2025-06-27T02:02:10.021315Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "store",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dept",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "type",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "size",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "weekly_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "isholiday",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "holiday_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "holidayimpact",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "us_tax_return",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sp500_weekly_mean_close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wmt_weekly_mean_close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "arcb_df_logistics_close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ait_df_logistics_close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ceva_df_logistics_close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fdx_df_logistics_close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "saia_df_logistics_close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tfii.to_df_logistics_close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "xpo_df_logistics_close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "odfl_df_logistics_close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ups_df_logistics_close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "jbht_df_logistics_close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dcoilwtico",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "china_official_manufacturing_pmi",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "china_official_services_pmi",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ism_manufacturing_pmi",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ism_services_pmi",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "euro_manufacturing_pmi",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "consumer_sentiment_umich",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "us_personal_consumption_expenditures",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "retail_sales_retail_and_food_services_usa",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "us_tbill_3mo_yield",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "us_fed_funds_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cpi_food_beverages",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cpi_shelter",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cpi_medical_care",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cpi_transportation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pce_healthcare_services",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "weekly_initial_jobless_claims",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rail_freight_carloads",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "truck_tonnage_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cny_per_usd",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mxn_per_usd",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cad_per_usd",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "inr_per_usd",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "vnd_per_usd",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "us_tax_canada",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "us_tax_china",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "us_tax_india",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "us_tax_mexico",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "us_tax_vietnam",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "markdown1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "markdown2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "markdown3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "markdown4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "markdown5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "weekofyr",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "lag_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lag_52",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "week_sin",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "week_cos",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "date_ordinal",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "41168a6b-7a80-4ccb-92ee-33ce1084f8a9",
       "rows": [
        [
         "0",
         "1",
         "1",
         "1",
         "151315",
         "24924.5",
         "0",
         "No Holiday",
         "0.8909157412340148",
         "0.0",
         "1083.81796875",
         "12.849576950073242",
         "19.7749",
         "16.3716",
         "11.386",
         "67.5286",
         "8.1133",
         "5.9522",
         "1.732",
         "4.0012",
         "35.1546",
         "26.3251",
         "71.15",
         "52.0",
         "57.0",
         "57.45",
         "50.5",
         "52.4",
         "73.6",
         "10093.4",
         "339580",
         "0.098",
         "0.13",
         "218.898",
         "247.997",
         "384.308",
         "191.978",
         "1663.318",
         "496000",
         "1060960",
         "81.3",
         "6.8269",
         "13.011",
         "1.0666",
         "46.256",
         "18421.0",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "5",
         "24073.92166666733",
         "24073.92166666733",
         "24073.92166666733",
         "0.5680647467311558",
         "0.8229838658936564",
         "733808"
        ],
        [
         "1",
         "1",
         "1",
         "1",
         "151315",
         "46039.49",
         "1",
         "Super Bowl",
         "0.9944154131125642",
         "0.0",
         "1069.8739990234376",
         "12.74108009338379",
         "19.9706",
         "16.2364",
         "11.006",
         "66.1162",
         "8.14",
         "5.7845",
         "1.7154",
         "4.0306",
         "34.4932",
         "26.7885",
         "74.11",
         "52.0",
         "57.0",
         "57.45",
         "50.5",
         "52.4",
         "73.6",
         "10093.4",
         "339580",
         "0.112",
         "0.13",
         "218.898",
         "247.997",
         "384.308",
         "191.978",
         "1663.318",
         "466000",
         "1060960",
         "81.3",
         "6.8293",
         "13.0574",
         "1.062",
         "46.494",
         "18406.0",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "6",
         "24924.5",
         "44830.550000000745",
         "44830.550000000745",
         "0.6631226582407952",
         "0.7485107481711011",
         "733815"
        ],
        [
         "2",
         "1",
         "1",
         "1",
         "151315",
         "41595.55",
         "1",
         "Valentine's Day, Presidents' Day",
         "0.716941869558779",
         "0.0",
         "1102.5750122070312",
         "12.876699209213257",
         "21.8988",
         "16.8577",
         "11.7",
         "67.7903",
         "7.66",
         "5.8391",
         "1.8538",
         "4.1189",
         "35.0687",
         "27.9924",
         "79.77",
         "52.0",
         "57.0",
         "57.45",
         "50.5",
         "54.1",
         "73.6",
         "10093.4",
         "339580",
         "0.1025",
         "0.13",
         "218.898",
         "247.997",
         "384.308",
         "191.978",
         "1663.318",
         "489000",
         "1060960",
         "81.3",
         "6.8318",
         "12.8493",
         "1.0438",
         "46.1075",
         "18487.4",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "7",
         "46039.49",
         "41268.23166666366",
         "41268.23166666366",
         "0.7485107481711011",
         "0.6631226582407953",
         "733822"
        ],
        [
         "3",
         "1",
         "1",
         "1",
         "151315",
         "19403.54",
         "0",
         "No Holiday",
         "0.0840786917266883",
         "0.0",
         "1103.0559814453125",
         "12.942227554321288",
         "22.6758",
         "17.1335",
         "11.864",
         "69.9236",
         "8.0707",
         "6.2608",
         "1.9285",
         "4.3097",
         "35.6784",
         "29.4901",
         "79.72",
         "52.0",
         "57.0",
         "57.45",
         "50.5",
         "54.1",
         "73.6",
         "10093.4",
         "339580",
         "0.122",
         "0.13",
         "218.898",
         "247.997",
         "384.308",
         "191.978",
         "1663.318",
         "500000",
         "1060960",
         "81.3",
         "6.8265",
         "12.8226",
         "1.0538",
         "46.202",
         "18622.2",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "8",
         "41595.55",
         "19270.18999999971",
         "19270.18999999971",
         "0.8229838658936564",
         "0.5680647467311559",
         "733829"
        ],
        [
         "4",
         "1",
         "1",
         "1",
         "151315",
         "21827.9",
         "0",
         "No Holiday",
         "0.1882550990706332",
         "0.0",
         "1122.89599609375",
         "12.925909423828124",
         "23.9654",
         "17.7752",
         "12.288",
         "72.5866",
         "8.424",
         "6.8441",
         "1.9368",
         "4.3818",
         "36.1191",
         "29.9464",
         "81.5",
         "55.1",
         "57.3",
         "58.05",
         "53.0",
         "54.2",
         "73.6",
         "10156.0",
         "346974",
         "0.14",
         "0.16",
         "219.321",
         "247.914",
         "385.712",
         "191.375",
         "1663.318",
         "488000",
         "1245587",
         "81.9",
         "6.8261",
         "12.7042",
         "1.0325",
         "45.776",
         "19008.0",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "9",
         "19403.54",
         "24924.5",
         "21613.615000000456",
         "0.8854560256532099",
         "0.4647231720437686",
         "733836"
        ],
        [
         "5",
         "1",
         "1",
         "1",
         "151315",
         "21043.39",
         "0",
         "No Holiday",
         "0.4254788669119128",
         "0.0",
         "1144.9579833984376",
         "12.991690254211424",
         "25.4786",
         "18.3684",
         "12.87",
         "73.1294",
         "9.3347",
         "7.0724",
         "1.9174",
         "4.7404",
         "37.3069",
         "30.6903",
         "81.26",
         "55.1",
         "57.3",
         "58.05",
         "53.0",
         "54.2",
         "73.6",
         "10156.0",
         "346974",
         "0.156",
         "0.16",
         "219.321",
         "247.914",
         "385.712",
         "191.375",
         "1663.318",
         "472000",
         "1245587",
         "81.9",
         "6.8261",
         "12.6092",
         "1.0245",
         "45.484",
         "19031.0",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "10",
         "21827.9",
         "46039.49",
         "21106.27999999997",
         "0.9350162426854148",
         "0.3546048870425355",
         "733843"
        ],
        [
         "6",
         "1",
         "1",
         "1",
         "151315",
         "22136.64",
         "1",
         "DST Start, St. Patrick's Day",
         "0.6826705121831975",
         "0.0",
         "1160.381982421875",
         "13.450643730163574",
         "26.1065",
         "18.5289",
         "12.802",
         "75.9375",
         "9.3733",
         "7.0217",
         "2.0281",
         "4.8316",
         "38.6741",
         "31.0829",
         "80.58",
         "55.1",
         "57.3",
         "58.05",
         "53.0",
         "54.2",
         "73.6",
         "10156.0",
         "346974",
         "0.16",
         "0.16",
         "219.321",
         "247.914",
         "385.712",
         "191.375",
         "1663.318",
         "478000",
         "1245587",
         "81.9",
         "6.826",
         "12.5195",
         "1.0153",
         "45.408",
         "18944.6",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "11",
         "21043.39",
         "41595.55",
         "21497.463333333144",
         "0.970941817426052",
         "0.239315664287558",
         "733850"
        ],
        [
         "7",
         "1",
         "1",
         "1",
         "151315",
         "26229.21",
         "0",
         "No Holiday",
         "0.8909157412340148",
         "0.0",
         "1168.00400390625",
         "13.431332397460938",
         "26.2467",
         "18.7317",
         "12.33",
         "76.5889",
         "9.392",
         "6.971",
         "2.1747",
         "4.7621",
         "39.0233",
         "31.0949",
         "79.75",
         "55.1",
         "57.3",
         "58.05",
         "53.0",
         "56.3",
         "73.6",
         "10156.0",
         "346974",
         "0.142",
         "0.16",
         "219.321",
         "247.914",
         "385.712",
         "191.375",
         "1663.318",
         "472000",
         "1245587",
         "81.9",
         "6.8267",
         "12.5416",
         "1.0222",
         "45.416",
         "18889.0",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "12",
         "22136.64",
         "19403.54",
         "25133.425000002146",
         "0.992708874098054",
         "0.120536680255323",
         "733857"
        ],
        [
         "8",
         "1",
         "1",
         "1",
         "151315",
         "57258.43",
         "1",
         "Good Friday",
         "1.028978538790462",
         "0.0125360439090881",
         "1173.5050048828125",
         "13.441711187362673",
         "26.5553",
         "18.8913",
         "11.8775",
         "78.1812",
         "9.38",
         "7.0737",
         "2.1028",
         "4.7513",
         "39.2497",
         "30.7411",
         "85.445",
         "55.7",
         "57.8",
         "59.6",
         "54.2",
         "56.6",
         "72.2",
         "10182.3",
         "349869",
         "0.158",
         "0.2",
         "219.531",
         "247.959",
         "386.589",
         "191.249",
         "1687.097",
         "459000",
         "1226038",
         "82.1",
         "6.826",
         "12.3523",
         "1.0146",
         "44.896",
         "18981.4",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "13",
         "26229.21",
         "21827.9",
         "49689.24500001222",
         "1.0",
         "-1.6081226496766366e-16",
         "733864"
        ],
        [
         "9",
         "1",
         "1",
         "1",
         "151315",
         "42960.91",
         "1",
         "Easter Sunday",
         "0.9051969686294122",
         "0.6112604669781572",
         "1188.0279541015625",
         "13.36084804534912",
         "26.4684",
         "19.4354",
         "11.438",
         "77.2032",
         "9.6947",
         "7.2592",
         "2.0143",
         "4.932",
         "39.1588",
         "30.7712",
         "84.6",
         "55.7",
         "57.8",
         "60.0",
         "55.4",
         "56.6",
         "72.2",
         "10182.3",
         "349869",
         "0.17",
         "0.2",
         "219.531",
         "247.959",
         "386.589",
         "191.249",
         "1687.097",
         "479000",
         "1226038",
         "82.1",
         "6.8246",
         "12.2339",
         "1.0026",
         "44.35",
         "15251.8",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "14",
         "57258.43",
         "21043.39",
         "34160.00166666135",
         "0.992708874098054",
         "-0.1205366802553228",
         "733871"
        ],
        [
         "10",
         "1",
         "1",
         "1",
         "151315",
         "17596.96",
         "0",
         "No Holiday",
         "0.4749944329607032",
         "0.99860189859059",
         "1201.6460205078124",
         "13.161457824707032",
         "26.7114",
         "19.9197",
         "11.52",
         "78.479",
         "10.0213",
         "7.2236",
         "2.0779",
         "5.1359",
         "40.5516",
         "31.6769",
         "82.97",
         "55.7",
         "57.8",
         "60.0",
         "55.4",
         "56.6",
         "72.2",
         "10182.3",
         "349869",
         "0.16",
         "0.2",
         "219.531",
         "247.959",
         "386.589",
         "191.249",
         "1687.097",
         "479000",
         "1226038",
         "82.1",
         "6.8256",
         "12.2028",
         "1.0032",
         "44.3395",
         "18907.8",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "15",
         "42960.91",
         "22136.64",
         "18470.88833332807",
         "0.970941817426052",
         "-0.2393156642875575",
         "733878"
        ],
        [
         "11",
         "1",
         "1",
         "1",
         "151315",
         "16145.35",
         "0",
         "No Holiday",
         "0.7048841092901271",
         "0.9131193871579976",
         "1207.316015625",
         "13.150838661193848",
         "27.8769",
         "20.7279",
         "12.514",
         "77.7314",
         "10.0733",
         "7.2705",
         "2.053",
         "5.2534",
         "41.6991",
         "31.8061",
         "84.34",
         "55.7",
         "57.8",
         "60.0",
         "55.4",
         "57.5",
         "72.2",
         "10182.3",
         "349869",
         "0.158",
         "0.2",
         "219.531",
         "247.959",
         "386.589",
         "191.249",
         "1687.097",
         "469000",
         "1226038",
         "82.1",
         "6.8265",
         "12.2403",
         "1.0041",
         "44.54",
         "18769.4",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "16",
         "17596.96",
         "26229.21",
         "27461.863333334564",
         "0.9350162426854148",
         "-0.3546048870425354",
         "733885"
        ],
        [
         "12",
         "1",
         "1",
         "1",
         "151315",
         "16555.11",
         "0",
         "No Holiday",
         "1.0508293723485551",
         "0.716941869558779",
         "1196.1179931640625",
         "12.988143157958984",
         "27.6072",
         "22.8709",
         "12.59",
         "76.8944",
         "10.7627",
         "7.4357",
         "2.0751",
         "5.2623",
         "41.7357",
         "31.9214",
         "86.07",
         "55.7",
         "57.8",
         "60.0",
         "55.4",
         "57.5",
         "72.2",
         "10182.3",
         "349869",
         "0.162",
         "0.2",
         "219.531",
         "247.959",
         "386.589",
         "191.249",
         "1687.097",
         "449000",
         "1226038",
         "82.1",
         "6.8255",
         "12.2598",
         "1.0093",
         "44.418",
         "18854.6",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "17",
         "16145.35",
         "57258.43",
         "24908.78833333467",
         "0.8854560256532099",
         "-0.4647231720437685",
         "733892"
        ],
        [
         "13",
         "1",
         "1",
         "1",
         "151315",
         "17413.94",
         "0",
         "No Holiday",
         "1.383154946134407",
         "0.4626349532067879",
         "1156.152001953125",
         "12.946140480041503",
         "25.6541",
         "21.9174",
         "11.936",
         "74.174",
         "10.804",
         "7.5439",
         "2.0696",
         "5.1096",
         "40.9862",
         "30.8177",
         "75.1",
         "53.9",
         "58.1",
         "60.05",
         "55.4",
         "57.6",
         "73.6",
         "10210.8",
         "346858",
         "0.144",
         "0.2",
         "219.651",
         "248.128",
         "387.094",
         "190.231",
         "1687.097",
         "451000",
         "1238429",
         "81.6",
         "6.8257",
         "12.599",
         "1.0295",
         "44.918",
         "18917.0",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "18",
         "16555.11",
         "42960.91",
         "18366.440000000293",
         "0.8229838658936565",
         "-0.5680647467311557",
         "733899"
        ],
        [
         "14",
         "1",
         "1",
         "1",
         "151315",
         "18926.74",
         "1",
         "Mother's Day",
         "1.3988825824421292",
         "0.2183399709681889",
         "1156.06201171875",
         "12.694713973999024",
         "25.7038",
         "22.5138",
         "12.346",
         "74.1656",
         "11.0307",
         "7.5012",
         "2.1139",
         "5.3312",
         "41.0362",
         "30.5857",
         "71.61",
         "53.9",
         "58.1",
         "60.05",
         "55.4",
         "57.6",
         "73.6",
         "10210.8",
         "346858",
         "0.16",
         "0.2",
         "219.651",
         "248.128",
         "387.094",
         "190.231",
         "1687.097",
         "451000",
         "1238429",
         "81.6",
         "6.8272",
         "12.4786",
         "1.0225",
         "45.044",
         "18897.2",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "19",
         "17413.94",
         "17596.96",
         "18489.96666666679",
         "0.7485107481711013",
         "-0.663122658240795",
         "733906"
        ],
        [
         "15",
         "1",
         "1",
         "1",
         "151315",
         "14773.04",
         "0",
         "No Holiday",
         "1.104296601034337",
         "0.0495155660487904",
         "1106.4139892578123",
         "12.72951431274414",
         "24.2301",
         "21.403",
         "12.194",
         "70.5744",
         "10.3493",
         "7.0883",
         "2.0336",
         "5.2005",
         "39.5533",
         "29.9597",
         "68.03",
         "53.9",
         "58.1",
         "60.05",
         "55.4",
         "55.9",
         "73.6",
         "10210.8",
         "346858",
         "0.168",
         "0.2",
         "219.651",
         "248.128",
         "387.094",
         "190.231",
         "1687.097",
         "474000",
         "1238429",
         "81.6",
         "6.8271",
         "12.8681",
         "1.0492",
         "46.198",
         "18771.6",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "20",
         "18926.74",
         "16145.35",
         "14270.16166666476",
         "0.6631226582407952",
         "-0.7485107481711012",
         "733913"
        ],
        [
         "16",
         "1",
         "1",
         "1",
         "151315",
         "15580.43",
         "0",
         "No Holiday",
         "1.4475059486807225",
         "0.0",
         "1081.62001953125",
         "12.263841819763185",
         "20.7321",
         "20.7124",
         "11.408",
         "69.4387",
         "9.6947",
         "6.9029",
         "1.9285",
         "5.0235",
         "38.3401",
         "29.4293",
         "74.0",
         "53.9",
         "58.1",
         "60.05",
         "55.4",
         "55.9",
         "73.6",
         "10210.8",
         "346858",
         "0.168",
         "0.2",
         "219.651",
         "248.128",
         "387.094",
         "190.231",
         "1687.097",
         "463000",
         "1238429",
         "81.6",
         "6.8298",
         "12.9591",
         "1.06",
         "46.916",
         "18951.0",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "21",
         "14773.04",
         "16555.11",
         "15403.633333332604",
         "0.5680647467311558",
         "-0.8229838658936564",
         "733920"
        ],
        [
         "17",
         "1",
         "1",
         "1",
         "151315",
         "17558.09",
         "1",
         "Memorial Day",
         "1.6826705121831975",
         "0.0",
         "1084.1999816894531",
         "12.428454160690308",
         "20.1022",
         "20.7964",
         "11.4925",
         "69.1822",
         "9.695",
         "6.9915",
         "1.8918",
         "5.0776",
         "38.0024",
         "29.2885",
         "71.43",
         "52.1",
         "58.8",
         "57.95",
         "55.4",
         "55.8",
         "76.0",
         "10231.3",
         "346516",
         "0.15",
         "0.18",
         "219.627",
         "248.295",
         "388.188",
         "189.426",
         "1687.097",
         "458000",
         "1183965",
         "81.6",
         "6.828",
         "12.8486",
         "1.0452",
         "46.8425",
         "18862.4",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "22",
         "15580.43",
         "17413.94",
         "17432.21000000043",
         "0.464723172043769",
         "-0.8854560256532096",
         "733927"
        ],
        [
         "18",
         "1",
         "1",
         "1",
         "151315",
         "16637.62",
         "0",
         "No Holiday",
         "1.4254788669119127",
         "0.0",
         "1069.319970703125",
         "12.36241569519043",
         "19.0222",
         "19.859",
         "11.31",
         "66.4297",
         "9.5533",
         "6.795",
         "1.8427",
         "4.8808",
         "36.6401",
         "28.4307",
         "73.89",
         "52.1",
         "58.8",
         "57.95",
         "55.4",
         "55.8",
         "76.0",
         "10231.3",
         "346516",
         "0.104",
         "0.18",
         "219.627",
         "248.295",
         "388.188",
         "189.426",
         "1687.097",
         "459000",
         "1183965",
         "81.6",
         "6.8305",
         "12.8017",
         "1.0423",
         "46.9",
         "18822.2",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "23",
         "17558.09",
         "18926.74",
         "16214.856666666456",
         "0.3546048870425358",
         "-0.9350162426854148",
         "733934"
        ],
        [
         "19",
         "1",
         "1",
         "1",
         "151315",
         "16216.27",
         "0",
         "No Holiday",
         "1.6770859252957615",
         "0.0",
         "1110.60400390625",
         "12.470700454711912",
         "19.3755",
         "20.8249",
         "11.986",
         "67.4742",
         "10.2787",
         "6.9573",
         "1.8759",
         "5.2643",
         "38.2098",
         "30.4175",
         "77.18",
         "52.1",
         "58.8",
         "57.95",
         "55.4",
         "55.8",
         "76.0",
         "10231.3",
         "346516",
         "0.092",
         "0.18",
         "219.627",
         "248.295",
         "388.188",
         "189.426",
         "1687.097",
         "467000",
         "1183965",
         "81.6",
         "6.8305",
         "12.5774",
         "1.0259",
         "46.284",
         "18925.0",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "24",
         "16637.62",
         "14773.04",
         "15579.784999998985",
         "0.2393156642875576",
         "-0.970941817426052",
         "733941"
        ],
        [
         "20",
         "1",
         "1",
         "1",
         "151315",
         "16328.72",
         "1",
         "Father's Day",
         "1.6078576107927938",
         "0.0",
         "1090.2",
         "12.204601097106934",
         "18.1379",
         "20.1769",
         "12.068",
         "64.7785",
         "9.7493",
         "6.9645",
         "1.9063",
         "5.0246",
         "37.2928",
         "29.0336",
         "78.45",
         "52.1",
         "58.8",
         "57.95",
         "55.4",
         "55.6",
         "76.0",
         "10231.3",
         "346516",
         "0.128",
         "0.18",
         "219.627",
         "248.295",
         "388.188",
         "189.426",
         "1687.097",
         "452000",
         "1183965",
         "81.6",
         "6.8026",
         "12.6037",
         "1.0317",
         "46.1325",
         "18867.2",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "25",
         "16216.27",
         "15580.43",
         "16062.634999999893",
         "0.120536680255323",
         "-0.992708874098054",
         "733948"
        ],
        [
         "21",
         "1",
         "1",
         "1",
         "151315",
         "16333.14",
         "0",
         "No Holiday",
         "1.043930979161355",
         "0.0",
         "1039.2939819335938",
         "11.793799018859865",
         "18.1326",
         "19.3813",
         "12.472",
         "60.8694",
         "9.9267",
         "6.7502",
         "1.7514",
         "5.0198",
         "35.5018",
         "28.5412",
         "72.06",
         "51.2",
         "57.1",
         "56.2",
         "54.6",
         "55.6",
         "67.8",
         "10268.1",
         "347612",
         "0.168",
         "0.18",
         "219.643",
         "248.43",
         "388.123",
         "191.082",
         "1718.993",
         "464000",
         "1214303",
         "82.0",
         "6.7854",
         "12.8865",
         "1.0549",
         "46.43",
         "18929.4",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "26",
         "16328.72",
         "17558.09",
         "16111.646666666726",
         "-3.216245299353273e-16",
         "-1.0",
         "733955"
        ],
        [
         "22",
         "1",
         "1",
         "1",
         "151315",
         "17688.76",
         "1",
         "Independence Day",
         "0.716941869558779",
         "0.0",
         "1059.135009765625",
         "11.902813196182253",
         "18.2134",
         "19.0642",
         "12.56",
         "61.5796",
         "10.2967",
         "6.3867",
         "1.7604",
         "5.019",
         "36.3675",
         "28.9645",
         "76.08",
         "51.2",
         "57.1",
         "55.85",
         "53.8",
         "55.6",
         "67.8",
         "10268.1",
         "347612",
         "0.16",
         "0.18",
         "219.643",
         "248.43",
         "388.123",
         "191.082",
         "1718.993",
         "454000",
         "1214303",
         "82.0",
         "6.7764",
         "12.848",
         "1.044",
         "46.8112",
         "18881.0",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "27",
         "16333.14",
         "16637.62",
         "17153.028333333205",
         "-0.1205366802553228",
         "-0.992708874098054",
         "733962"
        ],
        [
         "23",
         "1",
         "1",
         "1",
         "151315",
         "17150.84",
         "0",
         "No Holiday",
         "0.0495155660487904",
         "0.0",
         "1086.1239990234376",
         "12.192463684082032",
         "19.3791",
         "19.5167",
         "12.61",
         "64.5622",
         "10.504",
         "6.7434",
         "1.9728",
         "5.1865",
         "37.3801",
         "30.1359",
         "75.96",
         "51.2",
         "57.1",
         "55.85",
         "53.8",
         "55.6",
         "67.8",
         "10268.1",
         "347612",
         "0.152",
         "0.18",
         "219.643",
         "248.43",
         "388.123",
         "191.082",
         "1718.993",
         "439000",
         "1214303",
         "82.0",
         "6.7733",
         "12.7845",
         "1.038",
         "46.662",
         "18880.8",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "28",
         "17688.76",
         "16216.27",
         "16749.62000000011",
         "-0.2393156642875574",
         "-0.970941817426052",
         "733969"
        ],
        [
         "24",
         "1",
         "1",
         "1",
         "151315",
         "15360.45",
         "0",
         "No Holiday",
         "0.0",
         "0.0",
         "1084.1300048828125",
         "12.298804473876952",
         "19.1216",
         "20.65",
         "12.356",
         "64.6315",
         "10.0853",
         "6.8182",
         "1.9257",
         "5.2239",
         "37.8804",
         "30.3726",
         "78.68",
         "51.2",
         "57.1",
         "55.85",
         "53.8",
         "56.5",
         "67.8",
         "10268.1",
         "347612",
         "0.162",
         "0.18",
         "219.643",
         "248.43",
         "388.123",
         "191.082",
         "1718.993",
         "462000",
         "1214303",
         "82.0",
         "6.7786",
         "12.8107",
         "1.0451",
         "47.086",
         "18971.0",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "29",
         "17150.84",
         "16328.72",
         "15331.23166666634",
         "-0.3546048870425356",
         "-0.9350162426854148",
         "733976"
        ],
        [
         "25",
         "1",
         "1",
         "1",
         "151315",
         "15381.82",
         "0",
         "No Holiday",
         "0.0222135971069296",
         "0.0",
         "1107.6219970703123",
         "12.405147171020507",
         "20.3255",
         "21.4319",
         "12.924",
         "69.8369",
         "10.2107",
         "6.9835",
         "1.9589",
         "5.5977",
         "39.793",
         "30.8856",
         "78.85",
         "51.2",
         "57.1",
         "55.85",
         "53.8",
         "56.5",
         "67.8",
         "10268.1",
         "347612",
         "0.152",
         "0.18",
         "219.643",
         "248.43",
         "388.123",
         "191.082",
         "1718.993",
         "465000",
         "1214303",
         "82.0",
         "6.7769",
         "12.679",
         "1.0337",
         "46.574",
         "19006.4",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "30",
         "15360.45",
         "16333.14",
         "15503.78999999998",
         "-0.464723172043768",
         "-0.8854560256532101",
         "733983"
        ],
        [
         "26",
         "1",
         "1",
         "1",
         "151315",
         "17508.41",
         "0",
         "No Holiday",
         "0.1599136311145403",
         "0.0",
         "1124.202001953125",
         "12.51391887664795",
         "19.9329",
         "21.9171",
         "12.672",
         "71.8717",
         "9.2907",
         "7.25",
         "1.8953",
         "5.4493",
         "41.1414",
         "31.0418",
         "80.67",
         "51.7",
         "58.0",
         "55.9",
         "54.3",
         "56.7",
         "68.9",
         "10307.1",
         "349188",
         "0.156",
         "0.19",
         "219.879",
         "248.43",
         "389.059",
         "192.287",
         "1718.993",
         "476000",
         "1280718",
         "81.4",
         "6.7715",
         "12.5832",
         "1.0211",
         "46.044",
         "18929.8",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "31",
         "15381.82",
         "17688.76",
         "16917.473333333735",
         "-0.5680647467311556",
         "-0.8229838658936566",
         "733990"
        ],
        [
         "27",
         "1",
         "1",
         "1",
         "151315",
         "15536.4",
         "0",
         "No Holiday",
         "0.3887395330218428",
         "0.0",
         "1100.2360107421875",
         "12.480227851867676",
         "18.3809",
         "21.2284",
         "12.3",
         "71.0267",
         "8.2067",
         "7.1705",
         "1.9617",
         "5.2182",
         "40.5263",
         "29.6515",
         "75.39",
         "51.7",
         "58.0",
         "55.9",
         "54.3",
         "56.7",
         "68.9",
         "10307.1",
         "349188",
         "0.152",
         "0.19",
         "219.879",
         "248.43",
         "389.059",
         "192.287",
         "1718.993",
         "483000",
         "1280718",
         "81.4",
         "6.7787",
         "12.6983",
         "1.038",
         "46.468",
         "19048.0",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "32",
         "17508.41",
         "17150.84",
         "15106.943333333007",
         "-0.663122658240795",
         "-0.7485107481711013",
         "733997"
        ],
        [
         "28",
         "1",
         "1",
         "1",
         "151315",
         "15740.13",
         "0",
         "No Holiday",
         "0.6473775872054521",
         "0.0",
         "1082.6800048828125",
         "12.3359037399292",
         "17.7266",
         "20.8296",
         "11.63",
         "69.5614",
         "8.1867",
         "7.0425",
         "1.9534",
         "5.3086",
         "40.5313",
         "29.2164",
         "73.45",
         "51.7",
         "58.0",
         "55.9",
         "54.3",
         "56.7",
         "68.9",
         "10307.1",
         "349188",
         "0.16",
         "0.19",
         "219.879",
         "248.43",
         "389.059",
         "192.287",
         "1718.993",
         "486000",
         "1280718",
         "81.4",
         "6.7933",
         "12.6671",
         "1.0384",
         "46.374",
         "19010.0",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "33",
         "15536.4",
         "15360.45",
         "15124.738333332352",
         "-0.7485107481711011",
         "-0.6631226582407952",
         "734004"
        ],
        [
         "29",
         "1",
         "1",
         "1",
         "151315",
         "15793.87",
         "0",
         "No Holiday",
         "0.866525935914913",
         "0.0",
         "1057.273974609375",
         "12.50147876739502",
         "18.036",
         "20.095",
         "11.842",
         "67.3491",
         "8.132",
         "7.0353",
         "1.8731",
         "5.2168",
         "39.6597",
         "28.6253",
         "75.17",
         "51.7",
         "58.0",
         "55.9",
         "54.3",
         "55.0",
         "68.9",
         "10307.1",
         "349188",
         "0.158",
         "0.19",
         "219.879",
         "248.43",
         "389.059",
         "192.287",
         "1718.993",
         "464000",
         "1280718",
         "81.4",
         "6.7986",
         "12.9597",
         "1.0561",
         "46.762",
         "19159.6",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "34",
         "15740.13",
         "15381.82",
         "15292.94833333313",
         "-0.8229838658936564",
         "-0.5680647467311559",
         "734011"
        ],
        [
         "30",
         "1",
         "1",
         "1",
         "151315",
         "16241.78",
         "0",
         "No Holiday",
         "0.9874639560909118",
         "0.0",
         "1074.6300048828125",
         "12.488291358947754",
         "18.8468",
         "21.4204",
         "12.498",
         "68.0538",
         "8.1587",
         "7.1619",
         "1.9063",
         "5.252",
         "40.696",
         "29.2806",
         "74.52",
         "53.8",
         "57.9",
         "55.35",
         "51.5",
         "55.1",
         "68.2",
         "10327.1",
         "352179",
         "0.138",
         "0.19",
         "220.598",
         "248.568",
         "391.288",
         "193.316",
         "1718.993",
         "467000",
         "1239743",
         "82.1",
         "6.8057",
         "13.0701",
         "1.0526",
         "46.772",
         "19288.8",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "35",
         "15793.87",
         "17508.41",
         "15847.19999999972",
         "-0.8854560256532096",
         "-0.4647231720437691",
         "734018"
        ],
        [
         "31",
         "1",
         "1",
         "1",
         "151315",
         "18194.74",
         "1",
         "Labor Day",
         "0.8117449009293668",
         "0.0",
         "1101.1100158691406",
         "12.672545433044434",
         "19.9758",
         "22.1456",
         "13.0025",
         "70.6869",
         "8.695",
         "7.3326",
         "2.1547",
         "5.3736",
         "41.7945",
         "29.6104",
         "76.4",
         "53.8",
         "57.9",
         "55.35",
         "51.5",
         "55.1",
         "68.2",
         "10327.1",
         "352179",
         "0.14",
         "0.19",
         "220.598",
         "248.568",
         "391.288",
         "193.316",
         "1718.993",
         "452000",
         "1239743",
         "82.1",
         "6.7839",
         "13.0116",
         "1.0366",
         "46.475",
         "19228.6",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "36",
         "16241.78",
         "15536.4",
         "18024.114999999947",
         "-0.9350162426854148",
         "-0.3546048870425359",
         "734025"
        ],
        [
         "32",
         "1",
         "1",
         "1",
         "151315",
         "19354.23",
         "0",
         "No Holiday",
         "0.1090842587659851",
         "0.0",
         "1123.6639892578123",
         "12.88879108428955",
         "21.0568",
         "22.7781",
         "13.534",
         "71.1968",
         "9.0613",
         "7.1878",
         "2.1969",
         "5.4776",
         "41.606",
         "30.3293",
         "73.63",
         "53.8",
         "57.9",
         "55.35",
         "51.5",
         "55.1",
         "68.2",
         "10327.1",
         "352179",
         "0.154",
         "0.19",
         "220.598",
         "248.568",
         "391.288",
         "193.316",
         "1718.993",
         "444000",
         "1239743",
         "82.1",
         "6.7377",
         "12.8238",
         "1.0276",
         "46.132",
         "19462.0",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "37",
         "18194.74",
         "15740.13",
         "19037.64833333323",
         "-0.970941817426052",
         "-0.2393156642875577",
         "734032"
        ],
        [
         "33",
         "1",
         "1",
         "1",
         "151315",
         "18122.52",
         "0",
         "No Holiday",
         "0.0345631256778978",
         "0.0",
         "1138.05400390625",
         "13.121766471862792",
         "21.1013",
         "22.902",
         "13.596",
         "70.7026",
         "9.1547",
         "7.1604",
         "2.2218",
         "5.496",
         "41.4859",
         "30.6951",
         "74.63",
         "53.8",
         "57.9",
         "55.35",
         "51.5",
         "53.6",
         "68.2",
         "10327.1",
         "352179",
         "0.162",
         "0.19",
         "220.598",
         "248.568",
         "391.288",
         "193.316",
         "1718.993",
         "459000",
         "1239743",
         "82.1",
         "6.7062",
         "12.6841",
         "1.0298",
         "45.492",
         "19285.8",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "38",
         "19354.23",
         "15793.87",
         "17846.616666666465",
         "-0.992708874098054",
         "-0.1205366802553235",
         "734039"
        ],
        [
         "34",
         "1",
         "1",
         "1",
         "151315",
         "20094.19",
         "0",
         "No Holiday",
         "0.1882550990706332",
         "0.0",
         "1144.4059814453126",
         "13.06657600402832",
         "21.4409",
         "23.5235",
         "14.242",
         "72.1514",
         "9.7507",
         "7.4488",
         "2.5621",
         "5.4892",
         "41.3695",
         "30.3449",
         "81.57",
         "54.7",
         "57.4",
         "54.4",
         "52.35",
         "53.7",
         "67.7",
         "10386.4",
         "356215",
         "0.16",
         "0.19",
         "220.911",
         "248.692",
         "391.926",
         "196.845",
         "1728.828",
         "459000",
         "1289287",
         "83.2",
         "6.6897",
         "12.5338",
         "1.0274",
         "44.75",
         "19354.2",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "39",
         "18122.52",
         "16241.78",
         "19699.750000000466",
         "-1.0",
         "-1.8369701987210292e-16",
         "734046"
        ],
        [
         "35",
         "1",
         "1",
         "1",
         "151315",
         "23388.03",
         "0",
         "No Holiday",
         "0.4254788669119128",
         "0.0",
         "1156.1920166015625",
         "13.231171798706054",
         "21.3342",
         "23.8342",
         "15.004",
         "73.8067",
         "9.6693",
         "7.7422",
         "3.0767",
         "5.3892",
         "41.689",
         "30.4316",
         "82.66",
         "54.7",
         "57.4",
         "55.65",
         "53.2",
         "53.7",
         "67.7",
         "10386.4",
         "356215",
         "0.126",
         "0.19",
         "220.911",
         "248.692",
         "391.926",
         "196.845",
         "1728.828",
         "446000",
         "1289287",
         "83.2",
         "6.6865",
         "12.5229",
         "1.0156",
         "44.372",
         "19466.0",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "40",
         "20094.19",
         "18194.74",
         "22771.806666666875",
         "-0.992708874098054",
         "0.1205366802553232",
         "734053"
        ],
        [
         "36",
         "1",
         "1",
         "1",
         "151315",
         "26978.34",
         "0",
         "No Holiday",
         "0.6840686135926075",
         "0.0",
         "1172.63798828125",
         "13.135930061340332",
         "21.8694",
         "24.3484",
         "15.908",
         "75.3418",
         "9.6813",
         "8.0582",
         "3.2483",
         "5.5033",
         "42.339",
         "31.0123",
         "81.23",
         "54.7",
         "57.4",
         "55.65",
         "53.2",
         "53.7",
         "67.7",
         "10386.4",
         "356215",
         "0.135",
         "0.19",
         "220.911",
         "248.692",
         "391.926",
         "196.845",
         "1728.828",
         "459000",
         "1289287",
         "83.2",
         "6.6567",
         "12.4074",
         "1.0071",
         "44.275",
         "19376.0",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "41",
         "23388.03",
         "19354.23",
         "26380.46500000172",
         "-0.970941817426052",
         "0.2393156642875573",
         "734060"
        ],
        [
         "37",
         "1",
         "1",
         "1",
         "151315",
         "25543.04",
         "0",
         "No Holiday",
         "1.1165128153395183",
         "0.0",
         "1178.4239990234375",
         "13.120789909362792",
         "22.529",
         "24.8061",
         "16.028",
         "74.9729",
         "9.436",
         "8.1199",
         "3.3451",
         "5.5788",
         "43.0014",
         "31.3365",
         "81.15",
         "54.7",
         "57.4",
         "55.65",
         "53.2",
         "54.1",
         "67.7",
         "10386.4",
         "356215",
         "0.138",
         "0.19",
         "220.911",
         "248.692",
         "391.926",
         "196.845",
         "1728.828",
         "444000",
         "1289287",
         "83.2",
         "6.6497",
         "12.4152",
         "1.0236",
         "44.316",
         "18794.8",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "42",
         "26978.34",
         "18122.52",
         "25038.92166666709",
         "-0.9350162426854148",
         "0.3546048870425355",
         "734067"
        ],
        [
         "38",
         "1",
         "1",
         "1",
         "151315",
         "38640.93",
         "0",
         "No Holiday",
         "1.9057271456365144",
         "0.0",
         "1184.15",
         "13.217982864379882",
         "22.6286",
         "23.9352",
         "17.736",
         "75.1286",
         "9.3587",
         "8.5644",
         "3.4475",
         "5.8529",
         "42.3093",
         "31.4682",
         "81.45",
         "54.7",
         "57.4",
         "55.65",
         "53.2",
         "54.1",
         "67.7",
         "10386.4",
         "356215",
         "0.134",
         "0.19",
         "220.911",
         "248.692",
         "391.926",
         "196.845",
         "1728.828",
         "432000",
         "1289287",
         "83.2",
         "6.6717",
         "12.3845",
         "1.0224",
         "44.426",
         "19408.2",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "43",
         "25543.04",
         "20094.19",
         "38162.273333335295",
         "-0.8854560256532101",
         "0.464723172043768",
         "734074"
        ],
        [
         "39",
         "1",
         "1",
         "1",
         "151315",
         "34238.88",
         "1",
         "Halloween",
         "2.627894999687552",
         "0.0",
         "1204.5639892578124",
         "13.410420227050782",
         "23.1423",
         "23.401",
         "19.204",
         "74.4194",
         "9.8413",
         "8.5557",
         "3.6384",
         "6.0408",
         "42.521",
         "31.7959",
         "86.85",
         "55.2",
         "58.9",
         "56.75",
         "54.3",
         "54.6",
         "71.6",
         "10433.6",
         "359450",
         "0.13",
         "0.19",
         "221.315",
         "248.993",
         "392.535",
         "198.783",
         "1728.828",
         "453000",
         "1200298",
         "82.9",
         "6.6717",
         "12.2776",
         "1.0071",
         "44.144",
         "19348.2",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "44",
         "38640.93",
         "23388.03",
         "34238.87999999896",
         "-0.822983865893657",
         "0.5680647467311548",
         "734081"
        ],
        [
         "40",
         "1",
         "1",
         "1",
         "151315",
         "19549.39",
         "1",
         "DST End",
         "3.154924249008164",
         "0.0",
         "1213.6219970703123",
         "13.330810356140136",
         "21.9286",
         "23.8797",
         "21.02",
         "74.8459",
         "9.8453",
         "8.3378",
         "3.5886",
         "5.9923",
         "42.634",
         "31.9911",
         "84.89",
         "55.2",
         "58.9",
         "56.75",
         "54.3",
         "54.6",
         "71.6",
         "10433.6",
         "359450",
         "0.13",
         "0.19",
         "221.315",
         "248.993",
         "392.535",
         "198.783",
         "1728.828",
         "434000",
         "1200298",
         "82.9",
         "6.648",
         "12.2463",
         "1.0032",
         "44.4",
         "19466.0",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "45",
         "34238.88",
         "26978.34",
         "19549.39000000013",
         "-0.7485107481711011",
         "0.6631226582407952",
         "734088"
        ],
        [
         "41",
         "1",
         "1",
         "1",
         "151315",
         "19552.84",
         "0",
         "No Holiday",
         "4.386724827062942",
         "0.0",
         "1190.219970703125",
         "13.204309272766114",
         "21.553",
         "23.6863",
         "21.988",
         "73.1202",
         "9.9093",
         "8.2216",
         "3.6937",
         "5.9829",
         "42.3975",
         "31.8264",
         "81.65",
         "55.2",
         "58.9",
         "56.75",
         "54.3",
         "54.6",
         "71.6",
         "10433.6",
         "359450",
         "0.144",
         "0.19",
         "221.315",
         "248.993",
         "392.535",
         "198.783",
         "1728.828",
         "432000",
         "1200298",
         "82.9",
         "6.6388",
         "12.3379",
         "1.0176",
         "45.22",
         "19355.8",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "46",
         "19549.39",
         "25543.04",
         "19552.840000000084",
         "-0.6631226582407955",
         "0.7485107481711007",
         "734095"
        ],
        [
         "42",
         "1",
         "1",
         "1",
         "151315",
         "18820.29",
         "1",
         "Thanksgiving, Black Friday",
         "5.618869620260623",
         "0.0",
         "1191.5799865722656",
         "13.175003051757812",
         "21.9659",
         "23.7055",
         "22.4925",
         "74.0361",
         "10.1567",
         "8.2347",
         "3.2822",
         "6.2545",
         "42.9523",
         "32.2129",
         "83.87",
         "55.2",
         "58.9",
         "56.75",
         "54.3",
         "55.5",
         "71.6",
         "10433.6",
         "359450",
         "0.155",
         "0.19",
         "221.315",
         "248.993",
         "392.535",
         "198.783",
         "1728.828",
         "407000",
         "1200298",
         "82.9",
         "6.6513",
         "12.4172",
         "1.0181",
         "45.645",
         "19404.4",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "47",
         "19552.84",
         "38640.93",
         "18820.29000000004",
         "-0.5680647467311559",
         "0.8229838658936564",
         "734102"
        ],
        [
         "43",
         "1",
         "1",
         "1",
         "151315",
         "22517.56",
         "1",
         "Small Business Saturday, Cyber Monday",
         "5.107847659609846",
         "0.0",
         "1204.1239990234376",
         "13.285385704040529",
         "23.3081",
         "23.4477",
         "22.834",
         "79.1374",
         "10.228",
         "8.4584",
         "3.157",
         "6.3642",
         "44.2687",
         "32.7899",
         "89.18",
         "53.9",
         "58.8",
         "56.8",
         "55.0",
         "55.3",
         "74.5",
         "10471.0",
         "361979",
         "0.162",
         "0.18",
         "221.556",
         "249.284",
         "393.514",
         "202.454",
         "1728.828",
         "432000",
         "1166081",
         "84.0",
         "6.6627",
         "12.4193",
         "1.0151",
         "45.382",
         "19463.0",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "48",
         "18820.29",
         "34238.88",
         "22517.56000000052",
         "-0.4647231720437684",
         "0.88545602565321",
         "734109"
        ],
        [
         "44",
         "1",
         "1",
         "1",
         "151315",
         "31497.65",
         "0",
         "No Holiday",
         "3.9891455154827615",
         "0.0",
         "1229.710009765625",
         "13.362656784057616",
         "25.1683",
         "23.8833",
         "23.39",
         "79.1238",
         "10.652",
         "8.8201",
         "3.0297",
         "6.6259",
         "45.0429",
         "34.8144",
         "87.81",
         "53.9",
         "58.8",
         "56.8",
         "55.0",
         "55.3",
         "74.5",
         "10471.0",
         "361979",
         "0.142",
         "0.18",
         "221.556",
         "249.284",
         "393.514",
         "202.454",
         "1728.828",
         "428000",
         "1166081",
         "84.0",
         "6.6531",
         "12.4351",
         "1.0088",
         "44.964",
         "19461.0",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "49",
         "22517.56",
         "19549.39",
         "31497.650000000373",
         "-0.3546048870425359",
         "0.9350162426854148",
         "734116"
        ],
        [
         "45",
         "1",
         "1",
         "1",
         "151315",
         "44912.86",
         "1",
         "Green Monday",
         "4.406478888570174",
         "0.0",
         "1240.8119873046876",
         "13.354933547973634",
         "24.6823",
         "24.365",
         "21.102",
         "79.2069",
         "10.624",
         "9.1818",
         "3.0989",
         "6.5478",
         "45.4318",
         "34.5657",
         "88.02",
         "53.9",
         "58.8",
         "56.8",
         "55.0",
         "56.8",
         "74.5",
         "10471.0",
         "361979",
         "0.136",
         "0.18",
         "221.556",
         "249.284",
         "393.514",
         "202.454",
         "1728.828",
         "425000",
         "1166081",
         "84.0",
         "6.6587",
         "12.4047",
         "1.006",
         "45.254",
         "19464.0",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "50",
         "31497.65",
         "19552.84",
         "44912.85999999964",
         "-0.2393156642875578",
         "0.970941817426052",
         "734123"
        ],
        [
         "46",
         "1",
         "1",
         "1",
         "151315",
         "55931.23",
         "1",
         "Super Saturday, Christmas Eve",
         "3.651959326226952",
         "0.0",
         "1254.3224792480469",
         "13.15762734413147",
         "23.9307",
         "24.9387",
         "20.635",
         "79.159",
         "10.7883",
         "9.3779",
         "3.1853",
         "6.7376",
         "45.3785",
         "35.0674",
         "90.915",
         "53.9",
         "58.8",
         "56.8",
         "55.0",
         "56.8",
         "74.5",
         "10471.0",
         "361979",
         "0.14",
         "0.18",
         "221.556",
         "249.284",
         "393.514",
         "202.454",
         "1728.828",
         "424000",
         "1166081",
         "84.0",
         "6.6556",
         "12.3622",
         "1.0147",
         "45.175",
         "19461.0",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "51",
         "44912.86",
         "18820.29",
         "55931.23000000045",
         "-0.1205366802553236",
         "0.992708874098054",
         "734130"
        ],
        [
         "47",
         "1",
         "1",
         "1",
         "151315",
         "19124.58",
         "1",
         "Christmas Day, New Year's Eve",
         "2.1237965108872454",
         "0.0",
         "1258.27001953125",
         "13.230185317993165",
         "24.1768",
         "25.2438",
         "20.494",
         "78.7832",
         "10.9973",
         "9.2736",
         "3.2815",
         "6.8223",
         "45.3221",
         "35.3501",
         "91.38",
         "53.9",
         "58.8",
         "56.8",
         "55.0",
         "56.8",
         "74.5",
         "10471.0",
         "361979",
         "0.1379999999999999",
         "0.18",
         "221.556",
         "249.284",
         "393.514",
         "202.454",
         "1728.828",
         "404000",
         "1166081",
         "84.0",
         "6.6188",
         "12.3677",
         "1.0026",
         "45.0075",
         "19460.0",
         "1.7",
         "3.94",
         "6.84",
         "1.61",
         "6.76",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2010",
         "52",
         "55931.23",
         "22517.56",
         "19124.580000000075",
         "6.432490598706546e-16",
         "1.0",
         "734137"
        ],
        [
         "48",
         "1",
         "1",
         "1",
         "151315",
         "15984.24",
         "0",
         "No Holiday",
         "0.5347496410160179",
         "0.0",
         "1272.79599609375",
         "13.347564888000488",
         "24.1287",
         "24.9222",
         "22.176",
         "79.0561",
         "10.736",
         "9.5079",
         "3.619",
         "6.9819",
         "45.2872",
         "36.0927",
         "88.07",
         "52.9",
         "57.2",
         "58.9",
         "57.1",
         "57.1",
         "74.2",
         "10514.3",
         "364394",
         "0.144",
         "0.17",
         "222.735",
         "249.621",
         "394.072",
         "204.232",
         "1741.477",
         "413000",
         "1222479",
         "85.2",
         "6.6069",
         "12.2369",
         "0.9944",
         "45.068",
         "19463.0",
         "1.46",
         "4.65",
         "6.1",
         "5.37",
         "5.02",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2011",
         "1",
         "19124.58",
         "31497.65",
         "15984.239999999292",
         "0.120536680255323",
         "0.992708874098054",
         "734144"
        ],
        [
         "49",
         "1",
         "1",
         "1",
         "151315",
         "17359.7",
         "0",
         "No Holiday",
         "0.1599136311145403",
         "0.0",
         "1281.43798828125",
         "13.381450271606443",
         "23.082",
         "25.3947",
         "24.512",
         "80.3103",
         "10.3867",
         "9.7509",
         "3.6854",
         "7.0355",
         "44.9494",
         "36.4788",
         "91.53",
         "52.9",
         "57.2",
         "58.9",
         "57.1",
         "57.1",
         "74.2",
         "10514.3",
         "364394",
         "0.15",
         "0.17",
         "222.735",
         "249.621",
         "394.072",
         "204.232",
         "1741.477",
         "434000",
         "1222479",
         "85.2",
         "6.6101",
         "12.1245",
         "0.9891",
         "45.178",
         "19397.4",
         "1.46",
         "4.65",
         "6.1",
         "5.37",
         "5.02",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2011",
         "2",
         "15984.24",
         "44912.86",
         "17359.70000000077",
         "0.2393156642875577",
         "0.970941817426052",
         "734151"
        ]
       ],
       "shape": {
        "columns": 63,
        "rows": 421570
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>dept</th>\n",
       "      <th>type</th>\n",
       "      <th>size</th>\n",
       "      <th>weekly_sales</th>\n",
       "      <th>isholiday</th>\n",
       "      <th>holiday_name</th>\n",
       "      <th>holidayimpact</th>\n",
       "      <th>us_tax_return</th>\n",
       "      <th>sp500_weekly_mean_close</th>\n",
       "      <th>...</th>\n",
       "      <th>markdown4</th>\n",
       "      <th>markdown5</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyr</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_4</th>\n",
       "      <th>lag_52</th>\n",
       "      <th>week_sin</th>\n",
       "      <th>week_cos</th>\n",
       "      <th>date_ordinal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>151315</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>0.890916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1083.817969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>24073.921667</td>\n",
       "      <td>24073.921667</td>\n",
       "      <td>24073.921667</td>\n",
       "      <td>0.568065</td>\n",
       "      <td>8.229839e-01</td>\n",
       "      <td>733808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>151315</td>\n",
       "      <td>46039.49</td>\n",
       "      <td>1</td>\n",
       "      <td>Super Bowl</td>\n",
       "      <td>0.994415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1069.873999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>24924.500000</td>\n",
       "      <td>44830.550000</td>\n",
       "      <td>44830.550000</td>\n",
       "      <td>0.663123</td>\n",
       "      <td>7.485107e-01</td>\n",
       "      <td>733815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>151315</td>\n",
       "      <td>41595.55</td>\n",
       "      <td>1</td>\n",
       "      <td>Valentine's Day, Presidents' Day</td>\n",
       "      <td>0.716942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1102.575012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>46039.490000</td>\n",
       "      <td>41268.231667</td>\n",
       "      <td>41268.231667</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>6.631227e-01</td>\n",
       "      <td>733822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>151315</td>\n",
       "      <td>19403.54</td>\n",
       "      <td>0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>0.084079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1103.055981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>41595.550000</td>\n",
       "      <td>19270.190000</td>\n",
       "      <td>19270.190000</td>\n",
       "      <td>0.822984</td>\n",
       "      <td>5.680647e-01</td>\n",
       "      <td>733829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>151315</td>\n",
       "      <td>21827.90</td>\n",
       "      <td>0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>0.188255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1122.895996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>19403.540000</td>\n",
       "      <td>24924.500000</td>\n",
       "      <td>21613.615000</td>\n",
       "      <td>0.885456</td>\n",
       "      <td>4.647232e-01</td>\n",
       "      <td>733836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421565</th>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>118221</td>\n",
       "      <td>508.37</td>\n",
       "      <td>0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>0.109084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1443.923999</td>\n",
       "      <td>...</td>\n",
       "      <td>1601.01</td>\n",
       "      <td>3288.25</td>\n",
       "      <td>2012</td>\n",
       "      <td>39</td>\n",
       "      <td>467.300000</td>\n",
       "      <td>346.040000</td>\n",
       "      <td>727.050000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>734774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421566</th>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>118221</td>\n",
       "      <td>628.10</td>\n",
       "      <td>0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>0.317329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1452.712012</td>\n",
       "      <td>...</td>\n",
       "      <td>2253.43</td>\n",
       "      <td>2340.01</td>\n",
       "      <td>2012</td>\n",
       "      <td>40</td>\n",
       "      <td>508.370000</td>\n",
       "      <td>352.440000</td>\n",
       "      <td>894.980000</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>1.205367e-01</td>\n",
       "      <td>734781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421567</th>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>118221</td>\n",
       "      <td>1061.02</td>\n",
       "      <td>0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>0.575919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1438.269995</td>\n",
       "      <td>...</td>\n",
       "      <td>599.32</td>\n",
       "      <td>3990.54</td>\n",
       "      <td>2012</td>\n",
       "      <td>41</td>\n",
       "      <td>628.100000</td>\n",
       "      <td>605.960000</td>\n",
       "      <td>996.400000</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>2.393157e-01</td>\n",
       "      <td>734788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421568</th>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>118221</td>\n",
       "      <td>760.01</td>\n",
       "      <td>0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>1.037342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1449.297998</td>\n",
       "      <td>...</td>\n",
       "      <td>437.73</td>\n",
       "      <td>1537.49</td>\n",
       "      <td>2012</td>\n",
       "      <td>42</td>\n",
       "      <td>1061.020000</td>\n",
       "      <td>467.300000</td>\n",
       "      <td>1058.840000</td>\n",
       "      <td>-0.935016</td>\n",
       "      <td>3.546049e-01</td>\n",
       "      <td>734795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421569</th>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>118221</td>\n",
       "      <td>1076.80</td>\n",
       "      <td>0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>1.876749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1416.117969</td>\n",
       "      <td>...</td>\n",
       "      <td>211.94</td>\n",
       "      <td>858.33</td>\n",
       "      <td>2012</td>\n",
       "      <td>43</td>\n",
       "      <td>760.010000</td>\n",
       "      <td>508.370000</td>\n",
       "      <td>1167.900000</td>\n",
       "      <td>-0.885456</td>\n",
       "      <td>4.647232e-01</td>\n",
       "      <td>734802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>421570 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        store  dept  type    size  weekly_sales  isholiday  \\\n",
       "0           1     1     1  151315      24924.50          0   \n",
       "1           1     1     1  151315      46039.49          1   \n",
       "2           1     1     1  151315      41595.55          1   \n",
       "3           1     1     1  151315      19403.54          0   \n",
       "4           1     1     1  151315      21827.90          0   \n",
       "...       ...   ...   ...     ...           ...        ...   \n",
       "421565     45    98     2  118221        508.37          0   \n",
       "421566     45    98     2  118221        628.10          0   \n",
       "421567     45    98     2  118221       1061.02          0   \n",
       "421568     45    98     2  118221        760.01          0   \n",
       "421569     45    98     2  118221       1076.80          0   \n",
       "\n",
       "                            holiday_name  holidayimpact  us_tax_return  \\\n",
       "0                             No Holiday       0.890916            0.0   \n",
       "1                             Super Bowl       0.994415            0.0   \n",
       "2       Valentine's Day, Presidents' Day       0.716942            0.0   \n",
       "3                             No Holiday       0.084079            0.0   \n",
       "4                             No Holiday       0.188255            0.0   \n",
       "...                                  ...            ...            ...   \n",
       "421565                        No Holiday       0.109084            0.0   \n",
       "421566                        No Holiday       0.317329            0.0   \n",
       "421567                        No Holiday       0.575919            0.0   \n",
       "421568                        No Holiday       1.037342            0.0   \n",
       "421569                        No Holiday       1.876749            0.0   \n",
       "\n",
       "        sp500_weekly_mean_close  ...  markdown4  markdown5  year  weekofyr  \\\n",
       "0                   1083.817969  ...       0.00       0.00  2010         5   \n",
       "1                   1069.873999  ...       0.00       0.00  2010         6   \n",
       "2                   1102.575012  ...       0.00       0.00  2010         7   \n",
       "3                   1103.055981  ...       0.00       0.00  2010         8   \n",
       "4                   1122.895996  ...       0.00       0.00  2010         9   \n",
       "...                         ...  ...        ...        ...   ...       ...   \n",
       "421565              1443.923999  ...    1601.01    3288.25  2012        39   \n",
       "421566              1452.712012  ...    2253.43    2340.01  2012        40   \n",
       "421567              1438.269995  ...     599.32    3990.54  2012        41   \n",
       "421568              1449.297998  ...     437.73    1537.49  2012        42   \n",
       "421569              1416.117969  ...     211.94     858.33  2012        43   \n",
       "\n",
       "               lag_1         lag_4        lag_52  week_sin      week_cos  \\\n",
       "0       24073.921667  24073.921667  24073.921667  0.568065  8.229839e-01   \n",
       "1       24924.500000  44830.550000  44830.550000  0.663123  7.485107e-01   \n",
       "2       46039.490000  41268.231667  41268.231667  0.748511  6.631227e-01   \n",
       "3       41595.550000  19270.190000  19270.190000  0.822984  5.680647e-01   \n",
       "4       19403.540000  24924.500000  21613.615000  0.885456  4.647232e-01   \n",
       "...              ...           ...           ...       ...           ...   \n",
       "421565    467.300000    346.040000    727.050000 -1.000000 -1.836970e-16   \n",
       "421566    508.370000    352.440000    894.980000 -0.992709  1.205367e-01   \n",
       "421567    628.100000    605.960000    996.400000 -0.970942  2.393157e-01   \n",
       "421568   1061.020000    467.300000   1058.840000 -0.935016  3.546049e-01   \n",
       "421569    760.010000    508.370000   1167.900000 -0.885456  4.647232e-01   \n",
       "\n",
       "        date_ordinal  \n",
       "0             733808  \n",
       "1             733815  \n",
       "2             733822  \n",
       "3             733829  \n",
       "4             733836  \n",
       "...              ...  \n",
       "421565        734774  \n",
       "421566        734781  \n",
       "421567        734788  \n",
       "421568        734795  \n",
       "421569        734802  \n",
       "\n",
       "[421570 rows x 63 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = df_wm_train_pruned\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2e34fafe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T02:02:11.454462Z",
     "iopub.status.busy": "2025-06-27T02:02:11.453851Z",
     "iopub.status.idle": "2025-06-27T02:02:11.866044Z",
     "shell.execute_reply": "2025-06-27T02:02:11.865426Z",
     "shell.execute_reply.started": "2025-06-27T02:02:11.454436Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First date in series: 2010-02-05\n",
      "Last date in series: 2012-10-26\n"
     ]
    }
   ],
   "source": [
    "df_merged['date'] = df_wm_train_pruned['date_ordinal'].apply(lambda x: datetime.fromordinal(int(x)))\n",
    "\n",
    "# Verify the resulting date range\n",
    "min_date = df_merged['date'].min()\n",
    "max_date = df_merged['date'].max()\n",
    "\n",
    "print(f\"First date in series: {min_date.date()}\")\n",
    "print(f\"Last date in series: {max_date.date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ed184ad3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T02:02:15.031484Z",
     "iopub.status.busy": "2025-06-27T02:02:15.030654Z",
     "iopub.status.idle": "2025-06-27T02:02:15.221158Z",
     "shell.execute_reply": "2025-06-27T02:02:15.220413Z",
     "shell.execute_reply.started": "2025-06-27T02:02:15.031447Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 2010-02-05 → 2011-10-28 (267184 rows)\n",
      "Test set:     2011-11-04 → 2012-10-26 (154386 rows)\n",
      "Rows in training set : 267,184  ( 63.4 %)\n",
      "Rows in test set     : 154,386  ( 36.6 %)\n"
     ]
    }
   ],
   "source": [
    "df = df_merged.copy()\n",
    "\n",
    "# cutoff as 52 weeks before the last date\n",
    "last_date = df['date'].max()\n",
    "cutoff   = last_date - pd.Timedelta(weeks=52)\n",
    "\n",
    "# split\n",
    "train = df[df['date'] <= cutoff]\n",
    "test  = df[df['date'] >  cutoff]\n",
    "\n",
    "print(f\"Training set: {train['date'].min().date()} → {train['date'].max().date()} ({len(train)} rows)\")\n",
    "print(f\"Test set:     {test['date'].min().date()} → {test['date'].max().date()} ({len(test)} rows)\")\n",
    "\n",
    "\n",
    "# What share of rows are in TRAIN vs TEST?\n",
    "\n",
    "total_rows  = len(train) + len(test)\n",
    "train_pct   = len(train) / total_rows * 100\n",
    "test_pct    = len(test)  / total_rows * 100\n",
    "\n",
    "\n",
    "print(f\"Rows in training set : {len(train):,}  ({train_pct:5.1f} %)\")\n",
    "print(f\"Rows in test set     : {len(test):,}  ({test_pct:5.1f} %)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ee5f09b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T02:02:17.449303Z",
     "iopub.status.busy": "2025-06-27T02:02:17.449024Z",
     "iopub.status.idle": "2025-06-27T02:02:17.519193Z",
     "shell.execute_reply": "2025-06-27T02:02:17.518405Z",
     "shell.execute_reply.started": "2025-06-27T02:02:17.449283Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['weekly_sales', 'date', 'holiday_name'])\n",
    "y_train = train['weekly_sales']\n",
    "\n",
    "X_test  = test.drop(columns=['weekly_sales', 'date', 'holiday_name'])\n",
    "y_test  = test['weekly_sales']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d414cc",
   "metadata": {},
   "source": [
    "#### Custome Evaluation metric (WMAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4c9f20f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T02:02:21.643566Z",
     "iopub.status.busy": "2025-06-27T02:02:21.643066Z",
     "iopub.status.idle": "2025-06-27T02:02:21.648403Z",
     "shell.execute_reply": "2025-06-27T02:02:21.647691Z",
     "shell.execute_reply.started": "2025-06-27T02:02:21.643541Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ish = train['isholiday']   # 0/1 Series indexed same as X_train, y_train\n",
    "\n",
    "def weight_fn(idx_labels):\n",
    "    \"\"\"\n",
    "    idx_labels: an Index of row‐labels from y_true\n",
    "    returns an array of 5s and 1s matching those labels.\n",
    "    \"\"\"\n",
    "    # .loc uses the actual labels (dates + store/dept multi‐index, if any)\n",
    "    return np.where(ish.loc[idx_labels] == 1, 5, 1)\n",
    "\n",
    "# Two‐arg WMAE that ModelTrainer expects\n",
    "def wmae_custom(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    y_true: pd.Series\n",
    "    y_pred: np.ndarray (same length)\n",
    "    \"\"\"\n",
    "    w = weight_fn(y_true.index)\n",
    "    # now compute weighted MAE\n",
    "    return (w * np.abs(y_true - y_pred)).sum() / w.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370e57b8",
   "metadata": {},
   "source": [
    "#### LightGBM Hyper Parameters Search . CV Estimate (used to choose hyper-parameters faster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9373a3d8",
   "metadata": {},
   "source": [
    "##### LightGBM Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7d25d820",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.423477Z",
     "iopub.status.idle": "2025-06-26T22:10:14.423808Z",
     "shell.execute_reply": "2025-06-26T22:10:14.423645Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.42363Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "def lgb_pipeline_factory(params):\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\",  lgb.LGBMRegressor(**params, random_state=7, n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "trainer = ModelTrainer(\n",
    "    X             = X_train,\n",
    "    y             = y_train,\n",
    "    model_factory = lgb_pipeline_factory, \n",
    "    search        = 'random',\n",
    "    param_grid    = {\n",
    "        'num_leaves':       [31, 50, 100, 150, 200],\n",
    "        'max_depth':        [-1, 5, 10, 15, 20],\n",
    "        'learning_rate':    [0.01, 0.05, 0.1],\n",
    "        'n_estimators':     [100, 300, 500],\n",
    "        'feature_fraction': [0.6, 0.8, 1.0],\n",
    "        'bagging_fraction': [0.6, 0.8, 1.0],\n",
    "        'bagging_freq':     [0, 5, 10],\n",
    "        'min_child_samples':[5, 10, 20, 50],\n",
    "        # new regularization / split-gain params:\n",
    "        'min_split_gain':   [0, 0.1, 0.5, 1.0],\n",
    "        'lambda_l1':        [0, 0.1, 0.5, 1.0],\n",
    "        'lambda_l2':        [0, 0.1, 0.5, 1.0],\n",
    "    },\n",
    "    n_iter           = 50,\n",
    "    cv_splitter      = TimeSeriesSplit(n_splits=2),\n",
    "    custom_metrics   = {'wmae': wmae_custom},\n",
    "    log_path         = 'csv_files/ml_train_data/lgbm_random_wmae01.csv',\n",
    "    model_name       = 'LGBM_WMAE',\n",
    "    problem_type     = 'reg',\n",
    "    n_jobs           = -1,\n",
    "    random_state     = 7\n",
    ")\n",
    "\n",
    "\n",
    "# Run the search\n",
    "best_params, best_score = trainer.train()\n",
    "print(\" Best params:\", best_params)\n",
    "print(\" Best WMAE:  \", best_score)\n",
    "\n",
    "# explicitly close the CSV handle\n",
    "trainer.csv_file.close()\n",
    "# drop the trainer object and force garbage collection\n",
    "del trainer\n",
    "import gc; gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4925be82",
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-26T22:16:29.763Z",
     "iopub.status.busy": "2025-06-26T22:10:14.425126Z",
     "iopub.status.idle": "2025-06-26T22:10:14.425582Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "lgbm_random_wmae01 = pd.read_csv('csv_files/ml_train_data/lgbm_random_wmae01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "41d9c30b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.430086Z",
     "iopub.status.idle": "2025-06-26T22:10:14.430333Z",
     "shell.execute_reply": "2025-06-26T22:10:14.430229Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.430219Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df = lgbm_random_wmae01.copy()             \n",
    "\n",
    "params_df = (\n",
    "    df['param_json']\n",
    "    .apply(lambda s: json.loads(s) if pd.notnull(s) else {})  \n",
    "    .apply(pd.Series)                                         \n",
    ")\n",
    "df = pd.concat([df, params_df], axis=1)\n",
    "\n",
    "metric = 'wmae'\n",
    "ignore = {'model_name', 'param_json',            \n",
    "          'mae', 'rmse', 'r2', metric, '__source__'}\n",
    "\n",
    "param_cols = [c for c in df.columns if c not in ignore]\n",
    "\n",
    "# keep only numeric hyper-params\n",
    "X = df[param_cols].select_dtypes(include=[np.number])\n",
    "y = df[metric]\n",
    "\n",
    "# guard against “empty X” (all NaNs / non-numeric)\n",
    "if X.shape[1] == 0:\n",
    "    raise ValueError(\"No numeric hyper-parameter columns left after filtering!\")\n",
    "\n",
    "# urrogate model + analyses \n",
    "rf = RandomForestRegressor(n_estimators=200, random_state=7, n_jobs=-1)\n",
    "rf.fit(X, y)\n",
    "\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "print(\"→ RF importances:\\n\", importances.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "perm = permutation_importance(rf, X, y, n_repeats=10, random_state=7, n_jobs=-1)\n",
    "perm_imp = pd.Series(perm.importances_mean, index=X.columns)\n",
    "print(\"→ Permutation importances:\\n\", perm_imp.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "# partial-dependence plots \n",
    "top = importances.sort_values(ascending=False).index[:]\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(32, 32), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, feat in zip(axes, top):\n",
    "    PartialDependenceDisplay.from_estimator(rf, X, [feat], ax=ax)\n",
    "    ax.set_title(f\"PDP: {feat}\")\n",
    "\n",
    "for ax in axes[len(top):]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b7150b09",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.431215Z",
     "iopub.status.idle": "2025-06-26T22:10:14.431482Z",
     "shell.execute_reply": "2025-06-26T22:10:14.431347Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.431337Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "def lgb_pipeline_factory(params):\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\",  lgb.LGBMRegressor(**params, random_state=7, n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "trainer = ModelTrainer(\n",
    "    X             = X_train,\n",
    "    y             = y_train,\n",
    "    model_factory = lgb_pipeline_factory, \n",
    "    search        = 'random',\n",
    "    param_grid    = {\n",
    "        'num_leaves':       [150],\n",
    "        'max_depth':        [0, 100, 200],\n",
    "        'learning_rate':    [0.1],\n",
    "        'n_estimators':     [500],\n",
    "        'feature_fraction': [1],\n",
    "        'bagging_fraction': [1],\n",
    "        'bagging_freq':     [0, 20, 40],\n",
    "        'min_child_samples':[1],\n",
    "        # new regularization / split-gain params:\n",
    "        'min_split_gain':   [3,4,5],\n",
    "        'lambda_l1':        [0.1],\n",
    "        'lambda_l2':        [3,4,5],\n",
    "    },\n",
    "    n_iter           = 100,\n",
    "    cv_splitter      = TimeSeriesSplit(n_splits=2),\n",
    "    custom_metrics   = {'wmae': wmae_custom},\n",
    "    log_path         = 'csv_files/ml_train_data/lgbm_random_wmae03.csv',\n",
    "    model_name       = 'LGBM_WMAE',\n",
    "    problem_type     = 'reg',\n",
    "    n_jobs           = -1,\n",
    "    random_state     = 7\n",
    ")\n",
    "\n",
    "# Run the search\n",
    "best_params, best_score = trainer.train()\n",
    "print(\" Best params:\", best_params)\n",
    "print(\" Best WMAE:  \", best_score)\n",
    "\n",
    "# explicitly close the CSV handle\n",
    "trainer.csv_file.close()\n",
    "# drop the trainer object and force garbage collection\n",
    "del trainer\n",
    "import gc; gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a4413578",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.433164Z",
     "iopub.status.idle": "2025-06-26T22:10:14.43367Z",
     "shell.execute_reply": "2025-06-26T22:10:14.433552Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.433539Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "lgbm_random_wmae02 = pd.read_csv('csv_files/ml_train_data/lgbm_random_wmae02.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2f2bbfcb",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.436195Z",
     "iopub.status.idle": "2025-06-26T22:10:14.436538Z",
     "shell.execute_reply": "2025-06-26T22:10:14.436367Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.436353Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "# load & explode both CSVs if you haven’t yet —\n",
    "paths = [\n",
    "    'csv_files/ml_train_data/lgbm_random_wmae01.csv',\n",
    "    'csv_files/ml_train_data/lgbm_random_wmae02.csv',\n",
    "]\n",
    "dfs = []\n",
    "for path in paths:\n",
    "    df = pd.read_csv(path)\n",
    "    params = df['param_json'].apply(json.loads).apply(pd.Series)\n",
    "    df = pd.concat([df.drop(columns='param_json'), params], axis=1)\n",
    "    df['__source__'] = path.split('/')[-1]\n",
    "    dfs.append(df)\n",
    "df_all = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "49786d56",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.437247Z",
     "iopub.status.idle": "2025-06-26T22:10:14.437582Z",
     "shell.execute_reply": "2025-06-26T22:10:14.437427Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.437412Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "# choose metric & hyper‐param cols, drop any non‐numeric ones —\n",
    "metric = 'wmae'\n",
    "ignore = {'model_name','mae','rmse','r2', metric, '__source__'}\n",
    "param_cols = [c for c in df_all.columns if c not in ignore]\n",
    "\n",
    "# keep only numeric hyperparams\n",
    "X = df_all[param_cols].select_dtypes(include=[np.number])\n",
    "y = df_all[metric]\n",
    "\n",
    "# train surrogate —\n",
    "rf = RandomForestRegressor(n_estimators=200, random_state=7, n_jobs=-1)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# RF importances\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "print(\"→ RF importances:\\n\", importances.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "# permutation importances\n",
    "perm = permutation_importance(rf, X, y, n_repeats=10, random_state=7, n_jobs=-1)\n",
    "perm_imp = pd.Series(perm.importances_mean, index=X.columns)\n",
    "print(\"→ Permutation importances:\\n\", perm_imp.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "# partial dependence plots for top-3 features, all in one figure —\n",
    "top = importances.sort_values(ascending=False).index[:].tolist()\n",
    "\n",
    "fig, axes = plt.subplots(4, 4 ,figsize=(32, 32), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, feat in zip(axes, top):\n",
    "    PartialDependenceDisplay.from_estimator(rf, X, [feat], ax=ax)\n",
    "    ax.set_title(f\"PDP: {feat}\")\n",
    "\n",
    "# turn off the last (unused) subplot\n",
    "axes[-1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c70bccdb",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.443575Z",
     "iopub.status.idle": "2025-06-26T22:10:14.444116Z",
     "shell.execute_reply": "2025-06-26T22:10:14.443833Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.443816Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "def lgb_pipeline_factory(params):\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\",  lgb.LGBMRegressor(**params, random_state=7, n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "trainer = ModelTrainer(\n",
    "    X             = X_train,\n",
    "    y             = y_train,\n",
    "    model_factory = lgb_pipeline_factory, \n",
    "    search        = 'random',\n",
    "    param_grid    = {\n",
    "        'num_leaves':       [150],\n",
    "        'max_depth':        [0],\n",
    "        'learning_rate':    [0.1, 0.2, 0.3, 0.4],\n",
    "        'n_estimators':     [500,600,700,800],\n",
    "        'feature_fraction': [1],\n",
    "        'bagging_fraction': [1],\n",
    "        'bagging_freq':     [0],\n",
    "        'min_child_samples':[1],\n",
    "        # new regularization / split-gain params:\n",
    "        'min_split_gain':   [3],\n",
    "        'lambda_l1':        [0.1],\n",
    "        'lambda_l2':        [4, 6, 7],\n",
    "    },\n",
    "    n_iter           = 100,\n",
    "    cv_splitter      = TimeSeriesSplit(n_splits=2),\n",
    "    custom_metrics   = {'wmae': wmae_custom},\n",
    "    log_path         = 'csv_files/ml_train_data/lgbm_random_wmae03.csv',\n",
    "    model_name       = 'LGBM_WMAE',\n",
    "    problem_type     = 'reg',\n",
    "    n_jobs           = -1,\n",
    "    random_state     = 7\n",
    ")\n",
    "\n",
    "# Run the search\n",
    "best_params, best_score = trainer.train()\n",
    "print(\" Best params:\", best_params)\n",
    "print(\" Best WMAE:  \", best_score)\n",
    "\n",
    "# explicitly close the CSV handle\n",
    "trainer.csv_file.close()\n",
    "# drop the trainer object and force garbage collection\n",
    "del trainer\n",
    "import gc; gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b469c2a9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.450693Z",
     "iopub.status.idle": "2025-06-26T22:10:14.451096Z",
     "shell.execute_reply": "2025-06-26T22:10:14.450926Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.45091Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "# load & explode both CSVs if you haven’t yet —\n",
    "paths = [\n",
    "    'csv_files/ml_train_data/lgbm_random_wmae01.csv',\n",
    "    'csv_files/ml_train_data/lgbm_random_wmae02.csv',\n",
    "    'csv_files/ml_train_data/lgbm_random_wmae03.csv',\n",
    "]\n",
    "dfs = []\n",
    "for path in paths:\n",
    "    df = pd.read_csv(path)\n",
    "    params = df['param_json'].apply(json.loads).apply(pd.Series)\n",
    "    df = pd.concat([df.drop(columns='param_json'), params], axis=1)\n",
    "    df['__source__'] = path.split('/')[-1]\n",
    "    dfs.append(df)\n",
    "df_all = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e0d6365f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.455226Z",
     "iopub.status.idle": "2025-06-26T22:10:14.455565Z",
     "shell.execute_reply": "2025-06-26T22:10:14.455444Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.455428Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "# choose metric & hyper‐param cols, drop any non‐numeric ones —\n",
    "metric = 'wmae'\n",
    "ignore = {'model_name','mae','rmse','r2', metric, '__source__'}\n",
    "param_cols = [c for c in df_all.columns if c not in ignore]\n",
    "\n",
    "# keep only numeric hyperparams\n",
    "X = df_all[param_cols].select_dtypes(include=[np.number])\n",
    "y = df_all[metric]\n",
    "\n",
    "# train surrogate —\n",
    "rf = RandomForestRegressor(n_estimators=200, random_state=7, n_jobs=-1)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# RF importances\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "print(\"→ RF importances:\\n\", importances.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "# permutation importances\n",
    "perm = permutation_importance(rf, X, y, n_repeats=10, random_state=7, n_jobs=-1)\n",
    "perm_imp = pd.Series(perm.importances_mean, index=X.columns)\n",
    "print(\"→ Permutation importances:\\n\", perm_imp.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "# partial dependence plots for top-3 features, all in one figure —\n",
    "top = importances.sort_values(ascending=False).index[:].tolist()\n",
    "\n",
    "fig, axes = plt.subplots(4, 4 ,figsize=(32, 32), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, feat in zip(axes, top):\n",
    "    PartialDependenceDisplay.from_estimator(rf, X, [feat], ax=ax)\n",
    "    ax.set_title(f\"PDP: {feat}\")\n",
    "\n",
    "# turn off the last (unused) subplot\n",
    "axes[-1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6c4ddffb",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.456607Z",
     "iopub.status.idle": "2025-06-26T22:10:14.457098Z",
     "shell.execute_reply": "2025-06-26T22:10:14.456978Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.456962Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "def lgb_pipeline_factory(params):\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\",  lgb.LGBMRegressor(**params, random_state=7, n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "trainer = ModelTrainer(\n",
    "    X             = X_train,\n",
    "    y             = y_train,\n",
    "    model_factory = lgb_pipeline_factory, \n",
    "    search        = 'random',\n",
    "    param_grid    = {\n",
    "        'num_leaves':       [150],\n",
    "        'max_depth':        [0],\n",
    "        'learning_rate':    [0.1],\n",
    "        'n_estimators':     [500],\n",
    "        'feature_fraction': [1],\n",
    "        'bagging_fraction': [1],\n",
    "        'bagging_freq':     [0],\n",
    "        'min_child_samples':[0],\n",
    "        # new regularization / split-gain params:\n",
    "        'min_split_gain':   [3],\n",
    "        'lambda_l1':        [0.1],\n",
    "        'lambda_l2':        [6, 8, 9, 10, 11, 12],\n",
    "    },\n",
    "    n_iter           = 100,\n",
    "    cv_splitter      = TimeSeriesSplit(n_splits=2),\n",
    "    custom_metrics   = {'wmae': wmae_custom},\n",
    "    log_path         = 'csv_files/ml_train_data/lgbm_random_wmae04.csv',\n",
    "    model_name       = 'LGBM_WMAE',\n",
    "    problem_type     = 'reg',\n",
    "    n_jobs           = -1,\n",
    "    random_state     = 7\n",
    ")\n",
    "\n",
    "# Run the search\n",
    "best_params, best_score = trainer.train()\n",
    "print(\" Best params:\", best_params)\n",
    "print(\" Best WMAE:  \", best_score)\n",
    "\n",
    "# explicitly close the CSV handle\n",
    "trainer.csv_file.close()\n",
    "# drop the trainer object and force garbage collection\n",
    "del trainer\n",
    "import gc; gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1a383ae4",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.457915Z",
     "iopub.status.idle": "2025-06-26T22:10:14.458165Z",
     "shell.execute_reply": "2025-06-26T22:10:14.458038Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.458029Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "# load & explode both CSVs if you haven’t yet —\n",
    "paths = [\n",
    "    'csv_files/ml_train_data/lgbm_random_wmae01.csv',\n",
    "    'csv_files/ml_train_data/lgbm_random_wmae02.csv',\n",
    "    'csv_files/ml_train_data/lgbm_random_wmae03.csv',\n",
    "    'csv_files/ml_train_data/lgbm_random_wmae04.csv',\n",
    "\n",
    "]\n",
    "dfs = []\n",
    "for path in paths:\n",
    "    df = pd.read_csv(path)\n",
    "    params = df['param_json'].apply(json.loads).apply(pd.Series)\n",
    "    df = pd.concat([df.drop(columns='param_json'), params], axis=1)\n",
    "    df['__source__'] = path.split('/')[-1]\n",
    "    dfs.append(df)\n",
    "df_all = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f884f00c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.461264Z",
     "iopub.status.idle": "2025-06-26T22:10:14.461817Z",
     "shell.execute_reply": "2025-06-26T22:10:14.461563Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.461423Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "# choose metric & hyper‐param cols, drop any non‐numeric ones —\n",
    "metric = 'wmae'\n",
    "ignore = {'model_name','mae','rmse','r2', metric, '__source__'}\n",
    "param_cols = [c for c in df_all.columns if c not in ignore]\n",
    "\n",
    "# keep only numeric hyperparams\n",
    "X = df_all[param_cols].select_dtypes(include=[np.number])\n",
    "y = df_all[metric]\n",
    "\n",
    "# train surrogate —\n",
    "rf = RandomForestRegressor(n_estimators=200, random_state=7, n_jobs=-1)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# RF importances\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "print(\"→ RF importances:\\n\", importances.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "# permutation importances\n",
    "perm = permutation_importance(rf, X, y, n_repeats=10, random_state=7, n_jobs=-1)\n",
    "perm_imp = pd.Series(perm.importances_mean, index=X.columns)\n",
    "print(\"→ Permutation importances:\\n\", perm_imp.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "# partial dependence plots for top-3 features, all in one figure —\n",
    "top = importances.sort_values(ascending=False).index[:].tolist()\n",
    "\n",
    "fig, axes = plt.subplots(4, 4 ,figsize=(32, 32), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, feat in zip(axes, top):\n",
    "    PartialDependenceDisplay.from_estimator(rf, X, [feat], ax=ax)\n",
    "    ax.set_title(f\"PDP: {feat}\")\n",
    "\n",
    "# turn off the last (unused) subplot\n",
    "axes[-1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "37d8462a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.469962Z",
     "iopub.status.idle": "2025-06-26T22:10:14.470285Z",
     "shell.execute_reply": "2025-06-26T22:10:14.470152Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.47014Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_lgbm_random_04 = df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "21b3ecbe",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.47125Z",
     "iopub.status.idle": "2025-06-26T22:10:14.471607Z",
     "shell.execute_reply": "2025-06-26T22:10:14.47146Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.471445Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_lgbm_random_04.to_csv('csv_files/ml_train_data/df_lgbm_random_04.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "bcf2d254",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.473344Z",
     "iopub.status.idle": "2025-06-26T22:10:14.473702Z",
     "shell.execute_reply": "2025-06-26T22:10:14.47356Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.473544Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_lgbm_random_04 = pd.read_csv('csv_files/ml_train_data/df_lgbm_random_04.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f4c8a1",
   "metadata": {},
   "source": [
    "##### LightGBM Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49673cc4",
   "metadata": {},
   "source": [
    "Get best params from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "81db62ec",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.474662Z",
     "iopub.status.idle": "2025-06-26T22:10:14.476294Z",
     "shell.execute_reply": "2025-06-26T22:10:14.474841Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.474824Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df = df_lgbm_random_04.copy()\n",
    "\n",
    "# pick the row with the lowest WMAE\n",
    "best_row = df.loc[df['wmae'].idxmin()]\n",
    "\n",
    "# keep only the hyper-parameter columns\n",
    "non_params = {'model_name', 'mae', 'rmse', 'r2', 'wmae', '__source__'}\n",
    "param_series = best_row.drop(labels=non_params)\n",
    "\n",
    "# convert to a clean dict, turning floats like 500.0 → 500\n",
    "best_params = {\n",
    "    k: (int(v) if isinstance(v, (int, float)) and not math.isnan(v) and v.is_integer() else v)\n",
    "    for k, v in param_series.items()\n",
    "    if pd.notnull(v)                           # skip NaNs\n",
    "}\n",
    "\n",
    "\n",
    "best_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de16f4cf",
   "metadata": {},
   "source": [
    "Train best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d50c0e4a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.477465Z",
     "iopub.status.idle": "2025-06-26T22:10:14.477799Z",
     "shell.execute_reply": "2025-06-26T22:10:14.477648Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.477633Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "# Rebuild your best‐found model\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", lgb.LGBMRegressor(**best_params, random_state=7, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# 1) Fit on the entire training set\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# 2) Predict on the test set\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# 3) Compute standard metrics\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "# 4) Compute WMAE (holiday weeks weight=5, others=1)\n",
    "#    assumes you still have `test` DataFrame with 'holiday_name'\n",
    "weights = np.where(test['holiday_name'].notnull(), 5, 1)\n",
    "wmae    = (weights * np.abs(y_test - y_pred)).sum() / weights.sum()\n",
    "\n",
    "# 5) Print them all\n",
    "print(f\"Test MAE:   {mae:.4f}\")\n",
    "print(f\"Test RMSE:  {rmse:.4f}\")\n",
    "print(f\"Test R²:    {r2:.4f}\")\n",
    "print(f\"Test WMAE:  {wmae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd62ad4",
   "metadata": {},
   "source": [
    "Check what features were used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ddf1bdb6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.479022Z",
     "iopub.status.idle": "2025-06-26T22:10:14.479325Z",
     "shell.execute_reply": "2025-06-26T22:10:14.479199Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.479184Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "# grab the fitted LGBM from your pipeline\n",
    "model = pipe.named_steps['model']\n",
    "\n",
    "# make a Series of the importances\n",
    "fi = pd.Series(\n",
    "    model.feature_importances_,\n",
    "    index = X_train.columns\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "# print the top 10\n",
    "print(\"🌳 LightGBM split-gain importances:\")\n",
    "print(fi)\n",
    "\n",
    "# number of times the feature was used by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fdb39a",
   "metadata": {},
   "source": [
    "##### LGBM Retrain wihout not used features (Best Model to CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8d43ec05",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.480261Z",
     "iopub.status.idle": "2025-06-26T22:10:14.480595Z",
     "shell.execute_reply": "2025-06-26T22:10:14.480444Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.480427Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "cutoff  = df_merged.date.max() - pd.Timedelta(weeks=52)\n",
    "train   = df_merged[df_merged.date <= cutoff]\n",
    "test    = df_merged[df_merged.date >  cutoff]\n",
    "\n",
    "drop = [\n",
    "    'weekly_sales','date','holiday_name','year',\n",
    "    'markdown5','markdown1','markdown2','markdown3','markdown4',\n",
    "    'us_tax_india','us_tax_vietnam','us_tax_china','us_tax_canada'\n",
    "]\n",
    "\n",
    "X_train, y_train = train.drop(columns=drop), train.weekly_sales\n",
    "X_test,  y_test  = test .drop(columns=drop),  test .weekly_sales\n",
    "\n",
    "\n",
    "# Fit model, keep only used features\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\",  lgb.LGBMRegressor(**best_params, random_state=7, n_jobs=-1))\n",
    "])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "used_feats = X_train.columns[pipe.named_steps['model'].feature_importances_ > 0]\n",
    "pipe.fit(X_train[used_feats], y_train)\n",
    "\n",
    "\n",
    "# Predict & compute metrics\n",
    "\n",
    "y_pred  = pipe.predict(X_test[used_feats])\n",
    "\n",
    "mae     = mean_absolute_error(y_test, y_pred)\n",
    "rmse    = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2      = r2_score(y_test, y_pred)\n",
    "weights = np.where(test['holiday_name'].notnull(), 5, 1)\n",
    "wmae    = (weights * np.abs(y_test - y_pred)).sum() / weights.sum()\n",
    "\n",
    "\n",
    "row = {\n",
    "    \"model_name\": 'LGBM01',\n",
    "    **best_params,\n",
    "    \"mae\":  mae,\n",
    "    \"rmse\": rmse,\n",
    "    \"r2\":   r2,\n",
    "    \"wmae\": wmae\n",
    "}\n",
    "df_best_models = pd.DataFrame([row])\n",
    "\n",
    "df_best_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1217948b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.481803Z",
     "iopub.status.idle": "2025-06-26T22:10:14.482103Z",
     "shell.execute_reply": "2025-06-26T22:10:14.481986Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.481971Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_best_models.to_csv('csv_files/ml_train_data/df_best_models.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "903370b0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.483188Z",
     "iopub.status.idle": "2025-06-26T22:10:14.484009Z",
     "shell.execute_reply": "2025-06-26T22:10:14.483868Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.483848Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_best_models = pd.read_csv('csv_files/ml_train_data/df_best_models.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "60ca00b9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.486215Z",
     "iopub.status.idle": "2025-06-26T22:10:14.486538Z",
     "shell.execute_reply": "2025-06-26T22:10:14.486361Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.486346Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "# to merge new best model : \n",
    "results_df = pd.concat([results_df, df_best_models], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f153ce4",
   "metadata": {},
   "source": [
    "### XGBoostRegressor Hyper Parameters Search / CV Estimate (used to choose hyper-parameters faster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37252fb",
   "metadata": {},
   "source": [
    "##### XGBoost Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "85e2709d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.487456Z",
     "iopub.status.idle": "2025-06-26T22:10:14.487765Z",
     "shell.execute_reply": "2025-06-26T22:10:14.487656Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.487642Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "# Define an XGBoost pipeline factory\n",
    "def xgb_pipeline_factory(params):\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\",  XGBRegressor(**params, random_state=7, n_jobs=-1, verbosity=1))\n",
    "    ])\n",
    "\n",
    "# Set up the random search over a balanced grid of XGBoost hyper-params\n",
    "trainer = ModelTrainer(\n",
    "    X             = X_train,\n",
    "    y             = y_train,\n",
    "    model_factory = xgb_pipeline_factory, \n",
    "    search        = 'random',\n",
    "    param_grid    = {\n",
    "        'n_estimators':      [700,800,900],\n",
    "        'max_depth':         [10, 11, 12, 13],\n",
    "        'learning_rate':     [0.2, 0.3, 0.4, 0.5],\n",
    "        'subsample':         [1],\n",
    "        'colsample_bytree':  [0.7, 0.8, 0.9],\n",
    "        'gamma':             [0.01, 0.05 ,0.1],\n",
    "        'min_child_weight':  [1, 5, 10, 20],\n",
    "        'reg_alpha':         [1, 2, 3],\n",
    "        'reg_lambda':        [0.8, 1.0, 1.2],\n",
    "    },\n",
    "    n_iter           = 100,\n",
    "    cv_splitter      = TimeSeriesSplit(n_splits=3),\n",
    "    custom_metrics   = {'wmae': wmae_custom},\n",
    "    log_path         = 'csv_files/ml_train_data/xgb_random_wmae01.csv',\n",
    "    model_name       = 'XGB_WMAE',\n",
    "    problem_type     = 'reg',\n",
    "    n_jobs           = -1,\n",
    "    random_state     = 7\n",
    ")\n",
    "\n",
    "# Run the search\n",
    "best_params, best_score = trainer.train()\n",
    "print(\"Best params:\", best_params)\n",
    "print(\" Best WMAE:  \", best_score)\n",
    "\n",
    "# Clean up\n",
    "trainer.csv_file.close()\n",
    "del trainer\n",
    "import gc; gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "fced5b6a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.488747Z",
     "iopub.status.idle": "2025-06-26T22:10:14.488997Z",
     "shell.execute_reply": "2025-06-26T22:10:14.488893Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.488882Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "xgb_random_wmae01 = pd.read_csv('csv_files/ml_train_data/xgb_random_wmae01.csv')\n",
    "xgb_random_wmae01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ff092b55",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.490684Z",
     "iopub.status.idle": "2025-06-26T22:10:14.491156Z",
     "shell.execute_reply": "2025-06-26T22:10:14.4909Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.490884Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df = xgb_random_wmae01.copy()             \n",
    "\n",
    "params_df = (\n",
    "    df['param_json']\n",
    "    .apply(lambda s: json.loads(s) if pd.notnull(s) else {})  \n",
    "    .apply(pd.Series)                                         \n",
    ")\n",
    "df = pd.concat([df, params_df], axis=1)\n",
    "\n",
    "metric = 'wmae'\n",
    "ignore = {'model_name', 'param_json',            \n",
    "          'mae', 'rmse', 'r2', metric, '__source__'}\n",
    "\n",
    "param_cols = [c for c in df.columns if c not in ignore]\n",
    "\n",
    "# keep only numeric hyper-params\n",
    "X = df[param_cols].select_dtypes(include=[np.number])\n",
    "y = df[metric]\n",
    "\n",
    "# guard against “empty X” (all NaNs / non-numeric)\n",
    "if X.shape[1] == 0:\n",
    "    raise ValueError(\"No numeric hyper-parameter columns left after filtering!\")\n",
    "\n",
    "# urrogate model + analyses \n",
    "rf = RandomForestRegressor(n_estimators=200, random_state=7, n_jobs=-1)\n",
    "rf.fit(X, y)\n",
    "\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "print(\"→ RF importances:\\n\", importances.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "perm = permutation_importance(rf, X, y, n_repeats=10, random_state=7, n_jobs=-1)\n",
    "perm_imp = pd.Series(perm.importances_mean, index=X.columns)\n",
    "print(\"→ Permutation importances:\\n\", perm_imp.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "# partial-dependence plots \n",
    "top = importances.sort_values(ascending=False).index[:]\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(32, 32), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, feat in zip(axes, top):\n",
    "    PartialDependenceDisplay.from_estimator(rf, X, [feat], ax=ax)\n",
    "    ax.set_title(f\"PDP: {feat}\")\n",
    "\n",
    "for ax in axes[len(top):]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "73a322dd",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.493591Z",
     "iopub.status.idle": "2025-06-26T22:10:14.493858Z",
     "shell.execute_reply": "2025-06-26T22:10:14.493754Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.493742Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "# Define an XGBoost pipeline factory\n",
    "def xgb_pipeline_factory(params):\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\",  XGBRegressor(**params, random_state=7, n_jobs=-1, verbosity=1))\n",
    "    ])\n",
    "\n",
    "# Set up the random search over a balanced grid of XGBoost hyper-params\n",
    "trainer = ModelTrainer(\n",
    "    X             = X_train,\n",
    "    y             = y_train,\n",
    "    model_factory = xgb_pipeline_factory, \n",
    "    search        = 'random',\n",
    "    param_grid    = {\n",
    "        'n_estimators':      [200, 500, 700],\n",
    "        'max_depth':         [2,5,8,10],\n",
    "        'learning_rate':     [0, 0.05, 0.1, 0.2],\n",
    "        'subsample':         [0, 0.5, 1],\n",
    "        'colsample_bytree':  [0, 0.5, 0.8, 1],\n",
    "        'gamma':             [0 ,0.001],\n",
    "        'min_child_weight':  [0, 0.05, 0.1, 1],\n",
    "        'reg_alpha':         [0, 0.5, 5],\n",
    "        'reg_lambda':        [1.0],\n",
    "    },\n",
    "    n_iter           = 180,\n",
    "    cv_splitter      = TimeSeriesSplit(n_splits=3),\n",
    "    custom_metrics   = {'wmae': wmae_custom},\n",
    "    log_path         = 'csv_files/ml_train_data/xgb_random_wmae02.csv',\n",
    "    model_name       = 'XGB_WMAE',\n",
    "    problem_type     = 'reg',\n",
    "    n_jobs           = -1,\n",
    "    random_state     = 7\n",
    ")\n",
    "\n",
    "# 3) Run the search\n",
    "best_params, best_score = trainer.train()\n",
    "print(\"Best params:\", best_params)\n",
    "print(\" Best WMAE:  \", best_score)\n",
    "\n",
    "# 4) Clean up\n",
    "trainer.csv_file.close()\n",
    "del trainer\n",
    "import gc; gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "426646f6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.495171Z",
     "iopub.status.idle": "2025-06-26T22:10:14.495566Z",
     "shell.execute_reply": "2025-06-26T22:10:14.495382Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.495367Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "# load & explode both CSVs if you haven’t yet —\n",
    "paths = [\n",
    "    'csv_files/ml_train_data/xgb_random_wmae01.csv',\n",
    "    'csv_files/ml_train_data/xgb_random_wmae02.csv',\n",
    "]\n",
    "dfs = []\n",
    "for path in paths:\n",
    "    df = pd.read_csv(path)\n",
    "    params = df['param_json'].apply(json.loads).apply(pd.Series)\n",
    "    df = pd.concat([df.drop(columns='param_json'), params], axis=1)\n",
    "    df['__source__'] = path.split('/')[-1]\n",
    "    dfs.append(df)\n",
    "df_all = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ac5faf2b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.497021Z",
     "iopub.status.idle": "2025-06-26T22:10:14.497345Z",
     "shell.execute_reply": "2025-06-26T22:10:14.497237Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.497225Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "# choose metric & hyper‐param cols, drop any non‐numeric ones —\n",
    "metric = 'wmae'\n",
    "ignore = {'model_name','mae','rmse','r2', metric, '__source__'}\n",
    "param_cols = [c for c in df_all.columns if c not in ignore]\n",
    "\n",
    "# keep only numeric hyperparams\n",
    "X = df_all[param_cols].select_dtypes(include=[np.number])\n",
    "y = df_all[metric]\n",
    "\n",
    "# train surrogate —\n",
    "rf = RandomForestRegressor(n_estimators=200, random_state=7, n_jobs=-1)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# RF importances\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "print(\"→ RF importances:\\n\", importances.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "# permutation importances\n",
    "perm = permutation_importance(rf, X, y, n_repeats=10, random_state=7, n_jobs=-1)\n",
    "perm_imp = pd.Series(perm.importances_mean, index=X.columns)\n",
    "print(\"→ Permutation importances:\\n\", perm_imp.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "# partial dependence plots for top-3 features, all in one figure —\n",
    "top = importances.sort_values(ascending=False).index[:].tolist()\n",
    "\n",
    "fig, axes = plt.subplots(4, 4 ,figsize=(32, 32), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, feat in zip(axes, top):\n",
    "    PartialDependenceDisplay.from_estimator(rf, X, [feat], ax=ax)\n",
    "    ax.set_title(f\"PDP: {feat}\")\n",
    "\n",
    "# turn off the last (unused) subplot\n",
    "axes[-1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "27a5241d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.49831Z",
     "iopub.status.idle": "2025-06-26T22:10:14.498704Z",
     "shell.execute_reply": "2025-06-26T22:10:14.49853Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.498515Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_xgb_random_02 = df_all\n",
    "df_xgb_random_02.to_csv('csv_files/ml_train_data/df_xgb_random_02.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "a1d25595",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.499757Z",
     "iopub.status.idle": "2025-06-26T22:10:14.500111Z",
     "shell.execute_reply": "2025-06-26T22:10:14.49996Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.499945Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_xgb_random_02 = pd.read_csv('csv_files/ml_train_data/df_xgb_random_02.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d44af16",
   "metadata": {},
   "source": [
    "##### XGBoost Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61509a0",
   "metadata": {},
   "source": [
    "Get Best Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "14129844",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.501176Z",
     "iopub.status.idle": "2025-06-26T22:10:14.501941Z",
     "shell.execute_reply": "2025-06-26T22:10:14.501774Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.501756Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df = df_xgb_random_02.copy()\n",
    "\n",
    "# pick the row with the lowest WMAE\n",
    "best_row = df.loc[df['wmae'].idxmin()]\n",
    "\n",
    "# keep only the hyper-parameter columns\n",
    "non_params = {'model_name', 'mae', 'rmse', 'r2', 'wmae', '__source__'}\n",
    "param_series = best_row.drop(labels=non_params)\n",
    "\n",
    "# convert to a clean dict, turning floats like 500.0 → 500\n",
    "best_params = {\n",
    "    k: (int(v) if isinstance(v, (int, float)) and not math.isnan(v) and v.is_integer() else v)\n",
    "    for k, v in param_series.items()\n",
    "    if pd.notnull(v)                           # skip NaNs\n",
    "}\n",
    "\n",
    "\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dbe50e",
   "metadata": {},
   "source": [
    "Train Model with Best Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ec7d1cff",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.503328Z",
     "iopub.status.idle": "2025-06-26T22:10:14.503696Z",
     "shell.execute_reply": "2025-06-26T22:10:14.503543Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.503527Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "# Rebuild your best‐found model\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", XGBRegressor(**best_params, random_state=7, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# 1) Fit on the entire training set\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# 2) Predict on the test set\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# 3) Compute standard metrics\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "# 4) Compute WMAE (holiday weeks weight=5, others=1)\n",
    "#    assumes you still have `test` DataFrame with 'holiday_name'\n",
    "weights = np.where(test['holiday_name'].notnull(), 5, 1)\n",
    "wmae    = (weights * np.abs(y_test - y_pred)).sum() / weights.sum()\n",
    "\n",
    "# 5) Print them all\n",
    "print(f\"Test MAE:   {mae:.4f}\")\n",
    "print(f\"Test RMSE:  {rmse:.4f}\")\n",
    "print(f\"Test R²:    {r2:.4f}\")\n",
    "print(f\"Test WMAE:  {wmae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca6d13f",
   "metadata": {},
   "source": [
    "Check what features were most used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "21a3cc0e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.505112Z",
     "iopub.status.idle": "2025-06-26T22:10:14.50556Z",
     "shell.execute_reply": "2025-06-26T22:10:14.505364Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.505346Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "# grab the fitted LGBM from your pipeline\n",
    "model = pipe.named_steps['model']\n",
    "\n",
    "# make a Series of the importances\n",
    "fi = pd.Series(\n",
    "    model.feature_importances_,\n",
    "    index = X_train.columns\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "# print the top 10\n",
    "print(\"🌳 XGBoost split-gain importances:\")\n",
    "print(fi)\n",
    "\n",
    "# number of times the feature was used by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762892c9",
   "metadata": {},
   "source": [
    "##### XGBOOST Retrain wihout not used features (Best Model to CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "2081d449",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.506703Z",
     "iopub.status.idle": "2025-06-26T22:10:14.507018Z",
     "shell.execute_reply": "2025-06-26T22:10:14.506886Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.506871Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "cutoff  = df_merged.date.max() - pd.Timedelta(weeks=52)\n",
    "train   = df_merged[df_merged.date <= cutoff]\n",
    "test    = df_merged[df_merged.date >  cutoff]\n",
    "\n",
    "drop = [\n",
    "    'weekly_sales','date','holiday_name','pce_healthcare_services'\n",
    "]\n",
    "\n",
    "X_train, y_train = train.drop(columns=drop), train.weekly_sales\n",
    "X_test,  y_test  = test .drop(columns=drop),  test .weekly_sales\n",
    "\n",
    "\n",
    "# Fit model, keep only used features\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\",  XGBRegressor(**best_params, random_state=7, n_jobs=-1))\n",
    "])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "used_feats = X_train.columns[pipe.named_steps['model'].feature_importances_ > 0]\n",
    "pipe.fit(X_train[used_feats], y_train)\n",
    "\n",
    "\n",
    "# Predict & compute metrics\n",
    "\n",
    "y_pred  = pipe.predict(X_test[used_feats])\n",
    "\n",
    "mae     = mean_absolute_error(y_test, y_pred)\n",
    "rmse    = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2      = r2_score(y_test, y_pred)\n",
    "weights = np.where(test['holiday_name'].notnull(), 5, 1)\n",
    "wmae    = (weights * np.abs(y_test - y_pred)).sum() / weights.sum()\n",
    "\n",
    "\n",
    "row = {\n",
    "    \"model_name\": 'XGBOOST01',\n",
    "    **best_params,\n",
    "    \"mae\":  mae,\n",
    "    \"rmse\": rmse,\n",
    "    \"r2\":   r2,\n",
    "    \"wmae\": wmae\n",
    "}\n",
    "df_best_xgboost = pd.DataFrame([row])\n",
    "\n",
    "df_best_xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "b613d446",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.508079Z",
     "iopub.status.idle": "2025-06-26T22:10:14.508367Z",
     "shell.execute_reply": "2025-06-26T22:10:14.508223Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.50821Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "# to merge new best model : \n",
    "results_df = pd.concat([df_best_xgboost, df_best_models], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "d8361eaa",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.509364Z",
     "iopub.status.idle": "2025-06-26T22:10:14.509706Z",
     "shell.execute_reply": "2025-06-26T22:10:14.509582Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.509565Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_best_models = results_df\n",
    "df_best_models.to_csv('csv_files/ml_train_data/df_best_models.csv', index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "665cb3f8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.511123Z",
     "iopub.status.idle": "2025-06-26T22:10:14.511498Z",
     "shell.execute_reply": "2025-06-26T22:10:14.511324Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.511282Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_best_models = pd.read_csv('csv_files/ml_train_data/df_best_models.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6243d52a",
   "metadata": {},
   "source": [
    "### CatBoost  Hyper Parameters Search / CV Estimate (used to choose hyper-parameters faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "0ef14f4d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.514147Z",
     "iopub.status.idle": "2025-06-26T22:10:14.514482Z",
     "shell.execute_reply": "2025-06-26T22:10:14.514328Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.514318Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "def cat_pipeline_factory(params):\n",
    "    \"\"\"Return a (scaler → CatBoost) pipeline with the given hyper-params.\"\"\"\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),                # numeric features only; harmless for CatBoost\n",
    "        (\"model\",  CatBoostRegressor(\n",
    "                        **params,\n",
    "                        random_state=7,\n",
    "                        verbose=0,                  # silence per-iteration logging\n",
    "                    )\n",
    "        )\n",
    "    ])\n",
    "\n",
    "# Wide, balanced CatBoost hyper-parameter grid\n",
    "\n",
    "param_grid = {\n",
    "    # core learning-rate / depth / boosting length\n",
    "    'iterations'        : [ 500, 1000, 1500, 2000 ],\n",
    "    'depth'             : [ 4, 6, 8, 10 ],\n",
    "    'learning_rate'     : [ 0.01, 0.03, 0.1 ],\n",
    "    \n",
    "    # regularisation & tree shape\n",
    "    'l2_leaf_reg'       : [ 1, 3, 5, 10 ],\n",
    "    'min_data_in_leaf'  : [ 1, 5, 10, 20 ],\n",
    "    'random_strength'   : [ 0, 1, 5, 10 ],\n",
    "    'bagging_temperature': [ 0, 0.5, 1, 2 ],\n",
    "    \n",
    "    # sampling for rows / columns\n",
    "    'subsample'         : [ 0.6, 0.8, 1.0 ],\n",
    "    'rsm'               : [ 0.6, 0.8, 1.0 ],        # column sample\n",
    "       \n",
    "    # other structural knobs\n",
    "    'grow_policy'       : [ 'SymmetricTree', 'Depthwise', 'Lossguide' ],\n",
    "    'border_count'      : [ 32, 64, 128, 254 ],\n",
    "    'one_hot_max_size'  : [ 2, 5, 10 ],\n",
    "    \n",
    "    # objective variants (optional: restrict to one if you prefer)\n",
    "    'loss_function'     : [ 'MAE', 'RMSE']\n",
    "}\n",
    "\n",
    "# Random search trainer setup\n",
    "\n",
    "trainer = ModelTrainer(\n",
    "    X               = X_train,\n",
    "    y               = y_train,\n",
    "    model_factory   = cat_pipeline_factory,\n",
    "    search          = 'random',\n",
    "    param_grid      = param_grid,\n",
    "    n_iter          = 90,                          # ← wide but balanced exploration\n",
    "    cv_splitter     = TimeSeriesSplit(n_splits=3),\n",
    "    custom_metrics  = {'wmae': wmae_custom},\n",
    "    log_path        = 'csv_files/ml_train_data/cat_random_wmae01.csv',\n",
    "    model_name      = 'CAT_WMAE',\n",
    "    problem_type    = 'reg',\n",
    "    n_jobs          = -1,\n",
    "    random_state    = 7\n",
    ")\n",
    "\n",
    "\n",
    "# Run the search\n",
    "\n",
    "best_params, best_score = trainer.train()\n",
    "\n",
    "print(\" Best WMAE: \", best_score)\n",
    "\n",
    "\n",
    "# Clean up\n",
    "\n",
    "trainer.csv_file.close()\n",
    "del trainer\n",
    "import gc; gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "49586d0e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.515291Z",
     "iopub.status.idle": "2025-06-26T22:10:14.515612Z",
     "shell.execute_reply": "2025-06-26T22:10:14.515491Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.515476Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "cat_random_wmae01 = pd.read_csv('csv_files/ml_train_data/cat_random_wmae01.csv')\n",
    "cat_random_wmae01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "d2ce7993",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-26T22:10:14.516491Z",
     "iopub.status.idle": "2025-06-26T22:10:14.516746Z",
     "shell.execute_reply": "2025-06-26T22:10:14.516645Z",
     "shell.execute_reply.started": "2025-06-26T22:10:14.516633Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "df = cat_random_wmae01.copy()             \n",
    "\n",
    "params_df = (\n",
    "    df['param_json']\n",
    "    .apply(lambda s: json.loads(s) if pd.notnull(s) else {})  \n",
    "    .apply(pd.Series)                                         \n",
    ")\n",
    "df = pd.concat([df, params_df], axis=1)\n",
    "\n",
    "metric = 'wmae'\n",
    "ignore = {'model_name', 'param_json',            \n",
    "          'mae', 'rmse', 'r2', metric, '__source__'}\n",
    "\n",
    "param_cols = [c for c in df.columns if c not in ignore]\n",
    "\n",
    "# keep only numeric hyper-params\n",
    "X = df[param_cols].select_dtypes(include=[np.number])\n",
    "y = df[metric]\n",
    "\n",
    "# guard against “empty X” (all NaNs / non-numeric)\n",
    "if X.shape[1] == 0:\n",
    "    raise ValueError(\"No numeric hyper-parameter columns left after filtering!\")\n",
    "\n",
    "# urrogate model + analyses \n",
    "rf = RandomForestRegressor(n_estimators=200, random_state=7, n_jobs=-1)\n",
    "rf.fit(X, y)\n",
    "\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "print(\"→ RF importances:\\n\", importances.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "perm = permutation_importance(rf, X, y, n_repeats=10, random_state=7, n_jobs=-1)\n",
    "perm_imp = pd.Series(perm.importances_mean, index=X.columns)\n",
    "print(\"→ Permutation importances:\\n\", perm_imp.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "# partial-dependence plots \n",
    "top = importances.sort_values(ascending=False).index[:]\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(32, 32), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, feat in zip(axes, top):\n",
    "    PartialDependenceDisplay.from_estimator(rf, X, [feat], ax=ax)\n",
    "    ax.set_title(f\"PDP: {feat}\")\n",
    "\n",
    "for ax in axes[len(top):]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "2a9f0943",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T02:00:37.325458Z",
     "iopub.status.busy": "2025-06-27T02:00:37.325055Z",
     "iopub.status.idle": "2025-06-27T02:00:37.333577Z",
     "shell.execute_reply": "2025-06-27T02:00:37.332502Z",
     "shell.execute_reply.started": "2025-06-27T02:00:37.325437Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "#VSCode\n",
    "def cat_pipeline_factory(params):\n",
    "    \"\"\"\n",
    "    Build a (StandardScaler → CatBoostRegressor) pipeline.\n",
    "\n",
    "    Adds early_stopping_rounds=200 on top of the hyper-parameters supplied\n",
    "    by the random-search engine.\n",
    "    \"\"\"\n",
    "    params = params.copy()\n",
    "    params.update(\n",
    "        early_stopping_rounds=200   # stop if validation metric hasn't improved\n",
    "                                    # for 200 consecutive trees\n",
    "    )\n",
    "\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),        # safe for purely numeric features\n",
    "        (\"model\", CatBoostRegressor(\n",
    "            **params,                        # hyper-parameters from search\n",
    "            random_state=7,                  # reproducible results\n",
    "            verbose=0                        # keep per-tree logging silent\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "# Wide, balanced CatBoost hyper-parameter grid\n",
    "\n",
    "param_grid = {\n",
    "    # core learning-rate / depth / boosting length\n",
    "    'iterations'        : [ 3000, 5000 ],\n",
    "    'depth'             : [10, 12, 14 ],\n",
    "    'learning_rate'     : [0.1, 0.2, 0.3 ],\n",
    "    \n",
    "    # regularisation & tree shape\n",
    "    'l2_leaf_reg'       : [ 3, 17, 20 ],\n",
    "    'min_data_in_leaf'  : [ 1,5],\n",
    "    'random_strength'   : [ 0.1],\n",
    "    'bagging_temperature': [ 0.1],\n",
    "    \n",
    "    # sampling for rows / columns\n",
    "    'subsample'         : [ 0.1, 0.8 ],\n",
    "    'rsm'               : [ 0.9 ],        # column sample\n",
    "       \n",
    "    # other structural knobs\n",
    "    'grow_policy'       : [ 'Depthwise', 'Lossguide' ],\n",
    "    'border_count'      : [ 254, 512, 1024 ],\n",
    "    'one_hot_max_size'  : [5],\n",
    "    \n",
    "    # objective variants (optional: restrict to one if you prefer)\n",
    "    'loss_function'     : [ 'MAE', 'RMSE']\n",
    "}\n",
    "\n",
    "# Random search trainer setup\n",
    "\n",
    "trainer = ModelTrainer(\n",
    "    X               = X_train,\n",
    "    y               = y_train,\n",
    "    model_factory   = cat_pipeline_factory,\n",
    "    search          = 'random',\n",
    "    param_grid      = param_grid,\n",
    "    n_iter          = 50,                         \n",
    "    cv_splitter     = TimeSeriesSplit(n_splits=3),\n",
    "    custom_metrics  = {'wmae': wmae_custom},\n",
    "    log_path        = 'csv_files/ml_train_data/cat_random_wmae02.csv',\n",
    "    model_name      = 'CAT_WMAE',\n",
    "    problem_type    = 'reg',\n",
    "    n_jobs          = -1,\n",
    "    random_state    = 7\n",
    ")\n",
    "\n",
    "\n",
    "# Run the search\n",
    "\n",
    "best_params, best_score = trainer.train()\n",
    "\n",
    "print(\" Best WMAE: \", best_score)\n",
    "\n",
    "\n",
    "# Clean up\n",
    "\n",
    "trainer.csv_file.close()\n",
    "del trainer\n",
    "import gc; gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "d0ef7815-ba2d-49ca-b80f-a24d0ce040eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T02:04:46.002273Z",
     "iopub.status.busy": "2025-06-27T02:04:46.001507Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "#Kaggle\n",
    "def cat_pipeline_factory(params):\n",
    "    params = params.copy()\n",
    "    params.update(\n",
    "        task_type=\"GPU\",\n",
    "        devices=\"0\",\n",
    "        metric_period=20,\n",
    "        early_stopping_rounds=200,\n",
    "        bootstrap_type=\"Bernoulli\"      # lets subsample work\n",
    "    )\n",
    "\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", CatBoostRegressor(\n",
    "            **params,\n",
    "            random_state=7,\n",
    "            verbose=0\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    # core learning-rate / depth / boosting length\n",
    "    \"iterations\"        : [3000, 5000],\n",
    "    \"depth\"             : [10, 12, 14],\n",
    "    \"learning_rate\"     : [0.1, 0.2, 0.3],\n",
    "\n",
    "    # regularisation & tree shape\n",
    "    \"l2_leaf_reg\"       : [3, 17, 20],\n",
    "    \"min_data_in_leaf\"  : [1, 5],\n",
    "    \"random_strength\"   : [0.1],\n",
    "\n",
    "    # sampling for rows\n",
    "    \"subsample\"         : [0.1, 0.8],        # row sampling now works\n",
    "    # rsm removed ──↑\n",
    "\n",
    "    # other structural knobs\n",
    "    \"grow_policy\"       : [\"Depthwise\", \"Lossguide\"],\n",
    "    \"border_count\"      : [254, 512, 1024],\n",
    "    \"one_hot_max_size\"  : [5],\n",
    "\n",
    "    # objective variants\n",
    "    \"loss_function\"     : [\"MAE\", \"RMSE\"],\n",
    "}\n",
    "\n",
    "\n",
    "trainer = ModelTrainer(\n",
    "    X               = X_train,\n",
    "    y               = y_train,\n",
    "    model_factory   = cat_pipeline_factory,\n",
    "    search          = \"random\",\n",
    "    param_grid      = param_grid,\n",
    "    n_iter          = 50,\n",
    "    cv_splitter     = TimeSeriesSplit(n_splits=3),\n",
    "    custom_metrics  = {\"wmae\": wmae_custom},\n",
    "    log_path        = \"/kaggle/working/cat_random_wmae02.csv\",\n",
    "    model_name      = \"CAT_WMAE\",\n",
    "    problem_type    = \"reg\",\n",
    "    n_jobs          = 1,                 # one fit → one GPU\n",
    "    random_state    = 7\n",
    ")\n",
    "\n",
    "\n",
    "best_params, best_score = trainer.train()\n",
    "print(\"Best WMAE:\", best_score)\n",
    "\n",
    "\n",
    "trainer.csv_file.close()\n",
    "del trainer\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "3385f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "# load & explode both CSVs if you haven’t yet —\n",
    "paths = [\n",
    "    'csv_files/ml_train_data/cat_random_wmae01.csv',\n",
    "    'csv_files/ml_train_data/cat_random_wmae02.csv',\n",
    "]\n",
    "dfs = []\n",
    "for path in paths:\n",
    "    df = pd.read_csv(path)\n",
    "    params = df['param_json'].apply(json.loads).apply(pd.Series)\n",
    "    df = pd.concat([df.drop(columns='param_json'), params], axis=1)\n",
    "    df['__source__'] = path.split('/')[-1]\n",
    "    dfs.append(df)\n",
    "df_all = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "9d2cca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "# choose metric & hyper‐param cols, drop any non‐numeric ones —\n",
    "metric = 'wmae'\n",
    "ignore = {'model_name','mae','rmse','r2', metric, '__source__'}\n",
    "param_cols = [c for c in df_all.columns if c not in ignore]\n",
    "\n",
    "# keep only numeric hyperparams\n",
    "X = df_all[param_cols].select_dtypes(include=[np.number])\n",
    "y = df_all[metric]\n",
    "\n",
    "# train surrogate —\n",
    "rf = RandomForestRegressor(n_estimators=200, random_state=7, n_jobs=-1)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# RF importances\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "print(\"→ RF importances:\\n\", importances.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "# permutation importances\n",
    "perm = permutation_importance(rf, X, y, n_repeats=10, random_state=7, n_jobs=-1)\n",
    "perm_imp = pd.Series(perm.importances_mean, index=X.columns)\n",
    "print(\"→ Permutation importances:\\n\", perm_imp.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "# partial dependence plots for top-3 features, all in one figure —\n",
    "top = importances.sort_values(ascending=False).index[:].tolist()\n",
    "\n",
    "fig, axes = plt.subplots(4, 4 ,figsize=(32, 32), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, feat in zip(axes, top):\n",
    "    PartialDependenceDisplay.from_estimator(rf, X, [feat], ax=ax)\n",
    "    ax.set_title(f\"PDP: {feat}\")\n",
    "\n",
    "# turn off the last (unused) subplot\n",
    "axes[-1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "3c35834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "#Kaggle\n",
    "def cat_pipeline_factory(params):\n",
    "    params = params.copy()\n",
    "    params.update(\n",
    "        task_type=\"GPU\",\n",
    "        devices=\"0\",\n",
    "        metric_period=20,\n",
    "        early_stopping_rounds=200,\n",
    "        bootstrap_type=\"Bernoulli\"      # lets subsample work\n",
    "    )\n",
    "\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", CatBoostRegressor(\n",
    "            **params,\n",
    "            random_state=7,\n",
    "            verbose=0\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    # core learning-rate / depth / boosting length\n",
    "    \"iterations\"        : [2000],\n",
    "    \"depth\"             : [12, 16],\n",
    "    \"learning_rate\"     : [0.3, 0.4, 0.5],\n",
    "\n",
    "    # regularisation & tree shape\n",
    "    \"l2_leaf_reg\"       : [17,30],\n",
    "    \"min_data_in_leaf\"  : [3, 5],\n",
    "    \"random_strength\"   : [5],\n",
    "\n",
    "    # sampling for rows\n",
    "    \"subsample\"         : [0.8],        # row sampling now works\n",
    "    # rsm removed ──↑\n",
    "\n",
    "    # other structural knobs\n",
    "    \"grow_policy\"       : [\"Depthwise\", \"Lossguide\"],\n",
    "    \"border_count\"      : [1024, 2048, 4096],\n",
    "    \"one_hot_max_size\"  : [10,15, 20],\n",
    "\n",
    "    # objective variants\n",
    "    \"loss_function\"     : [\"MAE\", \"RMSE\"],\n",
    "}\n",
    "\n",
    "\n",
    "trainer = ModelTrainer(\n",
    "    X               = X_train,\n",
    "    y               = y_train,\n",
    "    model_factory   = cat_pipeline_factory,\n",
    "    search          = \"random\",\n",
    "    param_grid      = param_grid,\n",
    "    n_iter          = 50,\n",
    "    cv_splitter     = TimeSeriesSplit(n_splits=3),\n",
    "    custom_metrics  = {\"wmae\": wmae_custom},\n",
    "    log_path        = \"/kaggle/working/cat_random_wmae02.csv\",\n",
    "    model_name      = \"CAT_WMAE\",\n",
    "    problem_type    = \"reg\",\n",
    "    n_jobs          = 1,                 # one fit → one GPU\n",
    "    random_state    = 7\n",
    ")\n",
    "\n",
    "\n",
    "best_params, best_score = trainer.train()\n",
    "print(\"Best WMAE:\", best_score)\n",
    "\n",
    "\n",
    "trainer.csv_file.close()\n",
    "del trainer\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "3dad33ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "\n",
    "# load & explode both CSVs if you haven’t yet —\n",
    "paths = [\n",
    "    'csv_files/ml_train_data/cat_random_wmae01.csv',\n",
    "    'csv_files/ml_train_data/cat_random_wmae02.csv',\n",
    "    'csv_files/ml_train_data/cat_random_wmae03.csv',\n",
    "]\n",
    "dfs = []\n",
    "for path in paths:\n",
    "    df = pd.read_csv(path)\n",
    "    params = df['param_json'].apply(json.loads).apply(pd.Series)\n",
    "    df = pd.concat([df.drop(columns='param_json'), params], axis=1)\n",
    "    df['__source__'] = path.split('/')[-1]\n",
    "    dfs.append(df)\n",
    "df_all = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "d92fde00",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "\n",
    "# choose metric & hyper‐param cols, drop any non‐numeric ones —\n",
    "metric = 'wmae'\n",
    "ignore = {'model_name','mae','rmse','r2', metric, '__source__'}\n",
    "param_cols = [c for c in df_all.columns if c not in ignore]\n",
    "\n",
    "# keep only numeric hyperparams\n",
    "X = df_all[param_cols].select_dtypes(include=[np.number])\n",
    "y = df_all[metric]\n",
    "\n",
    "# train surrogate —\n",
    "rf = RandomForestRegressor(n_estimators=200, random_state=7, n_jobs=-1)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# RF importances\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "print(\"→ RF importances:\\n\", importances.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "# permutation importances\n",
    "perm = permutation_importance(rf, X, y, n_repeats=10, random_state=7, n_jobs=-1)\n",
    "perm_imp = pd.Series(perm.importances_mean, index=X.columns)\n",
    "print(\"→ Permutation importances:\\n\", perm_imp.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "# partial dependence plots for top-3 features, all in one figure —\n",
    "top = importances.sort_values(ascending=False).index[:].tolist()\n",
    "\n",
    "fig, axes = plt.subplots(4, 4 ,figsize=(32, 32), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, feat in zip(axes, top):\n",
    "    PartialDependenceDisplay.from_estimator(rf, X, [feat], ax=ax)\n",
    "    ax.set_title(f\"PDP: {feat}\")\n",
    "\n",
    "# turn off the last (unused) subplot\n",
    "axes[-1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "75b7a644",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "#Kaggle\n",
    "def cat_pipeline_factory(params):\n",
    "    params = params.copy()\n",
    "    params.update(\n",
    "        task_type=\"GPU\",\n",
    "        devices=\"0\",\n",
    "        metric_period=20,\n",
    "        early_stopping_rounds=200,\n",
    "        bootstrap_type=\"Bernoulli\"      # lets subsample work\n",
    "    )\n",
    "\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", CatBoostRegressor(\n",
    "            **params,\n",
    "            random_state=7,\n",
    "            verbose=0\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    # core learning-rate / depth / boosting length\n",
    "    \"iterations\"        : [6000],\n",
    "    \"depth\"             : [12],\n",
    "    \"learning_rate\"     : [0.4],\n",
    "\n",
    "    # regularisation & tree shape\n",
    "    \"l2_leaf_reg\"       : [15],\n",
    "    \"min_data_in_leaf\"  : [5],\n",
    "    \"random_strength\"   : [0.01, 0.1],\n",
    "\n",
    "    # sampling for rows\n",
    "    \"subsample\"         : [0.6],        # row sampling now works\n",
    "    # rsm removed ──↑\n",
    "\n",
    "    # other structural knobs\n",
    "    \"grow_policy\"       : [\"Depthwise\", \"Lossguide\"],\n",
    "    \"border_count\"      : [4096, 8192, 16384],\n",
    "    \"one_hot_max_size\"  : [20,15,30],\n",
    "\n",
    "    # objective variants\n",
    "    \"loss_function\"     : [\"MAE\", \"RMSE\"],\n",
    "}\n",
    "\n",
    "\n",
    "trainer = ModelTrainer(\n",
    "    X               = X_train,\n",
    "    y               = y_train,\n",
    "    model_factory   = cat_pipeline_factory,\n",
    "    search          = \"random\",\n",
    "    param_grid      = param_grid,\n",
    "    n_iter          = 50,\n",
    "    cv_splitter     = TimeSeriesSplit(n_splits=3),\n",
    "    custom_metrics  = {\"wmae\": wmae_custom},\n",
    "    log_path        = \"/kaggle/working/cat_random_wmae04.csv\",\n",
    "    model_name      = \"CAT_WMAE\",\n",
    "    problem_type    = \"reg\",\n",
    "    n_jobs          = 1,                 # one fit → one GPU\n",
    "    random_state    = 7\n",
    ")\n",
    "\n",
    "\n",
    "best_params, best_score = trainer.train()\n",
    "print(\"Best WMAE:\", best_score)\n",
    "\n",
    "\n",
    "trainer.csv_file.close()\n",
    "del trainer\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a04366c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "# load & explode both CSVs if you haven’t yet —\n",
    "paths = [\n",
    "    'csv_files/ml_train_data/cat_random_wmae01.csv',\n",
    "    'csv_files/ml_train_data/cat_random_wmae02.csv',\n",
    "    'csv_files/ml_train_data/cat_random_wmae03.csv',\n",
    "    'csv_files/ml_train_data/cat_random_wmae04.csv',\n",
    "]\n",
    "dfs = []\n",
    "for path in paths:\n",
    "    df = pd.read_csv(path)\n",
    "    params = df['param_json'].apply(json.loads).apply(pd.Series)\n",
    "    df = pd.concat([df.drop(columns='param_json'), params], axis=1)\n",
    "    df['__source__'] = path.split('/')[-1]\n",
    "    dfs.append(df)\n",
    "df_all = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "07685b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_all.to_csv('csv_files/ml_train_data/df_cat_random04.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "0a62e402",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "# choose metric & hyper‐param cols, drop any non‐numeric ones —\n",
    "metric = 'wmae'\n",
    "ignore = {'model_name','mae','rmse','r2', metric, '__source__'}\n",
    "param_cols = [c for c in df_all.columns if c not in ignore]\n",
    "\n",
    "# keep only numeric hyperparams\n",
    "X = df_all[param_cols].select_dtypes(include=[np.number])\n",
    "y = df_all[metric]\n",
    "\n",
    "# train surrogate —\n",
    "rf = RandomForestRegressor(n_estimators=200, random_state=7, n_jobs=-1)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# RF importances\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "print(\"→ RF importances:\\n\", importances.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "# permutation importances\n",
    "perm = permutation_importance(rf, X, y, n_repeats=10, random_state=7, n_jobs=-1)\n",
    "perm_imp = pd.Series(perm.importances_mean, index=X.columns)\n",
    "print(\"→ Permutation importances:\\n\", perm_imp.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "# partial dependence plots for top-3 features, all in one figure —\n",
    "top = importances.sort_values(ascending=False).index[:].tolist()\n",
    "\n",
    "fig, axes = plt.subplots(4, 4 ,figsize=(32, 32), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, feat in zip(axes, top):\n",
    "    PartialDependenceDisplay.from_estimator(rf, X, [feat], ax=ax)\n",
    "    ax.set_title(f\"PDP: {feat}\")\n",
    "\n",
    "# turn off the last (unused) subplot\n",
    "axes[-1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "bdbde2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "#Kaggle\n",
    "def cat_pipeline_factory(params):\n",
    "    params = params.copy()\n",
    "    params.update(\n",
    "        task_type=\"GPU\",\n",
    "        devices=\"0\",\n",
    "        metric_period=20,\n",
    "        early_stopping_rounds=200,\n",
    "        bootstrap_type=\"Bernoulli\"      # lets subsample work\n",
    "    )\n",
    "\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", CatBoostRegressor(\n",
    "            **params,\n",
    "            random_state=7,\n",
    "            verbose=0\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    # core learning-rate / depth / boosting length\n",
    "    \"iterations\"        : [2000],\n",
    "    \"depth\"             : [12],\n",
    "    \"learning_rate\"     : [0.4],\n",
    "\n",
    "    # regularisation & tree shape\n",
    "    \"l2_leaf_reg\"       : [17],\n",
    "    \"min_data_in_leaf\"  : [5],\n",
    "    \"random_strength\"   : [5],\n",
    "\n",
    "    # sampling for rows\n",
    "    \"subsample\"         : [0.8],        # row sampling now works\n",
    "    # rsm removed ──↑\n",
    "\n",
    "    # other structural knobs\n",
    "    \"grow_policy\"       : [\"Depthwise\", \"Lossguide\"],\n",
    "    \"border_count\"      : [8192],\n",
    "    \"one_hot_max_size\"  : [20],\n",
    "\n",
    "    # objective variants\n",
    "    \"loss_function\"     : [\"MAE\", \"RMSE\"],\n",
    "}\n",
    "\n",
    "\n",
    "trainer = ModelTrainer(\n",
    "    X               = X_train,\n",
    "    y               = y_train,\n",
    "    model_factory   = cat_pipeline_factory,\n",
    "    search          = \"random\",\n",
    "    param_grid      = param_grid,\n",
    "    n_iter          = 50,\n",
    "    cv_splitter     = TimeSeriesSplit(n_splits=3),\n",
    "    custom_metrics  = {\"wmae\": wmae_custom},\n",
    "    log_path        = \"/kaggle/working/cat_random_wmae04.csv\",\n",
    "    model_name      = \"CAT_WMAE\",\n",
    "    problem_type    = \"reg\",\n",
    "    n_jobs          = 1,                 # one fit → one GPU\n",
    "    random_state    = 7\n",
    ")\n",
    "\n",
    "\n",
    "best_params, best_score = trainer.train()\n",
    "print(\"Best WMAE:\", best_score)\n",
    "\n",
    "\n",
    "trainer.csv_file.close()\n",
    "del trainer\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a8e622",
   "metadata": {},
   "source": [
    "##### CatBoost Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8150bc",
   "metadata": {},
   "source": [
    "Get Best Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "f9eea3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_cat_random04 = pd.read_csv('csv_files/ml_train_data/df_cat_random04.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "890d1bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "df = df_cat_random04.copy()\n",
    "\n",
    "# pick the row with the lowest WMAE\n",
    "best_row = df.loc[df['wmae'].idxmin()]\n",
    "\n",
    "# keep only the hyper-parameter columns\n",
    "non_params = {'model_name', 'mae', 'rmse', 'r2', 'wmae', '__source__'}\n",
    "param_series = best_row.drop(labels=non_params)\n",
    "\n",
    "# convert to a clean dict, turning floats like 500.0 → 500\n",
    "best_params = {\n",
    "    k: (int(v) if isinstance(v, (int, float)) and not math.isnan(v) and v.is_integer() else v)\n",
    "    for k, v in param_series.items()\n",
    "    if pd.notnull(v)                           # skip NaNs\n",
    "}\n",
    "\n",
    "\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "c6a41d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "# Rebuild your best‐found model\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", CatBoostRegressor(**best_params, random_state=7))\n",
    "])\n",
    "\n",
    "# 1) Fit on the entire training set\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# 2) Predict on the test set\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# 3) Compute standard metrics\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "# 4) Compute WMAE (holiday weeks weight=5, others=1)\n",
    "#    assumes you still have `test` DataFrame with 'holiday_name'\n",
    "weights = np.where(test['holiday_name'].notnull(), 5, 1)\n",
    "wmae    = (weights * np.abs(y_test - y_pred)).sum() / weights.sum()\n",
    "\n",
    "# 5) Print them all\n",
    "print(f\"Test MAE:   {mae:.4f}\")\n",
    "print(f\"Test RMSE:  {rmse:.4f}\")\n",
    "print(f\"Test R²:    {r2:.4f}\")\n",
    "print(f\"Test WMAE:  {wmae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "d67d2b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "# grab the fitted LGBM from your pipeline\n",
    "model = pipe.named_steps['model']\n",
    "\n",
    "# make a Series of the importances\n",
    "fi = pd.Series(\n",
    "    model.feature_importances_,\n",
    "    index = X_train.columns\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "# print the top 10\n",
    "print(\"🌳 CatBoost split-gain importances:\")\n",
    "display(fi)\n",
    "\n",
    "# number of times the feature was used by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "5d1e4d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "cutoff  = df_merged.date.max() - pd.Timedelta(weeks=52)\n",
    "train   = df_merged[df_merged.date <= cutoff]\n",
    "test    = df_merged[df_merged.date >  cutoff]\n",
    "\n",
    "drop = [\n",
    "    'weekly_sales','date','holiday_name','markdown1', 'markdown2', 'markdown3', 'markdown4', 'markdown5'\n",
    "]\n",
    "\n",
    "X_train, y_train = train.drop(columns=drop), train.weekly_sales\n",
    "X_test,  y_test  = test .drop(columns=drop),  test .weekly_sales\n",
    "\n",
    "\n",
    "# Fit model, keep only used features\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\",  CatBoostRegressor(**best_params, random_state=7))\n",
    "])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "used_feats = X_train.columns[pipe.named_steps['model'].feature_importances_ > 0]\n",
    "pipe.fit(X_train[used_feats], y_train)\n",
    "\n",
    "\n",
    "# Predict & compute metrics\n",
    "\n",
    "y_pred  = pipe.predict(X_test[used_feats])\n",
    "\n",
    "mae     = mean_absolute_error(y_test, y_pred)\n",
    "rmse    = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2      = r2_score(y_test, y_pred)\n",
    "weights = np.where(test['holiday_name'].notnull(), 5, 1)\n",
    "wmae    = (weights * np.abs(y_test - y_pred)).sum() / weights.sum()\n",
    "\n",
    "\n",
    "row = {\n",
    "    \"model_name\": 'CatBoost01',\n",
    "    **best_params,\n",
    "    \"mae\":  mae,\n",
    "    \"rmse\": rmse,\n",
    "    \"r2\":   r2,\n",
    "    \"wmae\": wmae\n",
    "}\n",
    "df_best_catboost = pd.DataFrame([row])\n",
    "\n",
    "df_best_catboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "46bd10ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_best_models.to_csv('csv_files/ml_train_data/df_best_models.csv', index=None)\n",
    "results_df = pd.concat([df_best_catboost, df_best_models], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "ab424110",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_best_models = results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "7d9c2b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_best_models.to_csv('csv_files/ml_train_data/df_best_models.csv', index=None)\n",
    "df_best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de487076",
   "metadata": {},
   "source": [
    "### Random Forest Regressor Hyper Parameters Search / CV Estimate (used to choose hyper-parameters faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "44a4c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "# Define a Random Forest pipeline factory\n",
    "def rf_pipeline_factory(params):\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", RandomForestRegressor(**params, random_state=7, n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "# Updated RF hyperparameter grid (dropping 'auto' and using 1.0 instead)\n",
    "trainer = ModelTrainer(\n",
    "    X             = X_train,\n",
    "    y             = y_train,\n",
    "    model_factory = rf_pipeline_factory, \n",
    "    search        = 'random',\n",
    "    param_grid    = {\n",
    "        'n_estimators':       [100, 200, 300, 400, 500],\n",
    "        'max_depth':          [None, 10, 20, 30, 40],\n",
    "        'max_features':       [1.0, 'sqrt', 'log2', 0.5],  # replaced 'auto' with 1.0\n",
    "        'min_samples_split':  [2, 5, 10],\n",
    "        'min_samples_leaf':   [1, 2, 4],\n",
    "        'bootstrap':          [True, False]\n",
    "    },\n",
    "    n_iter           = 100,\n",
    "    cv_splitter      = TimeSeriesSplit(n_splits=3),\n",
    "    custom_metrics   = {'wmae': wmae_custom},\n",
    "    log_path         = 'csv_files/ml_train_data/rf_random_wmae01.csv',\n",
    "    model_name       = 'RF_WMAE',\n",
    "    problem_type     = 'reg',\n",
    "    n_jobs           = -1,\n",
    "    random_state     = 7\n",
    ")\n",
    "\n",
    "# Run the search\n",
    "best_params, best_score = trainer.train()\n",
    "print(\"Best params:\", best_params)\n",
    "print(\" Best WMAE:  \", best_score)\n",
    "\n",
    "# Clean up\n",
    "trainer.csv_file.close()\n",
    "del trainer\n",
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "39ec75f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "rf_random_wmae01 = pd.read_csv('csv_files/ml_train_data/rf_random_wmae01.csv')\n",
    "print(rf_random_wmae01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "bc1117cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "df = rf_random_wmae01.copy()             \n",
    "\n",
    "params_df = (\n",
    "    df['param_json']\n",
    "    .apply(lambda s: json.loads(s) if pd.notnull(s) else {})  \n",
    "    .apply(pd.Series)                                         \n",
    ")\n",
    "df = pd.concat([df, params_df], axis=1)\n",
    "\n",
    "metric = 'wmae'\n",
    "ignore = {'model_name', 'param_json',            \n",
    "          'mae', 'rmse', 'r2', metric, '__source__'}\n",
    "\n",
    "param_cols = [c for c in df.columns if c not in ignore]\n",
    "\n",
    "# keep only numeric hyper-params\n",
    "X = df[param_cols].select_dtypes(include=[np.number])\n",
    "y = df[metric]\n",
    "\n",
    "# guard against “empty X” (all NaNs / non-numeric)\n",
    "if X.shape[1] == 0:\n",
    "    raise ValueError(\"No numeric hyper-parameter columns left after filtering!\")\n",
    "\n",
    "# urrogate model + analyses \n",
    "rf = RandomForestRegressor(n_estimators=200, random_state=7, n_jobs=-1)\n",
    "rf.fit(X, y)\n",
    "\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "print(\"→ RF importances:\\n\", importances.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "perm = permutation_importance(rf, X, y, n_repeats=10, random_state=7, n_jobs=-1)\n",
    "perm_imp = pd.Series(perm.importances_mean, index=X.columns)\n",
    "print(\"→ Permutation importances:\\n\", perm_imp.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "# partial-dependence plots \n",
    "top = importances.sort_values(ascending=False).index[:]\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(32, 32), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, feat in zip(axes, top):\n",
    "    PartialDependenceDisplay.from_estimator(rf, X, [feat], ax=ax)\n",
    "    ax.set_title(f\"PDP: {feat}\")\n",
    "\n",
    "for ax in axes[len(top):]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "d1e292ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "# Define a Random Forest pipeline factory\n",
    "def rf_pipeline_factory(params):\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", RandomForestRegressor(**params, random_state=7, n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "# Updated RF hyperparameter grid (dropping 'auto' and using 1.0 instead)\n",
    "trainer = ModelTrainer(\n",
    "    X             = X_train,\n",
    "    y             = y_train,\n",
    "    model_factory = rf_pipeline_factory, \n",
    "    search        = 'random',\n",
    "    param_grid    = {\n",
    "        'n_estimators':       [200, 400],\n",
    "        'max_depth':          [20, 40, 60],\n",
    "        'max_features':       [1.0, 0.5], \n",
    "        'min_samples_split':  [0.1,0.5, 2],\n",
    "        'min_samples_leaf':   [4, 8, 16],\n",
    "        'bootstrap':          [True, False]\n",
    "    },\n",
    "    n_iter           = 100,\n",
    "    cv_splitter      = TimeSeriesSplit(n_splits=3),\n",
    "    custom_metrics   = {'wmae': wmae_custom},\n",
    "    log_path         = 'csv_files/ml_train_data/rf_random_wmae02.csv',\n",
    "    model_name       = 'RF_WMAE',\n",
    "    problem_type     = 'reg',\n",
    "    n_jobs           = -1,\n",
    "    random_state     = 7\n",
    ")\n",
    "\n",
    "# Run the search\n",
    "best_params, best_score = trainer.train()\n",
    "print(\"Best params:\", best_params)\n",
    "print(\" Best WMAE:  \", best_score)\n",
    "\n",
    "# Clean up\n",
    "trainer.csv_file.close()\n",
    "del trainer\n",
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "a6ce5205",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "# load & explode both CSVs if you haven’t yet —\n",
    "paths = [\n",
    "    'csv_files/ml_train_data/rf_random_wmae01.csv',\n",
    "    'csv_files/ml_train_data/rf_random_wmae02.csv',\n",
    "]\n",
    "dfs = []\n",
    "for path in paths:\n",
    "    df = pd.read_csv(path)\n",
    "    params = df['param_json'].apply(json.loads).apply(pd.Series)\n",
    "    df = pd.concat([df.drop(columns='param_json'), params], axis=1)\n",
    "    df['__source__'] = path.split('/')[-1]\n",
    "    dfs.append(df)\n",
    "df_all = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c45193a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "# choose metric & hyper‐param cols, drop any non‐numeric ones —\n",
    "metric = 'wmae'\n",
    "ignore = {'model_name','mae','rmse','r2', metric, '__source__'}\n",
    "param_cols = [c for c in df_all.columns if c not in ignore]\n",
    "\n",
    "# keep only numeric hyperparams\n",
    "X = df_all[param_cols].select_dtypes(include=[np.number])\n",
    "y = df_all[metric]\n",
    "\n",
    "# train surrogate —\n",
    "rf = RandomForestRegressor(n_estimators=200, random_state=7, n_jobs=-1)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# RF importances\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "print(\"→ RF importances:\\n\", importances.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "# permutation importances\n",
    "perm = permutation_importance(rf, X, y, n_repeats=10, random_state=7, n_jobs=-1)\n",
    "perm_imp = pd.Series(perm.importances_mean, index=X.columns)\n",
    "print(\"→ Permutation importances:\\n\", perm_imp.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "# partial dependence plots for top-3 features, all in one figure —\n",
    "top = importances.sort_values(ascending=False).index[:].tolist()\n",
    "\n",
    "fig, axes = plt.subplots(4, 4 ,figsize=(32, 32), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, feat in zip(axes, top):\n",
    "    PartialDependenceDisplay.from_estimator(rf, X, [feat], ax=ax)\n",
    "    ax.set_title(f\"PDP: {feat}\")\n",
    "\n",
    "# turn off the last (unused) subplot\n",
    "axes[-1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "693b5106",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "# Define a Random Forest pipeline factory\n",
    "def rf_pipeline_factory(params):\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", RandomForestRegressor(**params, random_state=7, n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "# Updated RF hyperparameter grid (dropping 'auto' and using 1.0 instead)\n",
    "trainer = ModelTrainer(\n",
    "    X             = X_train,\n",
    "    y             = y_train,\n",
    "    model_factory = rf_pipeline_factory, \n",
    "    search        = 'random',\n",
    "    param_grid    = {\n",
    "        'n_estimators':       [200, 400],\n",
    "        'max_depth':          [20],\n",
    "        'max_features':       [1.0, 0.5], \n",
    "        'min_samples_split':  [2],\n",
    "        'min_samples_leaf':   [4],\n",
    "        'bootstrap':          [False]\n",
    "    },\n",
    "    n_iter           = 100,\n",
    "    cv_splitter      = TimeSeriesSplit(n_splits=3),\n",
    "    custom_metrics   = {'wmae': wmae_custom},\n",
    "    log_path         = 'csv_files/ml_train_data/rf_random_wmae03.csv',\n",
    "    model_name       = 'RF_WMAE',\n",
    "    problem_type     = 'reg',\n",
    "    n_jobs           = -1,\n",
    "    random_state     = 7\n",
    ")\n",
    "\n",
    "# Run the search\n",
    "best_params, best_score = trainer.train()\n",
    "print(\"Best params:\", best_params)\n",
    "print(\" Best WMAE:  \", best_score)\n",
    "\n",
    "# Clean up\n",
    "trainer.csv_file.close()\n",
    "del trainer\n",
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "0de545d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "# load & explode both CSVs if you haven’t yet —\n",
    "paths = [\n",
    "    'csv_files/ml_train_data/rf_random_wmae01.csv',\n",
    "    'csv_files/ml_train_data/rf_random_wmae02.csv',\n",
    "    'csv_files/ml_train_data/rf_random_wmae03.csv',\n",
    "]\n",
    "dfs = []\n",
    "for path in paths:\n",
    "    df = pd.read_csv(path)\n",
    "    params = df['param_json'].apply(json.loads).apply(pd.Series)\n",
    "    df = pd.concat([df.drop(columns='param_json'), params], axis=1)\n",
    "    df['__source__'] = path.split('/')[-1]\n",
    "    dfs.append(df)\n",
    "df_all = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "5101a836",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "# choose metric & hyper‐param cols, drop any non‐numeric ones —\n",
    "metric = 'wmae'\n",
    "ignore = {'model_name','mae','rmse','r2', metric, '__source__'}\n",
    "param_cols = [c for c in df_all.columns if c not in ignore]\n",
    "\n",
    "# keep only numeric hyperparams\n",
    "X = df_all[param_cols].select_dtypes(include=[np.number])\n",
    "y = df_all[metric]\n",
    "\n",
    "# train surrogate —\n",
    "rf = RandomForestRegressor(n_estimators=200, random_state=7, n_jobs=-1)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# RF importances\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "print(\"→ RF importances:\\n\", importances.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "# permutation importances\n",
    "perm = permutation_importance(rf, X, y, n_repeats=10, random_state=7, n_jobs=-1)\n",
    "perm_imp = pd.Series(perm.importances_mean, index=X.columns)\n",
    "print(\"→ Permutation importances:\\n\", perm_imp.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "# partial dependence plots for top-3 features, all in one figure —\n",
    "top = importances.sort_values(ascending=False).index[:].tolist()\n",
    "\n",
    "fig, axes = plt.subplots(4, 4 ,figsize=(32, 32), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, feat in zip(axes, top):\n",
    "    PartialDependenceDisplay.from_estimator(rf, X, [feat], ax=ax)\n",
    "    ax.set_title(f\"PDP: {feat}\")\n",
    "\n",
    "# turn off the last (unused) subplot\n",
    "axes[-1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837700cf",
   "metadata": {},
   "source": [
    "##### Random Forest Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "bbb18396",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_all.to_csv('csv_files/ml_train_data/df_rf_random03.csv', index=None)\n",
    "df = pd.read_csv('csv_files/ml_train_data/df_rf_random03.csv')\n",
    "# pick the row with the lowest WMAE\n",
    "best_row = df.loc[df['wmae'].idxmin()]\n",
    "\n",
    "# keep only the hyper-parameter columns\n",
    "non_params = {'model_name', 'mae', 'rmse', 'r2', 'wmae', '__source__'}\n",
    "param_series = best_row.drop(labels=non_params)\n",
    "\n",
    "# convert to a clean dict, turning floats like 500.0 → 500\n",
    "best_params = {\n",
    "    k: (int(v) if isinstance(v, (int, float)) and not math.isnan(v) and v.is_integer() else v)\n",
    "    for k, v in param_series.items()\n",
    "    if pd.notnull(v)                           # skip NaNs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "c35fb74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "best_row = df.loc[df['wmae'].idxmin()]\n",
    "\n",
    "# Drop non‐hyperparameter cols\n",
    "non_params = {'model_name','mae','rmse','r2','wmae','__source__'}\n",
    "param_series = best_row.drop(labels=non_params)\n",
    "\n",
    "# Clean & cast params\n",
    "best_params = {}\n",
    "for k, v in param_series.items():\n",
    "    if pd.isnull(v):\n",
    "        continue\n",
    "    # try to interpret strings as numbers\n",
    "    if isinstance(v, str):\n",
    "        try:\n",
    "            num = float(v)\n",
    "            # if it's an integer value, cast to int\n",
    "            v = int(num) if num.is_integer() else num\n",
    "        except ValueError:\n",
    "            # not a number → leave as string\n",
    "            pass\n",
    "    # if it's a float that is whole, cast to int\n",
    "    if isinstance(v, float) and v.is_integer():\n",
    "        v = int(v)\n",
    "    best_params[k] = v\n",
    "\n",
    "print(\"Reconstructed params:\", best_params)\n",
    "\n",
    "# Rebuild & fit your pipeline\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", RandomForestRegressor(**best_params, random_state=7, n_jobs=-1))\n",
    "])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = pipe.predict(X_test)\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "# Compute WMAE (holiday weeks weight=5)\n",
    "weights = np.where(test['holiday_name'].notnull(), 5, 1)\n",
    "wmae    = (weights * np.abs(y_test - y_pred)).sum() / weights.sum()\n",
    "\n",
    "print(f\"Test MAE:   {mae:.4f}\")\n",
    "print(f\"Test RMSE:  {rmse:.4f}\")\n",
    "print(f\"Test R²:    {r2:.4f}\")\n",
    "print(f\"Test WMAE:  {wmae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "a17a0d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "# grab the fitted RF from your pipeline\n",
    "model = pipe.named_steps['model']\n",
    "\n",
    "# make a Series of the importances\n",
    "fi = pd.Series(\n",
    "    model.feature_importances_,\n",
    "    index = X_train.columns\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "# print the top 10\n",
    "print(\"🌳 RF split-gain importances:\")\n",
    "display(fi)\n",
    "\n",
    "# number of times the feature was used by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "dfaf722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "cutoff  = df_merged.date.max() - pd.Timedelta(weeks=52)\n",
    "train   = df_merged[df_merged.date <= cutoff]\n",
    "test    = df_merged[df_merged.date >  cutoff]\n",
    "\n",
    "drop = [\n",
    "    'weekly_sales','date','holiday_name'\n",
    "]\n",
    "\n",
    "X_train, y_train = train.drop(columns=drop), train.weekly_sales\n",
    "X_test,  y_test  = test .drop(columns=drop),  test .weekly_sales\n",
    "\n",
    "\n",
    "# Fit model, keep only used features\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\",  RandomForestRegressor(**best_params, random_state=7))\n",
    "])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "used_feats = X_train.columns[pipe.named_steps['model'].feature_importances_ > 0]\n",
    "pipe.fit(X_train[used_feats], y_train)\n",
    "\n",
    "\n",
    "# Predict & compute metrics\n",
    "\n",
    "y_pred  = pipe.predict(X_test[used_feats])\n",
    "\n",
    "mae     = mean_absolute_error(y_test, y_pred)\n",
    "rmse    = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2      = r2_score(y_test, y_pred)\n",
    "weights = np.where(test['holiday_name'].notnull(), 5, 1)\n",
    "wmae    = (weights * np.abs(y_test - y_pred)).sum() / weights.sum()\n",
    "\n",
    "\n",
    "row = {\n",
    "    \"model_name\": 'RandomForest01',\n",
    "    **best_params,\n",
    "    \"mae\":  mae,\n",
    "    \"rmse\": rmse,\n",
    "    \"r2\":   r2,\n",
    "    \"wmae\": wmae\n",
    "}\n",
    "df_best_randomforest = pd.DataFrame([row])\n",
    "\n",
    "df_best_randomforest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "16031a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "# to merge new best model : \n",
    "df_best_models = pd.read_csv('csv_files/ml_train_data/df_best_models.csv')\n",
    "results_df = pd.concat([df_best_randomforest, df_best_models], ignore_index=True)\n",
    "df_best_models = results_df\n",
    "df_best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "5e2c2927",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_best_models.to_csv('csv_files/ml_train_data/df_best_models.csv', index=None)\n",
    "df_best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262e7937",
   "metadata": {},
   "source": [
    "### Histogram-Based Gradient Boosting  Hyper Parameters Search / CV Estimate (used to choose hyper-parameters faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "92d8165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "# Pipeline factory for Histogram-Based Gradient Boosting\n",
    "def hgb_pipeline_factory(params):\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", HistGradientBoostingRegressor(**params, random_state=7))\n",
    "    ])\n",
    "\n",
    "# 2) Build a “wide” param‐grid, but drop 'poisson' to avoid the non-negativity requirement error\n",
    "hgb_param_grid = {\n",
    "    # loss functions (no more 'poisson' for now)\n",
    "    \"loss\":                 [\"squared_error\", \"absolute_error\"],\n",
    "    # number of boosting iterations\n",
    "    \"max_iter\":             [100, 200, 300, 500],\n",
    "    # step size shrinkage\n",
    "    \"learning_rate\":        [0.01, 0.05, 0.1, 0.2],\n",
    "    # maximum number of leaves per tree\n",
    "    \"max_leaf_nodes\":       [31, 63, 127, None],\n",
    "    # maximum depth of each tree (None = unlimited, bounded by leaf‐nodes)\n",
    "    \"max_depth\":            [None, 3, 5, 10],\n",
    "    # minimum number of samples in each leaf\n",
    "    \"min_samples_leaf\":     [1, 10, 20, 50],\n",
    "    # regularization strength (L2 penalty)\n",
    "    \"l2_regularization\":    [0.0, 1.0, 10.0],\n",
    "    # number of bins used to bucket continuous features\n",
    "    \"max_bins\":             [100, 150, 255],\n",
    "    # tolerance for early stopping (only applies if early_stopping=True)\n",
    "    \"tol\":                  [1e-7, 1e-5, 1e-3],\n",
    "    # number of rounds with no improvement to wait before stopping\n",
    "    \"n_iter_no_change\":     [5, 10, 20],\n",
    "    # whether to use early stopping on a validation split\n",
    "    \"early_stopping\":       [True, False],\n",
    "    # fraction of data to use for the internal validation set (if early_stopping=True)\n",
    "    \"validation_fraction\":  [0.05, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "# Set up the ModelTrainer for Randomized Search\n",
    "trainer = ModelTrainer(\n",
    "    X             = X_train,\n",
    "    y             = y_train,\n",
    "    model_factory = hgb_pipeline_factory,\n",
    "    search        = 'random',\n",
    "    param_grid    = hgb_param_grid,\n",
    "    n_iter        = 50,\n",
    "    cv_splitter   = TimeSeriesSplit(n_splits=3),\n",
    "    custom_metrics= {'wmae': wmae_custom},\n",
    "    log_path      = 'csv_files/ml_train_data/hgb_random_wmae01.csv',\n",
    "    model_name    = 'HGB_WMAE',\n",
    "    problem_type  = 'reg',\n",
    "    n_jobs        = -1,\n",
    "    random_state  = 7\n",
    ")\n",
    "\n",
    "# Run the search\n",
    "best_params, best_score = trainer.train()\n",
    "print(\"Best params:\", best_params)\n",
    "print(\"Best WMAE:  \", best_score)\n",
    "\n",
    "# Clean up\n",
    "trainer.csv_file.close()\n",
    "del trainer\n",
    "import gc; gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "f507cc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "hgb_random_wmae01 = pd.read_csv('csv_files/ml_train_data/hgb_random_wmae01.csv')\n",
    "hgb_random_wmae01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "6e4342ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "df = hgb_random_wmae01.copy()             \n",
    "\n",
    "params_df = (\n",
    "    df['param_json']\n",
    "    .apply(lambda s: json.loads(s) if pd.notnull(s) else {})  \n",
    "    .apply(pd.Series)                                         \n",
    ")\n",
    "df = pd.concat([df, params_df], axis=1)\n",
    "\n",
    "metric = 'wmae'\n",
    "ignore = {'model_name', 'param_json',            \n",
    "          'mae', 'rmse', 'r2', metric, '__source__'}\n",
    "\n",
    "param_cols = [c for c in df.columns if c not in ignore]\n",
    "\n",
    "# keep only numeric hyper-params\n",
    "X = df[param_cols].select_dtypes(include=[np.number])\n",
    "y = df[metric]\n",
    "\n",
    "# guard against “empty X” (all NaNs / non-numeric)\n",
    "if X.shape[1] == 0:\n",
    "    raise ValueError(\"No numeric hyper-parameter columns left after filtering!\")\n",
    "\n",
    "# urrogate model + analyses \n",
    "rf = RandomForestRegressor(n_estimators=200, random_state=7, n_jobs=-1)\n",
    "rf.fit(X, y)\n",
    "\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "print(\"→ RF importances:\\n\", importances.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "perm = permutation_importance(rf, X, y, n_repeats=10, random_state=7, n_jobs=-1)\n",
    "perm_imp = pd.Series(perm.importances_mean, index=X.columns)\n",
    "print(\"→ Permutation importances:\\n\", perm_imp.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "# partial-dependence plots \n",
    "top = importances.sort_values(ascending=False).index[:]\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(32, 32), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, feat in zip(axes, top):\n",
    "    PartialDependenceDisplay.from_estimator(rf, X, [feat], ax=ax)\n",
    "    ax.set_title(f\"PDP: {feat}\")\n",
    "\n",
    "for ax in axes[len(top):]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "92b88c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "# Pipeline factory for Histogram-Based Gradient Boosting\n",
    "def hgb_pipeline_factory(params):\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", HistGradientBoostingRegressor(**params, random_state=7))\n",
    "    ])\n",
    "\n",
    "# 2) Build a “wide” param‐grid, but drop 'poisson' to avoid the non-negativity requirement error\n",
    "hgb_param_grid = {\n",
    "    # loss functions (no more 'poisson' for now)\n",
    "    \"loss\":                 [\"absolute_error\"],\n",
    "    # number of boosting iterations\n",
    "    \"max_iter\":             [300, 500, 1000],\n",
    "    # step size shrinkage\n",
    "    \"learning_rate\":        [0.05,0.01, 0.4],\n",
    "    # maximum number of leaves per tree\n",
    "    \"max_leaf_nodes\":       [None],\n",
    "    # maximum depth of each tree (None = unlimited, bounded by leaf‐nodes)\n",
    "    \"max_depth\":            [5, 10],\n",
    "    # minimum number of samples in each leaf\n",
    "    \"min_samples_leaf\":     [20,100],\n",
    "    # regularization strength (L2 penalty)\n",
    "    \"l2_regularization\":    [10.0, 20.0],\n",
    "    # number of bins used to bucket continuous features\n",
    "    \"max_bins\":             [255],\n",
    "    # tolerance for early stopping (only applies if early_stopping=True)\n",
    "    \"tol\":                  [1e-3, 1e-2],\n",
    "    # number of rounds with no improvement to wait before stopping\n",
    "    \"n_iter_no_change\":     [2, 5],\n",
    "    # whether to use early stopping on a validation split\n",
    "    \"early_stopping\":       [False],\n",
    "    # fraction of data to use for the internal validation set (if early_stopping=True)\n",
    "    \"validation_fraction\":  [0.05, 0.2],\n",
    "}\n",
    "\n",
    "# Set up the ModelTrainer for Randomized Search\n",
    "trainer = ModelTrainer(\n",
    "    X             = X_train,\n",
    "    y             = y_train,\n",
    "    model_factory = hgb_pipeline_factory,\n",
    "    search        = 'random',\n",
    "    param_grid    = hgb_param_grid,\n",
    "    n_iter        = 50,\n",
    "    cv_splitter   = TimeSeriesSplit(n_splits=3),\n",
    "    custom_metrics= {'wmae': wmae_custom},\n",
    "    log_path      = 'csv_files/ml_train_data/hgb_random_wmae02.csv',\n",
    "    model_name    = 'HGB_WMAE',\n",
    "    problem_type  = 'reg',\n",
    "    n_jobs        = -1,\n",
    "    random_state  = 7\n",
    ")\n",
    "\n",
    "# Run the search\n",
    "best_params, best_score = trainer.train()\n",
    "print(\"Best params:\", best_params)\n",
    "print(\"Best WMAE:  \", best_score)\n",
    "\n",
    "# Clean up\n",
    "trainer.csv_file.close()\n",
    "del trainer\n",
    "import gc; gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "94ee5aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "# load & explode both CSVs if you haven’t yet —\n",
    "paths = [\n",
    "    'csv_files/ml_train_data/hgb_random_wmae01.csv',\n",
    "    'csv_files/ml_train_data/hgb_random_wmae02.csv',\n",
    "]\n",
    "dfs = []\n",
    "for path in paths:\n",
    "    df = pd.read_csv(path)\n",
    "    params = df['param_json'].apply(json.loads).apply(pd.Series)\n",
    "    df = pd.concat([df.drop(columns='param_json'), params], axis=1)\n",
    "    df['__source__'] = path.split('/')[-1]\n",
    "    dfs.append(df)\n",
    "df_all = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "ab0c47b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "# choose metric & hyper‐param cols, drop any non‐numeric ones —\n",
    "metric = 'wmae'\n",
    "ignore = {'model_name','mae','rmse','r2', metric, '__source__'}\n",
    "param_cols = [c for c in df_all.columns if c not in ignore]\n",
    "\n",
    "# keep only numeric hyperparams\n",
    "X = df_all[param_cols].select_dtypes(include=[np.number])\n",
    "y = df_all[metric]\n",
    "\n",
    "# train surrogate —\n",
    "rf = RandomForestRegressor(n_estimators=200, random_state=7, n_jobs=-1)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# RF importances\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "print(\"→ RF importances:\\n\", importances.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "# permutation importances\n",
    "perm = permutation_importance(rf, X, y, n_repeats=10, random_state=7, n_jobs=-1)\n",
    "perm_imp = pd.Series(perm.importances_mean, index=X.columns)\n",
    "print(\"→ Permutation importances:\\n\", perm_imp.sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "# partial dependence plots for top-3 features, all in one figure —\n",
    "top = importances.sort_values(ascending=False).index[:].tolist()\n",
    "\n",
    "fig, axes = plt.subplots(4, 4 ,figsize=(32, 32), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, feat in zip(axes, top):\n",
    "    PartialDependenceDisplay.from_estimator(rf, X, [feat], ax=ax)\n",
    "    ax.set_title(f\"PDP: {feat}\")\n",
    "\n",
    "# turn off the last (unused) subplot\n",
    "axes[-1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11cee78",
   "metadata": {},
   "source": [
    "#### HBGB Halving Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ba1f0ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "# Pipeline factory for Histogram-Based Gradient Boosting\n",
    "def hgb_pipeline_factory(params):\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", HistGradientBoostingRegressor(**params, random_state=7))\n",
    "    ])\n",
    "\n",
    "# 2) Build a “wide” param‐grid (same as before)\n",
    "hgb_param_grid = {\n",
    "    \"loss\":                 [\"absolute_error\"],\n",
    "    \"max_iter\":             [300, 500, 1000],\n",
    "    \"learning_rate\":        [0.05, 0.01, 0.4],\n",
    "    \"max_leaf_nodes\":       [None],\n",
    "    \"max_depth\":            [5, 10],\n",
    "    \"min_samples_leaf\":     [20, 100],\n",
    "    \"l2_regularization\":    [10.0, 20.0],\n",
    "    \"max_bins\":             [255],\n",
    "    \"tol\":                  [1e-3, 1e-2],\n",
    "    \"n_iter_no_change\":     [2, 5],\n",
    "    \"early_stopping\":       [True],\n",
    "    \"validation_fraction\":  [0.05, 0.2],\n",
    "}\n",
    "\n",
    "trainer = ModelTrainer(\n",
    "    X             = X_train,\n",
    "    y             = y_train,\n",
    "    model_factory = hgb_pipeline_factory,\n",
    "    search        = 'halving',      # now recognized!\n",
    "    param_grid    = hgb_param_grid,\n",
    "    n_iter        = 2,             # ignored by halving\n",
    "    cv_splitter   = TimeSeriesSplit(n_splits=3),\n",
    "    custom_metrics= {'wmae': wmae_custom},\n",
    "    log_path      = 'csv_files/ml_train_data/hgb_halving_wmae03.csv',\n",
    "    model_name    = 'HGB_WMAE',\n",
    "    problem_type  = 'reg',\n",
    "    n_jobs        = -1,\n",
    "    random_state  = 7\n",
    ")\n",
    "best_params, best_score = trainer.train()\n",
    "\n",
    "\n",
    "# Run the halving search\n",
    "best_params, best_score = trainer.train()\n",
    "print(\"Best params:\", best_params)\n",
    "print(\"Best WMAE:  \", best_score)\n",
    "\n",
    "# Clean up\n",
    "trainer.csv_file.close()\n",
    "del trainer\n",
    "import gc; gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "bbf12acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\estif\\AppData\\Local\\Temp\\ipykernel_5088\\3725908297.py:14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_all = pd.concat(dfs, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load & explode both CSVs if you haven’t yet —\n",
    "paths = [\n",
    "    'csv_files/ml_train_data/hgb_random_wmae01.csv',\n",
    "    'csv_files/ml_train_data/hgb_random_wmae02.csv',\n",
    "    'csv_files/ml_train_data/hgb_halving_wmae03.csv',\n",
    "]\n",
    "dfs = []\n",
    "for path in paths:\n",
    "    df = pd.read_csv(path)\n",
    "    params = df['param_json'].apply(json.loads).apply(pd.Series)\n",
    "    df = pd.concat([df.drop(columns='param_json'), params], axis=1)\n",
    "    df['__source__'] = path.split('/')[-1]\n",
    "    dfs.append(df)\n",
    "df_all = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f2790e",
   "metadata": {},
   "source": [
    "##### HBGB Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7576a093",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "df_all.to_csv('csv_files/ml_train_data/df_hgb_halving_wmae03.csv', index=None)\n",
    "df = pd.read_csv('csv_files/ml_train_data/df_hgb_halving_wmae03.csv')\n",
    "# pick the row with the lowest WMAE\n",
    "best_row = df.loc[df['wmae'].idxmin()]\n",
    "\n",
    "# keep only the hyper-parameter columns\n",
    "non_params = {'model_name', 'mae', 'rmse', 'r2', 'wmae', '__source__'}\n",
    "param_series = best_row.drop(labels=non_params)\n",
    "\n",
    "# convert to a clean dict, turning floats like 500.0 → 500\n",
    "best_params = {\n",
    "    k: (int(v) if isinstance(v, (int, float)) and not math.isnan(v) and v.is_integer() else v)\n",
    "    for k, v in param_series.items()\n",
    "    if pd.notnull(v)                           # skip NaNs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08803d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\estif\\Desktop\\DataAnalyst\\_DataCourse_IronHack\\Quests\\ml_walmart_price\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but HistGradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Split your data\n",
    "cutoff  = df_merged.date.max() - pd.Timedelta(weeks=52)\n",
    "train   = df_merged[df_merged.date <= cutoff]\n",
    "test    = df_merged[df_merged.date >  cutoff]\n",
    "\n",
    "drop = ['weekly_sales','date','holiday_name']\n",
    "X_train, y_train = train.drop(columns=drop), train.weekly_sales\n",
    "X_test,  y_test  = test .drop(columns=drop),  test .weekly_sales\n",
    "\n",
    "# Build & fit a full‐feature pipeline\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\",  HistGradientBoostingRegressor(**best_params, random_state=7))\n",
    "])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Try to grab built‐in importances, else do permutation importance\n",
    "model = pipe.named_steps[\"model\"]\n",
    "try:\n",
    "    importances = model.feature_importances_\n",
    "    used_feats = X_train.columns[importances > 0]\n",
    "except AttributeError:\n",
    "    # permutation importances on the training set\n",
    "    perm = permutation_importance(\n",
    "        model, X_train, y_train,\n",
    "        n_repeats=5, random_state=7, n_jobs=-1\n",
    "    )\n",
    "    used_feats = X_train.columns[perm.importances_mean > 0]\n",
    "\n",
    "# Re‐fit pipeline on only the used features\n",
    "pipe2 = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\",  HistGradientBoostingRegressor(**best_params, random_state=7))\n",
    "])\n",
    "pipe2.fit(X_train[used_feats], y_train)\n",
    "\n",
    "# Predict & compute metrics\n",
    "y_pred  = pipe2.predict(X_test[used_feats])\n",
    "\n",
    "mae     = mean_absolute_error(y_test, y_pred)\n",
    "rmse    = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2      = r2_score(y_test, y_pred)\n",
    "weights = np.where(test['holiday_name'].notnull(), 5, 1)\n",
    "wmae    = (weights * np.abs(y_test - y_pred)).sum() / weights.sum()\n",
    "\n",
    "# Build your result DataFrame\n",
    "row = {\n",
    "    \"model_name\": 'HGB01',\n",
    "    **best_params,\n",
    "    \"mae\":  mae,\n",
    "    \"rmse\": rmse,\n",
    "    \"r2\":   r2,\n",
    "    \"wmae\": wmae\n",
    "}\n",
    "df_best_randomforest = pd.DataFrame([row])\n",
    "df_best_randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f093d794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to merge new best model : \n",
    "df_best_models = pd.read_csv('csv_files/ml_train_data/df_best_models.csv')\n",
    "results_df = pd.concat([df_best_randomforest, df_best_models], ignore_index=True)\n",
    "df_best_models = results_df\n",
    "df_best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81444ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_models.to_csv('csv_files/ml_train_data/df_best_models.csv', index=None)\n",
    "df_best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafc8038",
   "metadata": {},
   "source": [
    "### ExtraTreesRegressor  Hyper Parameters Search / CV Estimate (used to choose hyper-parameters faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3871ae07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Pipeline factory that remaps 'max_iter'→'n_estimators' and adds speedups\n",
    "def et_pipeline_factory(params):\n",
    "    p = params.copy()\n",
    "    # rename the halving budget\n",
    "    if \"max_iter\" in p:\n",
    "        p[\"n_estimators\"] = p.pop(\"max_iter\")\n",
    "    # always warm-start so growing budgets reuse previous trees\n",
    "    p[\"warm_start\"] = True\n",
    "    # if bootstrap, enable out-of-bag scoring for cheap hold-out estimates\n",
    "    if p.get(\"bootstrap\", False):\n",
    "        p[\"oob_score\"] = True\n",
    "    else:\n",
    "        # remove oob if bootstrap is disabled\n",
    "        p.pop(\"oob_score\", None)\n",
    "\n",
    "    # Construct pipeline\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", ExtraTreesRegressor(**p, random_state=7, n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "\n",
    "# 2) Halving-friendly grid: all valid ExtraTrees parameters except random_state/n_jobs\n",
    "et_param_grid_halving = {\n",
    "    # budgets for successive halving\n",
    "    \"max_iter\":              [100,   200,  400,  800],  \n",
    "    # split criteria (no poisson on negative y)\n",
    "    \"criterion\":             [\"squared_error\", \"absolute_error\"],\n",
    "    # tree structure\n",
    "    \"max_depth\":             [None,  10,   20,   30],\n",
    "    \"max_leaf_nodes\":        [None,  20,   50,   100],\n",
    "    # feature sampling\n",
    "    \"max_features\":          [\"sqrt\", \"log2\", 0.5, 1.0],\n",
    "    # sample‐weight controls\n",
    "    \"bootstrap\":             [True,  False],\n",
    "    \"max_samples\":           [0.5,   0.7,  1.0],  # fraction of rows per tree\n",
    "    # node‐splitting\n",
    "    \"min_samples_split\":     [2,     5,   10,    0.01, 0.05],\n",
    "    \"min_samples_leaf\":      [1,     2,    4,    0.01],\n",
    "    \"min_weight_fraction_leaf\":[0.0, 0.01, 0.05],\n",
    "    # regularization / pruning\n",
    "    \"min_impurity_decrease\": [0.0,   1e-7, 1e-5],\n",
    "    \"ccp_alpha\":             [0.0,   0.001,0.01,  0.1]\n",
    "}\n",
    "\n",
    "\n",
    "# 3) Run halving with your existing ModelTrainer\n",
    "trainer = ModelTrainer(\n",
    "    X             = X_train,\n",
    "    y             = y_train,\n",
    "    model_factory = et_pipeline_factory,\n",
    "    search        = 'halving',                   \n",
    "    param_grid    = et_param_grid_halving,      \n",
    "    cv_splitter   = TimeSeriesSplit(n_splits=3),  # or KFold, or None\n",
    "    custom_metrics= {'wmae': wmae_custom},\n",
    "    log_path      = 'csv_files/ml_train_data/et_halving_wmae01.csv',\n",
    "    model_name    = 'ET_WMAE',\n",
    "    problem_type  = 'reg',\n",
    "    n_jobs        = -1,\n",
    "    random_state  = 7\n",
    ")\n",
    "\n",
    "best_params, best_score = trainer.train()\n",
    "print(\"Best params:\", best_params)\n",
    "print(\"Best WMAE:  \", best_score)\n",
    "\n",
    "# 4) Clean up\n",
    "trainer.csv_file.close()\n",
    "del trainer\n",
    "import gc; gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6081828e",
   "metadata": {},
   "source": [
    "### NGBoost (Natural Gradient Boosting)  Hyper Parameters Search / CV Estimate (used to choose hyper-parameters faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dae2a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from ngboost import NGBRegressor\n",
    "from ngboost.distns import Normal, Laplace, StudentT\n",
    "\n",
    "# 1) Pipeline factory for NGBoost\n",
    "def ngb_pipeline_factory(params):\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", NGBRegressor(**params, random_state=7))\n",
    "    ])\n",
    "\n",
    "# 2) A broad hyperparameter grid for randomized search\n",
    "ngb_param_grid = {\n",
    "    # number of boosting rounds\n",
    "    \"n_estimators\":            [100, 200, 500, 1000],\n",
    "    # shrinkage / step size\n",
    "    \"learning_rate\":           [0.01, 0.05, 0.1, 0.2],\n",
    "    # choice of predictive distribution\n",
    "    \"Dist\":                    [Normal, Laplace, StudentT],\n",
    "    # whether to use natural gradient updates\n",
    "    \"natural_gradient\":        [True, False],\n",
    "    # fraction of data to subsample for each update\n",
    "    \"minibatch_frac\":          [0.5, 1.0],\n",
    "    # fraction of features to subsample for each tree\n",
    "    \"col_sample\":              [0.5, 1.0],\n",
    "    # stopping tolerance (None disables early stopping)\n",
    "    \"tol\":                     [None, 1e-4, 1e-3],\n",
    "    # tree‐specific parameters passed to the default base learner\n",
    "    \"Base__max_depth\":         [3, 5, 10],\n",
    "    \"Base__min_samples_leaf\":  [1, 5, 10],\n",
    "}\n",
    "\n",
    "# 3) Set up the ModelTrainer for randomized search\n",
    "trainer = ModelTrainer(\n",
    "    X             = X_train,\n",
    "    y             = y_train,\n",
    "    model_factory = ngb_pipeline_factory,\n",
    "    search        = 'random',\n",
    "    param_grid    = ngb_param_grid,\n",
    "    n_iter        = 100,\n",
    "    cv_splitter   = TimeSeriesSplit(n_splits=3),\n",
    "    custom_metrics= {'wmae': wmae_custom},\n",
    "    log_path      = 'csv_files/ml_train_data/ngb_random_wmae.csv',\n",
    "    model_name    = 'NGB_WMAE',\n",
    "    problem_type  = 'reg',\n",
    "    n_jobs        = -1,           # NGBoost itself parallelizes tree fits internally\n",
    "    random_state  = 7\n",
    ")\n",
    "\n",
    "# 4) Run the search\n",
    "best_params, best_score = trainer.train()\n",
    "print(\"Best params:\", best_params)\n",
    "print(\" Best WMAE:  \", best_score)\n",
    "\n",
    "# 5) Clean up\n",
    "trainer.csv_file.close()\n",
    "del trainer\n",
    "import gc; gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699df851",
   "metadata": {},
   "source": [
    "### HuberRegressor (Robust Linear Model)  Hyper Parameters Search / CV Estimate (used to choose hyper-parameters faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cdd5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# 1) Pipeline factory for HuberRegressor\n",
    "def huber_pipeline_factory(params):\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", HuberRegressor(**params))\n",
    "    ])\n",
    "\n",
    "# 2) Broad hyperparameter grid for randomized search\n",
    "huber_param_grid = {\n",
    "    # The epsilon parameter for the Huber loss threshold\n",
    "    \"epsilon\":          [1.1, 1.35, 1.5, 1.75, 2.0],\n",
    "    # Regularization strength (inverse of C in SVM terms)\n",
    "    \"alpha\":            [1e-4, 1e-3, 1e-2, 1e-1, 1.0],\n",
    "    # Maximum number of iterations for the solver\n",
    "    \"max_iter\":         [100, 500, 1000],\n",
    "    # Tolerance for optimization convergence\n",
    "    \"tol\":              [1e-4, 1e-3, 1e-2],\n",
    "    # Whether to calculate the intercept for this model\n",
    "    \"fit_intercept\":    [True, False],\n",
    "    # Whether to reuse the solution of the previous call to fit as initialization\n",
    "    \"warm_start\":       [False, True]\n",
    "}\n",
    "\n",
    "# 3) Set up the ModelTrainer for randomized search\n",
    "trainer = ModelTrainer(\n",
    "    X             = X_train,\n",
    "    y             = y_train,\n",
    "    model_factory = huber_pipeline_factory,\n",
    "    search        = 'random',\n",
    "    param_grid    = huber_param_grid,\n",
    "    n_iter        = 100,\n",
    "    cv_splitter   = TimeSeriesSplit(n_splits=3),\n",
    "    custom_metrics= {'wmae': wmae_custom},\n",
    "    log_path      = 'csv_files/ml_train_data/huber_random_wmae.csv',\n",
    "    model_name    = 'HUBER_WMAE',\n",
    "    problem_type  = 'reg',\n",
    "    n_jobs        = -1,       # parallelism handled by sklearn where applicable\n",
    "    random_state  = 7\n",
    ")\n",
    "\n",
    "# 4) Run the search\n",
    "best_params, best_score = trainer.train()\n",
    "print(\"Best params:\", best_params)\n",
    "print(\"Best WMAE:   \", best_score)\n",
    "\n",
    "# 5) Clean up\n",
    "trainer.csv_file.close()\n",
    "del trainer\n",
    "import gc; gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3fb80d",
   "metadata": {},
   "source": [
    "### Meta Ensemble  Hyper Parameters Search / CV Estimate (used to choose hyper-parameters faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcc9303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "# Import your base‐learner classes:\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor\n",
    "from ngboost import NGBRegressor\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "\n",
    "# 1) Load your tuned‐params CSV (index should be model_name)\n",
    "best_params_df = pd.read_csv('best_params.csv', index_col='model_name')\n",
    "\n",
    "# 2) Map CSV names → model classes (add new entries here as you add models)\n",
    "model_mapping = {\n",
    "    'CatBoost01': CatBoostRegressor,\n",
    "    'XGBOOST01':  XGBRegressor,\n",
    "    'LGBM01':     LGBMRegressor,\n",
    "    'RF01':       RandomForestRegressor,\n",
    "    'ET01':       ExtraTreesRegressor,\n",
    "    'HGB01':      HistGradientBoostingRegressor,\n",
    "    'NGB01':      NGBRegressor,\n",
    "    'HUBER01':    HuberRegressor,\n",
    "    # 'NEWMODEL':  YourNewRegressorClass,\n",
    "}\n",
    "\n",
    "# 3) Instantiate each base learner with its best params\n",
    "base_estimators = []\n",
    "for name, row in best_params_df.iterrows():\n",
    "    cls = model_mapping.get(name)\n",
    "    if cls is None:\n",
    "        # placeholder slot for future models\n",
    "        continue\n",
    "    # drop any NaNs from your CSV\n",
    "    params = {k: v for k, v in row.to_dict().items() if pd.notna(v)}\n",
    "    # many of these regressors accept random_state; pass it if they do\n",
    "    if 'random_state' in cls().get_params():\n",
    "        params['random_state'] = 7\n",
    "    # Some need n_jobs\n",
    "    if 'n_jobs' in cls().get_params():\n",
    "        params['n_jobs'] = -1\n",
    "    estimator = cls(**params)\n",
    "    base_estimators.append((name.lower(), estimator))\n",
    "\n",
    "# 4) Build the stacking regressor\n",
    "stack = StackingRegressor(\n",
    "    estimators     = base_estimators,\n",
    "    final_estimator= RidgeCV(alphas=[0.1, 1.0, 10.0]),   # simple meta‐learner\n",
    "    cv             = TimeSeriesSplit(n_splits=3),\n",
    "    passthrough    = False,\n",
    "    n_jobs         = -1,\n",
    "    verbose        = 1\n",
    ")\n",
    "\n",
    "# 5) Random‐search **only** the meta‐learner params\n",
    "meta_param_dist = {\n",
    "    # RidgeCV’s alpha grid to search over \n",
    "    \"final_estimator__alphas\": [\n",
    "        [0.01, 0.1, 1.0],\n",
    "        [0.1, 1.0, 10.0],\n",
    "        [1.0, 10.0, 100.0]\n",
    "    ],\n",
    "    # whether to feed original features alongside base‐predictions\n",
    "    \"passthrough\": [True, False],\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator        = stack,\n",
    "    param_distributions = meta_param_dist,\n",
    "    n_iter           = 20,\n",
    "    cv               = TimeSeriesSplit(n_splits=3),\n",
    "    scoring          = make_scorer(wmae_custom, greater_is_better=False),\n",
    "    n_jobs           = -1,\n",
    "    random_state     = 7,\n",
    "    verbose          = 2\n",
    ")\n",
    "\n",
    "# 6) Fit & evaluate\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best meta‐params:\", search.best_params_)\n",
    "print(\"Stacked WMAE:\", -search.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8777adb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7749575,
     "sourceId": 12295466,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7750250,
     "sourceId": 12296537,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
